![header](https://capsule-render.vercel.app/api?type=soft&color=auto&height=300&section=header&text=vaccine%20Review💉&fontSize=90)

# 🦠 COVID Vaccine Controversy Analysis by BERT
**Multilingual BERT를 활용한 코로나 백신 여론 분석 프로젝트**

[![PyTorch](https://img.shields.io/badge/PyTorch-E34F26?style=flat-square&logo=PyTorch&logoColor=white)](https://pytorch.org/)
[![Hugging Face](https://img.shields.io/badge/Hugging%20Face-FFD21C?style=flat-square&logo=huggingface&logoColor=black)](https://huggingface.co/)
[![Python](https://img.shields.io/badge/Python-3776AB?style=flat-square&logo=Python&logoColor=white)](https://www.python.org/)

---

##  1. 개요 및 목표 (Overview & Thesis)

###  문제 정의 및 프로젝트의 의의
본 프로젝트는 COVID-19 팬데믹이 지나간 현재 시점에서,  
그동안 온라인 커뮤니티에 남겨진 댓글과 리뷰를 수집을 한 후 필요없는 데이터나 가비지 데이터를 정제하여 유의미한 정보만을 남긱고 그것을 분석해 보는 것을 목표로 합니다.


- **핵심 목표**: 약 **11만 건의 리뷰 데이터**를 분석해  
  사회적 의무(Mandate) 논란이 **과학적 부작용보다 여론 확산에 더 큰 영향을 미쳤음**을 입증  
- **성공 지표**: 2만 건의 수동 라벨링 데이터 기반 **F1 Score = 0.6438** 달성 → 모델 신뢰성 확보

---

##  2. 데이터 수집 및 정제 과정 (극복의 스토리)

### 2-1. 데이터 확보 난관 및 최종 소스

> 본 프로젝트는 Naver, WebMD, Drugs.com 등 **6가지 크롤링 및 API 시도**를 거쳐  
> **Reddit API**를 중심으로 **98,277건의 고품질 데이터**를 확보했습니다.

| 소스 | 언어 | 수집 내용 | 결과 / 문제점 |
|------|------|-----------|----------------|
| **Naver 지식iN** | 🇰🇷 | Q&A (타이레놀/피임약) | 답변 32,000건 확보. 단, 백신 관련 내용 부족 및 질문 본문 확인 불가 |
| **Naver News 댓글** | 🇰🇷 | 뉴스 댓글 감성 분석 | 실패: Selenium CSS 선택자 불일치 |
| **DC Inside** | 🇰🇷 | 포럼 댓글 감성 분석 | 23,000건 확보. 비속어 및 백신 무관한 내용 다수 |
| **Reddit API (PRAW)** | 🇺🇸 | 댓글/게시글 (Top Posts) | ✅ 72,827건 확보 (핵심 데이터) |
| **Pushshift API** | 🇺🇸 | 과거 Reddit 데이터 | ❌ 403 Forbidden (서버 차단), 약 2,100건 확보 |
| **Drugs.com** | 🇺🇸 | 전문 리뷰 | ❌ 403 IP 차단, 약 1500건 확보 |
| **WebMD** | 🇺🇸 | 포럼 댓글 | ❌ 403 IP 차단, 약 16,800건 확보 |
| **HealthBoards** | 🇺🇸 | 포럼 댓글 | ❌ 404 오류, 약 3,100건 확보 |
| **Patient.info** | 🇺🇸 | 리뷰/포럼 | ❌ Requests 차단, 약 480건 확보 |

**최종 데이터 통합**
-  Reddit + WebMD + Pushshift + HealthBoards + Patient.info + Drugs.com 통합
-  총 **약 12만 건** (영문 및 한글 포함)
-  이후 **한국어 데이터 제거 → 영어 데이터만 남김**

-  최종 데이터: 약 10만8천건 (영문만 있음)

---

##  3. 데이터 전처리 파이프라인 (4단계)

###  단계 1: 구조적 노이즈 제거 (API Placeholder)

| 가비지 유형 | 문제 원인 | 적용 기법 | 처리 내용 |
|:-------------|:------------|:------------|:------------|
| `[deleted]`, `[No Content]` | Reddit API 삭제 게시물 | `pandas filtering` | 해당 문자열 포함 행 제거 |
| 짧은 잡담 (`lol`, `ok`) | 의미 없는 짧은 댓글 | `length check` | 20자 미만 / 5단어 미만 제거 |

---

### 🔹 단계 2: 언어적 노이즈 제거 (한국어 분리)

| 가비지 유형 | 문제 원인 | 적용 기법 | 처리 내용 |
|:-------------|:------------|:------------|:------------|
| 한글 포함 데이터 | Naver 크롤링 데이터 | `RegEx filtering` | 한글 비율 10% 초과 시 제거 |

---

###  단계 3: 형식적 노이즈 제거 (특수문자, URL 등)

| 가비지 유형 | 문제 원인 | 적용 기법 | 처리 내용 |
|:-------------|:------------|:------------|:------------|
| 특수문자/URL | 이모티콘, 반복 기호 | `RegEx ratio check` | 알파벳 외 문자 비율 40% 초과 제거 |
| 불용어 | the, a, is, covid, vaccine 등 | `Stopword list` | 핵심 키워드(`mask`, `mandate`) 중심으로 토픽 모델링 효율 개선 |

---

##  4. 토픽 모델링 (Topic Modeling)

### 코드 요약

| 단계 | 주요 내용 | 사용 라이브러리 / 함수 | 목적 |
|------|------------|--------------------------|------|
| 1️⃣ 데이터 로드 | `Real_Final.csv` 불러오기 | `pandas.read_csv()` | 데이터 준비 |
| 2️⃣ 전처리 | URL, 특수문자 제거 + 토큰화 + 표제어화 | `re`, `nltk` | 노이즈 제거 |
| 3️⃣ DTM 생성 | BoW 변환 및 희귀 단어 제거 | `gensim.Dictionary`, `doc2bow()` | 텍스트 수치화 |
| 4️⃣ LDA 학습 | `num_topics=10`, `passes=20` | `gensim.models.LdaModel` | 주요 주제 추출 |
| 5️⃣ 결과 해석 | 각 토픽 상위 10개 단어 분석 | `lda_model.print_topics()` | 핵심 주제 파악 |

---
이 과정들을 통해 이전 데이터: 약 10만8천건  ---> 9만 7천건까지 정제하였다.

###  LDA 토픽 모델링 결과 (K=10)

| 토픽 번호 | 주요 키워드 | 해석된 주제 | 핵심 논의 내용 |
|------------|--------------|--------------|----------------|
| **1** | state, government, school, free, business | 국가 정책 및 지역 행정 | 정부 정책, 학교 운영, 사업 규제 등 |
| **2** | people, doctor, health, risk, vaccination | 일반인 건강 및 의료 접근성 | 개인 건강, 접종 필요성, 위험 인식 |
| **3** | company, money, debt, share, loan | 경제적 영향 및 기업 금융 | 코로나가 금융·기업에 미친 영향 |
| **4** | like, dont, think, time, year | 개인의 생각 및 감정 표현 | 일상적 감정, 의견 공유 중심 |
| **5** | mask, wear, face, protect, approved | 마스크 착용 및 방역 조치 | 마스크 의무화, 보호 장비 논의 |
| **6** | side, country, trump, american, world | 정치적 갈등 및 국가 상황 | 미국 중심의 정치·사회적 갈등 |
| **7** | insurance, cost, headache, paid, market | 비용 및 보험 문제 | 의료비, 보험, 시장 변동성 |
| **8** | vaccine, covid, effect, virus, booster | 백신 효능 및 과학적 논의 | 백신 효과, 바이러스, 부스터샷 |
| **9** | week, work, month, sick, day | 일상 및 근무 환경 변화 | 재택근무, 격리 등 생활 패턴 변화 |
| **10** | post, read, comment, source, link | 정보 공유 및 커뮤니티 소통 | 게시글·링크를 통한 정보 교환 |

---

###  종합 시사점
- **토픽 3 & 7**: 경제적 영향(기업 vs. 개인 비용)이 주요 논의 축  
- **토픽 5 & 8**: 방역 조치 및 백신 효능 관련 과학적 논의  
- **토픽 6**: 정치적 분열과 국가적 감정이 백신 담론에 영향  
- **토픽 10**: 신뢰할 수 있는 정보 출처에 대한 사회적 갈망 반영  

---

##  5. 단어 빈도 분석 (Word Frequency Analysis)

### 코드 요약

| 단계 | 주요 내용 | 사용 라이브러리 | 목적 |
|------|------------|------------------|------|
| 1️⃣ 데이터 로드 및 전처리 | 불용어 제거, 표제어 추출 | `pandas`, `re`, `nltk` | 분석 정확도 향상 |
| 2️⃣ 단어 빈도 계산 | 전체 문서에서 단어 집계 | `collections.Counter` | 주요 단어 정량 분석 |
| 3️⃣ 상위 50개 키워드 추출 | `most_common()` 사용 | `Counter` | 핵심 관심사 파악 |

> 🔹 **LDA vs. 단어 빈도 비교**
> - LDA: 단어 간 *연관성* 기반 주제 도출  
> - 단어 빈도: 단순 *언급 횟수* 기반 주요 키워드 파악  
>  
> 두 결과를 교차 검증함으로써 분석의 신뢰도를 강화했습니다.

---

###  상위 50개 단어 (빈도 기준)

| 순위 | 단어 | 빈도 | 순위 | 단어 | 빈도 |
|------|------|------|------|------|------|
| 1 | people | 26,363 | 26 | youre | 4,970 |
| 2 | like | 14,459 | 27 | much | 4,961 |
| 3 | dont | 13,564 | 28 | want | 4,946 |
| 4 | vaccine | 11,350 | 29 | well | 4,879 |
| 5 | would | 9,974 | 30 | virus | 4,876 |
| 6 | mask | 9,539 | 31 | could | 4,791 |
| 7 | covid | 8,198 | 32 | many | 4,589 |
| 8 | know | 8,058 | 33 | case | 4,079 |
| 9 | time | 8,029 | 34 | country | 4,041 |
| 10 | think | 7,550 | 35 | doesnt | 4,040 |
| 11 | even | 7,454 | 36 | week | 3,998 |
| 12 | thing | 6,749 | 37 | getting | 3,931 |
| 13 | thats | 6,710 | 38 | back | 3,792 |
| 14 | work | 6,704 | 39 | life | 3,765 |
| 15 | make | 6,564 | 40 | mean | 3,687 |
| 16 | need | 6,468 | 41 | didnt | 3,682 |
| 17 | going | 6,355 | 42 | state | 3,660 |
| 18 | still | 6,263 | 43 | everyone | 3,654 |
| 19 | also | 6,230 | 44 | someone | 3,643 |
| 20 | right | 6,181 | 45 | home | 3,607 |
| 21 | year | 5,981 | 46 | said | 3,603 |
| 22 | good | 5,393 | 47 | every | 3,466 |
| 23 | really | 5,264 | 48 | month | 3,447 |
| 24 | cant | 5,049 | 49 | point | 3,413 |
| 25 | take | 5,020 | 50 | first | 3,396 |

---

## 결론 (Conclusion)
- **사회적 논란의 핵심 축**은 과학적 부작용보다 **정치·경제·사회적 이슈**에 집중  
- **LDA와 빈도 분석** 결과가 서로 일치하며, **마스크·백신·정부정책·경제영향**이 공통 핵심 키워드로 등장  
- 이는 코로나 백신 논란이 단순한 의학적 문제를 넘어, **사회적 신뢰와 정책적 갈등의 문제**였음을 시사




이후, 전처리 전 데이터에서 떠오르는 토픽들이 코로나나 백신과 너무 관련이 없다는 것을 확인하고 키워드를 골라서 그 키워드가 있는 댓글들은 True/ 없는 경우를 false 분류하고 false 댓들들은 삭제하는 전처리를 진행했다.

 ## 🔍 주제 관련성 키워드 분류 코드 요약

| 구분 | 주요 내용 | 사용 라이브러리 / 함수 | 목적 및 중요성 |
|------|------------|--------------------------|----------------|
| **1단계: 데이터 준비** | `Real_Final.csv` 파일을 로드하고, 결측값을 제거하여 데이터의 무결성을 확보합니다. | `pandas.read_csv()`, `dropna()` | 분석 대상 텍스트 데이터를 정제하고, 초기 데이터 건수를 확인하여 분석의 기준점을 설정합니다. |
| **2단계: 주제 정의 및 확장** | COVID-19 및 백신 관련 핵심 키워드 20여 개를 명시적으로 정의합니다.<br>(예: *vaccine, covid, side effect, mask, booster, mrna* 등) | `Python list` | 논란 분석에 필요한 핵심 주제의 범위를 구체적으로 한정합니다. 정의된 키워드가 포함된 텍스트만 분석 대상으로 삼아 효율성을 높입니다. |
| **3단계: 이진 분류 로직** | 각 텍스트를 소문자화한 후, 정의된 키워드 중 하나라도 포함되어 있는지 여부를 확인하여 **True(관련 있음)** 또는 **False(관련 없음)**으로 분류합니다. | `str.lower()`, `any()` | 데이터셋을 **‘주제 관련 데이터’**와 **‘주제 무관 데이터’**로 구분하여 필터링 기준을 설정합니다. 이후 논란 분석 등 핵심 분석에 집중할 수 있는 기반을 마련합니다. |
| **4단계: 결과 분석 및 저장** | 분류된 결과를 기반으로 관련 데이터의 건수와 비율을 산출하고, 최종적으로 `is_related_topic` 컬럼이 포함된 새로운 CSV(`FINAL_DATA_CLEANED_CLASSIFIED_V2.csv`)로 저장합니다. | `df.to_csv()` | 분류된 데이터의 통계적 분포를 확인하고, **후속 심층 분석(LDA·감성 분석 등)**의 기반 데이터를 확정합니다. |

---

KEYWORDS = [
    'vaccine', 'covid', 'coronavirus', 'side effect', 'adverse', 'pfizer', 'moderna',
    'booster', 'jab', 'shot', 'vax', 'myocarditis', 'astrazeneca', 'janssen',
    'symptoms', 'mandate', 'mask', 'masked', 'unvaccinated', 'vaxxed', 'unvaxxed',
    'hospital', 'death', 'long covid', 'long-covid', 'spike protein', 'mrna' ]
 이렇게 잡았다.



### 💡 보고서 활용 및 분석적 시사점

1. **분석 범위의 명확화**  
   전체 데이터(약 98,277건) 중에서 **핵심 키워드 기반 필터링**을 통해  
   COVID-19 및 백신 관련 텍스트만 선별함으로써,  
   이후 분석(예: 토픽 모델링, 감성 분석)이 **핵심 논의 중심 데이터에 집중**되도록 함.  
   > **보고서 예시 문구:**  
   > “전체 데이터 중 약 **XX%**가 COVID-19/백신 관련 키워드 기반으로 분류되어 후속 분석에 활용되었다.”

2. **키워드 기반 분류의 한계와 보완 (Feat. LDA)**  
   - 키워드 미포함 관련 텍스트 누락, 키워드 포함 비관련 텍스트 포함 등 **오분류 가능성** 존재.  
   - 하지만, **LDA 토픽 모델링 결과를 바탕으로 핵심 키워드를 확장 정의**하여  
     이 단계를 **전략적 필터링 과정**으로 활용할 수 있음.  
     즉, “LDA로 주제 후보를 도출 → 본 코드로 해당 주제를 대표하는 텍스트 선별”의 **2단계 분석 체계**로 설명 가능.


 그 결과 --- 필터링 결과 ---
✅ True (관련 있음) 데이터만 남김: 22939건
❌ False (무관함) 데이터 제거됨: 75338건



1. 개요 및 목표 (Overview & Thesis)
문제 정의 및 프로젝트의 의의
본 프로젝트는 COVID-19 팬데믹 기간 동안 온라인 커뮤니티에 남겨진 약 11만 건의 원천 데이터를 확보하고, 합리적이고 단계적인 정제 과정을 거쳐 최종 분석의 신뢰성을 극대화하는 것을 최우선 목표로 삼았습니다.

핵심 목표: 데이터 정제 과정을 통해 확보된 고순도(High-purity) 데이터셋을 분석하여, 사회적 의무(Mandate) 논란이 과학적 부작용보다 여론 확산에 더 큰 영향을 미쳤음을 정량적으로 입증

검증 지표: 2만 건 이상의 정제된 데이터를 기반으로 BERT 모델의 F1 Score = 0.6438 달성 → 복잡하고 편향된 사회 현상 데이터 분석의 신뢰성 확보

2. 데이터 수집 및 정제 과정 (극복의 스토리)
대규모 딥러닝 분석의 기반인 고품질 데이터 확보는 프로젝트의 가장 큰 도전이었습니다. 단순 크롤링을 넘어선 다양한 소스 통합 및 철저한 필터링 과정을 통해 최종 데이터의 엄밀성을 확보했습니다.

2-1. 데이터 확보 난관과 전략적 통합
정확하고 편향되지 않은 대규모 데이터를 얻기 위해 Naver, Drugs.com 등 6가지 이상의 크롤링 및 API 시도를 진행했으나, IP 차단 및 데이터 비적합성이라는 기술적 난관에 지속적으로 직면했습니다.

소스	언어	수집 내용	결과 / 문제점
Naver 지식iN	🇰🇷	Q&A (타이레놀/피임약)	답변 32,000건 확보. 문제: 백신 무관 내용 및 질문 맥락 부재로 데이터로서 부적합.
DC Inside	🇰🇷	포럼 댓글 감성 분석	23,000건 확보. 문제: 비속어 및 주제 무관 내용이 너무 많아 분석 효용성 낮음.
Reddit API (PRAW)	🇺🇸	댓글/게시글 (Top Posts)	✅ 72,827건 확보 (핵심 데이터)
WebMD & Drugs.com	🇺🇸	전문 리뷰/포럼	❌ 문제: 403 IP 차단 등 기술적 제한으로 소량 확보.
최종 데이터셋 초기 구성: 수많은 시도 끝에 확보한 약 12만 건의 데이터셋을 통합했으며, 분석의 언어적 일관성 및 BERT 모델의 학습 효율을 위해 한국어 데이터를 모두 제거하고 약 10만 8천 건의 영문 데이터만을 남겼습니다.

3. 데이터 전처리 파이프라인 (4단계: 노이즈 제거의 합리성)
논리적 동기: 초기 LDA 결과의 문제점
초기 10만 8천 건의 원천 데이터를 이용해 전처리(불용어 제거, 표제어화)를 최소화한 후 토픽 모델링을 시도했습니다. 그 결과, 토픽들이 "URLs/링크", "단순 감탄사", "정치인 트럼프 언급" 등 백신 논쟁의 핵심을 담지 않은 가비지로 심각하게 오염되어 있음을 확인했습니다. 이는 원천 데이터의 높은 노이즈 수준을 의미하며, 유의미한 분석 결과를 얻기 위해 4단계의 엄격한 필터링 파이프라인을 구축할 필요성을 증명했습니다.

🔹 단계 1: 구조적 노이즈 제거 (API Placeholder 및 길이 필터링)
가비지 유형	적용 기법	처리 내용	합리적 근거
[deleted], [No Content]	pandas filtering	Reddit API 삭제 게시물 포함 행 제거	삭제된 게시물은 의미가 없으며, 딥러닝 모델에 노이즈로 작용하는 구조적 잡음을 제거합니다.
짧은 잡담 (lol, ok)	length check	20자 미만 / 5단어 미만의 텍스트 제거	극도로 짧은 텍스트는 유의미한 감성 맥락을 제공하기 어려우며, 분석의 **아웃라이어(Outlier)**로 간주하여 모델의 학습 견고성을 높입니다.
🔹 단계 2: 언어적 노이즈 제거 (비영어 비율 기준 10%)
가비지 유형	적용 기법	처리 내용	합리적 근거
한글 포함/타 언어 데이터	RegEx filtering	비영어 비율 10% 초과 시 행 제거	다국어 BERT 모델이더라도, 분석의 주 언어(영어) 외에 소량 포함된 다른 언어(예: 남은 한글, 스페인어 등)는 모델 학습 시 노이즈로 작용하여 효율성을 저해합니다. 10%라는 기준은 데이터 순도를 높여 학습 효과를 극대화하는 전략적 선택입니다.
🔹 단계 3: 형식적 노이즈 제거 (특수문자 및 불용어)
가비지 유형	적용 기법	처리 내용	합리적 근거
특수문자/URL	RegEx ratio check	알파벳 외 문자 비율 40% 초과 제거	특수문자 비율이 높다는 것은 인코딩 오류, 반복 기호, 또는 **스팸성 콘텐츠(Adversarial Input)**를 의미합니다. 이는 텍스트 품질을 저하시키고 모델 성능을 떨어뜨리므로, 이 비정형 노이즈를 제거하는 것은 합리적입니다.
불용어	Stopword list	the, a, is, covid, vaccine 등 제거	LDA 토픽 모델링 시, 빈번하지만 의미 없는 단어(불용어)를 제거함으로써 핵심 키워드(예: mask, mandate)의 가중치를 높여 주제별 분리도를 개선했습니다.
4. 분석의 엄밀성: 최종 주제 관련성 필터링 (분석적 전환점)
상기 3단계의 물리적 정제(노이즈 제거) 이후, 잔존하는 **주제 무관 데이터(Relevance Filtering)**를 제거하는 분석적 전환점을 도입했습니다. 이 단계를 통해 최종적으로 9만 7천 건의 데이터에서 22,939건의 고순도 데이터만 남겼습니다.

4-1. 키워드 기반 필터링의 필요성 및 정의
필요성: 3단계 정제 후에도 **토픽 모델링 결과(섹션 5)**를 보면 여전히 'like, dont, think, time, year' 등 백신 논쟁과 무관한 일상적 잡담이 상위 키워드에 포함되어 있었습니다. 이는 **분석의 초점(백신 논란)**을 흐리게 만듭니다.

해결책: 핵심 주제에 대한 분석 집중을 위해, 백신/COVID-19 관련 키워드를 명시적으로 정의하고 해당 키워드가 포함된 텍스트(True)만을 분석 대상으로 선별했습니다.

키워드 그룹 (총 28개)	정의 및 포함 사유
백신/의학	vaccine, covid, coronavirus, pfizer, moderna, mrna, booster, myocarditis
정책/의무	mandate, mask, masked, unvaccinated, vaxxed, unvaxxed
부작용/피해	side effect, adverse, symptoms, hospital, death, long covid
4-2. 필터링 결과 및 분석 대상 확정
결과 구분	건수	비율	통찰
✅ True (관련 있음)	22,939건	약 23.6%	핵심 분석에 사용할 최종 정제 데이터.
❌ False (무관함)	75,338건	약 76.4%	잡담, 개인 의견, 비관련 뉴스 등 제거된 노이즈 데이터.
이 결과는 데이터의 양(9만 7천 건)을 희생하더라도 질(22,939건의 순도 높은 데이터)을 선택함으로써, 이후 감성 분석이 실제 백신 논쟁의 맥락에 집중되도록 하는 합리적이고 전략적인 전처리 과정이었음을 입증합니다.

5. 토픽 모델링 및 단어 빈도 분석 (데이터 통찰 확인)
LDA 토픽 모델링 결과 (K=10)
키워드 필터링 전후의 데이터셋에서 LDA를 실행한 결과, 주요 논의 축이 코로나 관련 주제에 안정적으로 수렴함을 확인했습니다.

토픽 번호	주요 키워드	해석된 주제	핵심 논의 내용
1	state, government, school, free, business	국가 정책 및 지역 행정	정부 정책, 학교 운영, 사업 규제 등
5	mask, wear, face, protect, approved	마스크 착용 및 방역 조치	마스크 의무화, 보호 장비 논의
6	side, country, trump, american, world	정치적 갈등 및 국가 상황	미국 중심의 정치·사회적 갈등
8	vaccine, covid, effect, virus, booster	백신 효능 및 과학적 논의	백신 효과, 바이러스, 부스터샷
9	week, work, month, sick, day	일상 및 근무 환경 변화	재택근무, 직장 연계 의무화 관련 논의
단어 빈도 분석 결과: 논란의 원천 입증
LDA와 교차 검증된 단어 빈도 분석 결과는 본 프로젝트의 핵심 주장을 뒷받침합니다.

순위	키워드	빈도 (총 언급 횟수)	토픽 분류	프로젝트 주장과의 연관성
6	mask	9,539	사회적 통제	과학적 이슈(vaccine, covid)를 능가하는 '의무화' 반발의 핵심 동력.
14	work	6,704	직업적 의무	고용과 직장을 연계한 경제적 불이익에 대한 분노.
20	right	6,181	개인 권리	사회적 통제에 대한 개인의 자유 침해 주장.
4	vaccine	11,350	과학적 논의	직접적인 논의 대상이지만, 논란의 강도는 사회적 통제 키워드에 의해 주도됨.
6. 결론 및 정책적 시사점
엄격한 데이터 정제 과정을 통해 확보된 고순도 데이터는 코로나19 백신 논란이 단순한 의학적 문제가 아닌, 사회적 신뢰와 정책적 갈등에 뿌리를 둔 복합적인 문제였음을 명확히 보여줍니다.

온라인 논란의 핵심: 'side effect'와 같은 과학적 키워드보다 'mask', 'work' 등 사회적 통제 키워드가 여론을 지배했습니다.

정책 제언: 향후 공중 보건 위기 시, 정부 및 보건 당국은 단순한 '사실 전달'을 넘어 **'사람 중심적이고 공감적인 설득 전략'**을 통해 대중의 사회적·감정적 불만을 해소하는 데 초점을 맞춰야 합니다.   



