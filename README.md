![header](https://capsule-render.vercel.app/api?type=soft&color=auto&height=300&section=header&text=vaccine%20Review💉&fontSize=90)

# 🦠 COVID Vaccine Controversy Analysis by BERT
**Multilingual BERT를 활용한 코로나 백신 여론 분석 프로젝트**

[![PyTorch](https://img.shields.io/badge/PyTorch-E34F26?style=flat-square&logo=PyTorch&logoColor=white)](https://pytorch.org/)
[![Hugging Face](https://img.shields.io/badge/Hugging%20Face-FFD21C?style=flat-square&logo=huggingface&logoColor=black)](https://huggingface.co/)
[![Python](https://img.shields.io/badge/Python-3776AB?style=flat-square&logo=Python&logoColor=white)](https://www.python.org/)

---

##  1. 개요 및 목표 (Overview & Thesis)

###  문제 정의 및 프로젝트의 의의
본 프로젝트는 COVID-19 팬데믹이 지나간 현재 시점에서,  
그동안 온라인 커뮤니티에 남겨진 댓글과 리뷰를 수집을 한 후 필요없는 데이터나 가비지 데이터를 정제하여 유의미한 정보만을 남긱고 그것을 분석해 보고 어떤 새로운 결론을 찾는 것을을 목표로 합니다.


- **핵심 목표**: 약 **11만 건의 리뷰 데이터**를 분석해  
  사회적 의무(Mandate) 논란이 **과학적 부작용보다 여론 확산에 더 큰 영향을 미쳤음**을 입증  
- **성공 지표**: 2만 건의 수동 라벨링 데이터 기반 **F1 Score = 0.6438** 달성 → 모델 신뢰성 확보

---

##  2. 데이터 수집 및 정제 과정 (극복의 스토리)

### 2-1. 데이터 확보 난관 및 최종 소스

> 본 프로젝트는 Naver, WebMD, Drugs.com 등 **6가지 크롤링 및 API 시도**를 거쳐  
> **Reddit API**를 중심으로 **98,277건의 고품질 데이터**를 확보했습니다.

| 소스 | 언어 | 수집 내용 | 결과 / 문제점 |
|------|------|-----------|----------------|
| **Naver 지식iN** | 🇰🇷 | Q&A (타이레놀/피임약) | 답변 32,000건 확보. 단, 백신 관련 내용 부족 및 질문 본문 확인 불가 |
| **Naver News 댓글** | 🇰🇷 | 뉴스 댓글 감성 분석 | 실패: Selenium CSS 선택자 불일치 |
| **DC Inside** | 🇰🇷 | 포럼 댓글 감성 분석 | 23,000건 확보. 비속어 및 백신 무관한 내용 다수 |
| **Reddit API (PRAW)** | 🇺🇸 | 댓글/게시글 (Top Posts) | ✅ 72,827건 확보 (핵심 데이터) |
| **Pushshift API** | 🇺🇸 | 과거 Reddit 데이터 | ❌ 403 Forbidden (서버 차단), 약 2,100건 확보 |
| **Drugs.com** | 🇺🇸 | 전문 리뷰 | ❌ 403 IP 차단, 약 1500건 확보 |
| **WebMD** | 🇺🇸 | 포럼 댓글 | ❌ 403 IP 차단, 약 16,800건 확보 |
| **HealthBoards** | 🇺🇸 | 포럼 댓글 | ❌ 404 오류, 약 3,100건 확보 |
| **Patient.info** | 🇺🇸 | 리뷰/포럼 | ❌ Requests 차단, 약 480건 확보 |

**최종 데이터 통합**
-  Reddit + WebMD + Pushshift + HealthBoards + Patient.info + Drugs.com 통합
-  총 **약 12만 건** (영문 및 한글 포함)
-  이후 **한국어 데이터 제거 → 영어 데이터만 남김**

-  최종 데이터: 약 10만8천건 (영문만 있음)

---

##  3. 데이터 전처리 파이프라인 (4단계)

###  단계 1: 구조적 노이즈 제거 (API Placeholder)

| 가비지 유형 | 문제 원인 | 적용 기법 | 처리 내용 |
|:-------------|:------------|:------------|:------------|
| `[deleted]`, `[No Content]` | Reddit API 삭제 게시물 | `pandas filtering` | 해당 문자열 포함 행 제거 |
| 짧은 잡담 (`lol`, `ok`) | 의미 없는 짧은 댓글 | `length check` | 20자 미만 / 5단어 미만 제거 |

---

### 🔹 단계 2: 언어적 노이즈 제거 (한국어 분리)

| 가비지 유형 | 문제 원인 | 적용 기법 | 처리 내용 |
|:-------------|:------------|:------------|:------------|
| 한글 포함 데이터 | Naver 크롤링 데이터 | `RegEx filtering` | 한글 비율 10% 초과 시 제거 |

---

###  단계 3: 형식적 노이즈 제거 (특수문자, URL 등)

| 가비지 유형 | 문제 원인 | 적용 기법 | 처리 내용 |
|:-------------|:------------|:------------|:------------|
| 특수문자/URL | 이모티콘, 반복 기호 | `RegEx ratio check` | 알파벳 외 문자 비율 40% 초과 제거 |
| 불용어 | the, a, is, covid, vaccine 등 | `Stopword list` | 핵심 키워드(`mask`, `mandate`) 중심으로 토픽 모델링 효율 개선 |

---

이 과정들을 통해 이전 데이터: 약 10만8천건  ---> 9만 7천건까지 정제하였다.


이후 전체 데이터에서 10% 샘플을 뽑아 긍/부정으로 직접 라벨링을 진행했고  3.5:7.5 의비율로 긍/부정이 구분되었다. 
추가로 직접적으로 백신과 코로나, 부작용에 대한 언급은 얼마나 있는지 확인하기 위해 10% 셈플에 백신과 코로나, 부작용에 대한 언급이 있으면 True. 없다면 false로 추가로 라벨링을 진행하였다. 그 결과는 False=84% True=16의 결과가 나왔다.
이후 KoELECTRA를 사용하여 러신러닝을 진행하여 전체 데이터의 긍부정 비율과 true faluse 비율을 얻었다.
 1. 전체 감정 분포 ---
| Predicted_Sentiment   |   Count |   Ratio (%) |
|:----------------------|--------:|------------:|
| Negative              |   74954 |       76.27 |
| Positive              |   23323 |       23.73 |


2. True/false 비율
related_to_vaccine
False   83.29%
True    16.71%


3.모델 최종 성능 ---
✅ Accuracy (정확도): 0.8204
✅ F1 Score (균형 점수): 0.6438

이라는 결과가 나왔다 

시계열 데이터를 따라서 시간이 변함에 따라 부정의 비율이 어떻게 나오는지 도표를 통해서 확인해 봤다.

##  4. 토픽 모델링 (Topic Modeling)

### 코드 요약

| 단계 | 주요 내용 | 사용 라이브러리 / 함수 | 목적 |
|------|------------|--------------------------|------|
| 1️⃣ 데이터 로드 | `Real_Final.csv` 불러오기 | `pandas.read_csv()` | 데이터 준비 |
| 2️⃣ 전처리 | URL, 특수문자 제거 + 토큰화 + 표제어화 | `re`, `nltk` | 노이즈 제거 |
| 3️⃣ DTM 생성 | BoW 변환 및 희귀 단어 제거 | `gensim.Dictionary`, `doc2bow()` | 텍스트 수치화 |
| 4️⃣ LDA 학습 | `num_topics=10`, `passes=20` | `gensim.models.LdaModel` | 주요 주제 추출 |
| 5️⃣ 결과 해석 | 각 토픽 상위 10개 단어 분석 | `lda_model.print_topics()` | 핵심 주제 파악 |

---

###  LDA 토픽 모델링 결과 (K=10)

| 토픽 번호 | 주요 키워드 | 해석된 주제 | 핵심 논의 내용 |
|------------|--------------|--------------|----------------|
| **1** | state, government, school, free, business | 국가 정책 및 지역 행정 | 정부 정책, 학교 운영, 사업 규제 등 |
| **2** | people, doctor, health, risk, vaccination | 일반인 건강 및 의료 접근성 | 개인 건강, 접종 필요성, 위험 인식 |
| **3** | company, money, debt, share, loan | 경제적 영향 및 기업 금융 | 코로나가 금융·기업에 미친 영향 |
| **4** | like, dont, think, time, year | 개인의 생각 및 감정 표현 | 일상적 감정, 의견 공유 중심 |
| **5** | mask, wear, face, protect, approved | 마스크 착용 및 방역 조치 | 마스크 의무화, 보호 장비 논의 |
| **6** | side, country, trump, american, world | 정치적 갈등 및 국가 상황 | 미국 중심의 정치·사회적 갈등 |
| **7** | insurance, cost, headache, paid, market | 비용 및 보험 문제 | 의료비, 보험, 시장 변동성 |
| **8** | vaccine, covid, effect, virus, booster | 백신 효능 및 과학적 논의 | 백신 효과, 바이러스, 부스터샷 |
| **9** | week, work, month, sick, day | 일상 및 근무 환경 변화 | 재택근무, 격리 등 생활 패턴 변화 |
| **10** | post, read, comment, source, link | 정보 공유 및 커뮤니티 소통 | 게시글·링크를 통한 정보 교환 |

---

###  종합 시사점
- **토픽 3 & 7**: 경제적 영향(기업 vs. 개인 비용)이 주요 논의 축  
- **토픽 5 & 8**: 방역 조치 및 백신 효능 관련 과학적 논의  
- **토픽 6**: 정치적 분열과 국가적 감정이 백신 담론에 영향  
- **토픽 10**: 신뢰할 수 있는 정보 출처에 대한 사회적 갈망 반영


## 결론과 한계점 
- **사회적 논란의 핵심 축**은 과학적 부작용보다 **정치·경제·사회적 이슈**에 집중.
- **LDA와 빈도 분석** 결과가 서로 일치하며, **마스크·백신·정부정책·경제영향**이 공통 핵심 키워드로 등장함 
- 이는 코로나 백신 논란이 단순한 의학적 문제를 넘어, **사회적 신뢰와 정책적 갈등의 문제**였음을 시사한다.
따라서 일반적으로 사회적 신뢰와 정책적 갈등이 심할때 사회 불안지수, 경재 불안지수가 높아지기에 두 그래프를 X을 시간을 기준으로 비교해 보기로 했다
시계열 데이터를 따라서 시간이 변함에 따라 부정의 비율이 어떻게 나오는지 도표를 통해서 확인해 봤다.



## 두 그래프 비교 결과
피어슨 상관계수 = -0.006
DTW 거리 = 1280
참으로 실망적인 결과였다, 



피어슨 상관계수 ≈ -0.006은  0에 매우 가까움 → 두 그래프의 선 모양은 거의 직선적으로 상관이 없음.

즉, 한 그래프가 올라가면 다른 그래프가 올라가거나 내려가는 경향이 거의 없다는 의미입니다.


DTW(Dynamic Time Warping)는 두 시계열의 모양 차이를 측정하는 지표인데, 값이 크면 패턴이 많이 다름을 의미합니다.

1280 정도면 두 그래프의 모양이 상당히 다르다는 것을 보여줍니다.


- 하지만, 코로나 펜데믹이 이제는 과거가된 시점에서 이 결론은 너무나 naive하고 누구나 예상할 수 있는 결론이다.
- 또한 https://www.kci.go.kr/kciportal/ci/sereArticleSearch/ciSereArtiView.kci?sereArticleSearchBean.artiId=ART002756191과 논문 Sun Woong Kim. (2021). COVID-19 Fear Index and Stock Market. Journal of Convergence for Information Technology, 11(9), 84-93.을 보면
  이미 코로나와 공포지수는 관련이 있다고 보는게 일반적인 사실인데 그래프의 결과는 너무나도 관련이 없는 수치가 나왔다.
  
또한 그래프를 공포지수나 당시 사회 불안을 나타네는 표본들과 비교해 봐도 무언가 사회 현상과 연상지을 만한 부분을 발견하지는 못했으며, 이후 전체 데이터에서 무작위로 천개를 뽑아 직접 데이터를 읽어본 결과
false가 나오더라도 코로나나 백신과 직접 관련된 코멘트가 다분했고, 긍/부정 또한 부정으로 나왔지만, 중립에 가깝거나 아예 관련이 없는 정치 이야기인 경우가 너무 많았다.


## 결론
전처리 방법이 무언가 잘못 되었다는 것을 인식하고 처음부터 데이터 전처리부터 다시하기로, 방법을 바꾸기로 결정했다.

---


## 1️⃣ 다시 한번 개요 및 목표 (Overview & Thesis)

### 🎯 문제 정의 및 프로젝트의 의의  
본 프로젝트는 **COVID-19 팬데믹 기간 동안 온라인 커뮤니티에 남겨진 약 11만 건의 원천 데이터**를 확보하고,  
**합리적이고 단계적인 정제 과정**을 거쳐 최종 분석의 **신뢰성을 극대화**하는 것을 최우선 목표로 삼았습니다.

- **핵심 목표:**  
  데이터 정제 과정을 통해 확보된 **고순도(High-purity) 데이터셋**을 분석하여 새로운 결론을 찾는 것.




---

##  다시 한번 더  데이터 전처리 파이프라인 (노이즈 제거의 합리성)

### 🧠 논리적 동기: 초기 LDA 결과의 문제점  
초기 원천 데이터를 최소 전처리 후 LDA로 분석한 결과,  
**URLs, 감탄사, 정치인 이름 등 가비지 토픽**이 다수 등장 → 고노이즈 데이터로 판정.  
이에 따라 **4단계의 정제 파이프라인**을 설계했습니다.

---

### 🔹 단계 1: 구조적 노이즈 제거 (API Placeholder 및 길이 필터링)

| 가비지 유형 | 적용 기법 | 처리 내용 | 근거 |
|--------------|------------|------------|------|
| [deleted], [No Content] | pandas filtering | 삭제된 게시물 제거 | 의미 없는 구조적 잡음 제거 |
| 짧은 잡담 (lol, ok 등) | length check | 20자 미만 / 5단어 미만 텍스트 제거 | 학습 아웃라이어 제거, 모델 견고성 향상 |

---

### 🔹 단계 2: 언어적 노이즈 제거 (비영어 비율 10% 기준)

| 가비지 유형 | 적용 기법 | 처리 내용 | 근거 |
|--------------|------------|------------|------|
| 한글/타언어 포함 | RegEx filtering | 비영어 비율 10% 초과 시 제거 | 언어적 순도 향상 및 학습 효율 극대화 |

---

### 🔹 단계 3: 형식적 노이즈 제거 (특수문자 및 불용어)

| 가비지 유형 | 적용 기법 | 처리 내용 | 근거 |
|--------------|------------|------------|------|
| 특수문자 / URL | RegEx ratio check | 알파벳 외 문자 40% 초과 제거 | 인코딩 오류 및 스팸 방지 |
| 불용어 | Stopword list | the, a, is, covid, vaccine 등 제거 | 핵심 단어 가중치 향상 및 주제 분리도 개선 |

---

## 4️⃣ 분석의 엄밀성: 최종 주제 관련성 필터링 (Analytical Refinement)

### 🎯 단계 4: 주제 무관 데이터 제거 (Relevance Filtering)
물리적 정제 이후에도 여전히 ‘like, think, time’ 등의 **비주제적 단어**가 남아 있었기 때문에,  
**COVID-19 관련 키워드**를 포함한 데이터만 남기도록 필터링했습니다.


이후, 전처리 전 데이터에서 떠오르는 토픽들이 코로나나 백신과 너무 관련이 없다는 것을 확인하고 키워드를 골라서 그 키워드가 있는 댓글들은 True/ 없는 경우를 false 분류하고 false 댓들들은 삭제하는 전처리를 진행했다.

# 🔍 주제 관련성 키워드 분류 코드 요약

| 구분 | 주요 내용 | 사용 라이브러리 / 함수 | 목적 및 중요성 |
|------|------------|--------------------------|----------------|
| **1단계: 데이터 준비** | `Real_Final.csv` 파일을 로드하고, 결측값을 제거하여 데이터의 무결성을 확보합니다. | `pandas.read_csv()`, `dropna()` | 분석 대상 텍스트 데이터를 정제하고, 초기 데이터 건수를 확인하여 분석의 기준점을 설정합니다. |
| **2단계: 주제 정의 및 확장** | COVID-19 및 백신 관련 핵심 키워드 20여 개를 명시적으로 정의합니다.<br>(예: *vaccine, covid, side effect, mask, booster, mrna* 등) | `Python list` | 논란 분석에 필요한 핵심 주제의 범위를 구체적으로 한정합니다. 정의된 키워드가 포함된 텍스트만 분석 대상으로 삼아 효율성을 높입니다. |
| **3단계: 이진 분류 로직** | 각 텍스트를 소문자화한 후, 정의된 키워드 중 하나라도 포함되어 있는지 여부를 확인하여 **True(관련 있음)** 또는 **False(관련 없음)**으로 분류합니다. | `str.lower()`, `any()` | 데이터셋을 **‘주제 관련 데이터’**와 **‘주제 무관 데이터’**로 구분하여 필터링 기준을 설정합니다. 이후 논란 분석 등 핵심 분석에 집중할 수 있는 기반을 마련합니다. |
| **4단계: 결과 분석 및 저장** | 분류된 결과를 기반으로 관련 데이터의 건수와 비율을 산출하고, 최종적으로 `is_related_topic` 컬럼이 포함된 새로운 CSV(`FINAL_DATA_CLEANED_CLASSIFIED_V2.csv`)로 저장합니다. | `df.to_csv()` | 분류된 데이터의 통계적 분포를 확인하고, **후속 심층 분석(LDA·감성 분석 등)**의 기반 데이터를 확정합니다. |
---

### 💡 보고서 활용 및 분석적 시사점

1. **분석 범위의 명확화**  
   전체 데이터(약 98,277건) 중에서 **핵심 키워드 기반 필터링**을 통해  
   COVID-19 및 백신 관련 텍스트만 선별함으로써,  
   이후 분석(예: 토픽 모델링, 감성 분석)이 **핵심 논의 중심 데이터에 집중**되도록 함.  
   > **보고서 예시 문구:**  
   > “전체 데이터 중 약 **XX%**가 COVID-19/백신 관련 키워드 기반으로 분류되어 후속 분석에 활용되었다.”

2. **키워드 기반 분류의 한계와 보완 (Feat. LDA)**  
   - 키워드 미포함 관련 텍스트 누락, 키워드 포함 비관련 텍스트 포함 등 **오분류 가능성** 존재.  
   - 하지만, **LDA 토픽 모델링 결과를 바탕으로 핵심 키워드를 확장 정의**하여  
     이 단계를 **전략적 필터링 과정**으로 활용할 수 있음.  
     즉, “LDA로 주제 후보를 도출 → 본 코드로 해당 주제를 대표하는 텍스트 선별”의 **2단계 분석 체계**로 설명 가능.


---
## 키워드
KEYWORDS = [
    'vaccine', 'covid', 'coronavirus', 'side effect', 'adverse', 'pfizer', 'moderna',
    'booster', 'jab', 'shot', 'vax', 'myocarditis', 'astrazeneca', 'janssen',
    'symptoms', 'mandate', 'mask', 'masked', 'unvaccinated', 'vaxxed', 'unvaxxed',
    'hospital', 'death', 'long covid', 'long-covid', 'spike protein', 'mrna' ]
 이렇게 잡았다.

 이유는 저번에 'vaccine', 'covid', 'coronavirus', 'side effect' 이런식으로 간단히 잡으니, 코로나 백신과 관련이 있는데도 false로 구분된 경우가 매우 많았기에, 저번 false 데이터(약 7만 건) 중에 1000 건을 무작위로 뽑아 실은True 였던 것들은 직접 라벨링을 한번 더 진행하고, 그 중 빈도가 높게 등장했던 상위 30위를 뽑아 위 합리적인 키워드들을 정했다.

| 키워드 그룹 | 예시 | 포함 이유 |
|--------------|------|------------|
| 백신/의학 | vaccine, covid, pfizer, moderna, booster,pfizer | 백신 관련 직접 논의 |
| 정책/의무 | mandate, mask, masked, unvaccinated,jab | 사회적 의무 논란 |
| 부작용/피해 | side effect, adverse, symptoms, hospital | 의학적 부작용 논의 |

---

### 📊 필터링 결과

| 결과 구분 | 건수 | 비율 | 통찰 |
|------------|------|------|------|
| ✅ True (관련 있음) | 23,939 | 23.6% | 최종 분석용 고순도 데이터 |
| ❌ False (무관함) | 75,338 | 76.4% | 잡담, 뉴스 등 제거 |


false는 모두 지우고 True만 남기여서 FINAL_DATA_FILTERED_TRUE.csv로 저장.

## 검증
이 FINAL_DATA_FILTERED_TRUE.csv 데이터가 과연 정말로 코로나 백신 대이터로써 좋은 데이터인지 검증하기 위해 또 10%(약 2,200개)를 무작위로 뽑아 직접 읽어보면서 코로나와 정말로 관련이 있는지 확인하는 작업을 거쳤다.

결과를 보니 대부분 정말로 코로나와 관련이 있는 데이터였지만, 종종 의료관련업계 사람들이 코로나 백신에 대한 자신의 의견이 없이 여론이 아닌 논문의 링크나 기사의 링크는 보내는 경우가 종종 보였기 때문에 [eX) See the rest of the article by infectious disease expert [Dr. Siouxsie Wiles](https://en.wikipedia.org/wiki/Siouxsie_Wiles) (PhD from Oxford) [here](https://thespinoff.co.nz/society/09-03-2020/the-three-phases-of-covid-19-and-how-we-can-make-it-manageable/).]  추가적으로 FINAL_DATA_FILTERED_TRUE.csv 데이터에서 그런 데이터를 지우는 전처리를 진행했다.
#결과
✅ 원본 데이터 (23939 행) 불러오기 완료.
✅ 클리닝 완료. 총 1010개의 행이 삭제되었습니다.
🎉 클리닝된 데이터 (22929 행)가 'FINAL_DATA_ROWS_DELETED.csv'(으)로 성공적으로 저장되었습니다.

다만, 기사를 인용하면서도 단순 기사 공유가 아닌 경우에도 있을 수 있을 것 같아서 1010개를 직접적으로 확인해 보고 쓸 수 있는 데이터라고 판단한 423개는 다시 추가하여 'FINAL_DATA_ROWS_DELETED_2.csv'(23,352개)로 저장하였다.


> ✔️ **결론:** 데이터의 양보다 질을 선택 — 감성 분석의 초점이 백신 논란의 본질에 집중되도록 보장
>
> 이 정제된 FINAL_DATA_ROWS_DELETED.csv를 사용할 것이다

---


## 5. 단어 빈도 분석 (Word Frequency Analysis)

### 코드 요약

| 단계 | 주요 내용 | 사용 라이브러리 | 목적 |
|------|------------|----------------|------|
| 1️⃣ 데이터 로드 및 전처리 | 불용어 제거, 표제어 추출 | `pandas`, `re`, `nltk` | 분석 정확도 향상 |
| 2️⃣ 단어 빈도 계산 | 전체 문서에서 단어 집계 | `collections.Counter` | 주요 단어 정량 분석 |
| 3️⃣ 상위 50개 키워드 추출 | `most_common()` 사용 | `Counter` | 핵심 관심사 파악 |

> **LDA vs. 단어 빈도 비교**  
> - LDA: 단어 간 *연관성* 기반 주제 도출  
> - 단어 빈도: 단순 *언급 횟수* 기반 주요 키워드 파악  
> - 두 결과를 교차 검증하여 분석 신뢰도 강화

### 주요 단어 결과
1. people  
2. covid  
3. vaccine  
4. get  
5. dont  
6. mask  

> 분석 해석:  
> - 2위와 3위를 통해 코로나 관련 논의가 활발함  
> - 1위는 일반 대중에 대한 논의  
> - 4,5,6위를 통해 부정적 의견 및 마스크 관련 언급 많음

---

### 데이터 라벨링
- 전체 데이터의 10% (약 2,100개) 샘플링 후 수동 라벨링 진행
- 이진 분류와 삼분류 동시에 수행

**이진 분류 결과 비율**

| sentiment_binary | 비율 (%) |
|-----------------|----------|
| 부정            | 81.21    |
| 긍정            | 18.79    |

**삼분류 결과 비율**

| sentiment_three | 비율 (%) |
|----------------|----------|
| 부정           | 63.51    |
| 긍정           | 18.79    |
| 중립           | 17.70    |

---

## Ⅰ. 데이터 개요 및 탐색적 분석 (EDA)
**목표:** 댓글 데이터에서 자주 등장하는 단어 파악 및 트렌드 분석  

### 1. 전처리 및 주요 단어 추출
- 소문자 변환, URL 제거, 비알파벳 문자 제거  
- 불용어(Stopwords) 및 3글자 미만 단어 제거  
- 결과물: `top_words_frequency.png` (상위 20개 단어 빈도)

### 2. 시계열 단어 빈도 분석
- 상위 5개 단어를 월별 상대적 빈도로 계산  
- 결과물:  
  - `word_frequency_over_time.png` (월별 빈도 꺾은선 그래프)  
  - `monthly_word_frequency_ts.csv` (월별 빈도 데이터)

---

## Ⅱ. 딥러닝 학습 데이터 준비 및 라벨링 (Human Annotation)
**목표:** KoElectra 학습용 고품질 수동 라벨링 데이터 준비

### 1. 샘플링 및 인코딩 문제 해결
- 원본 데이터 약 22,939개 중 10% 샘플링 (약 2,294개)  
- 깨진 문자(Mojibake) 문제 해결: `pd.read_csv(encoding='utf-8' 또는 'cp949')`  
- 시간 정보 포함하여 라벨링 파일 생성:
  - `BERT_labeled_binary.csv` (긍정/부정)  
  - `BERT_labeled_three.csv` (긍정/부정/중립)

---

## Ⅲ. KoElectra 모델 학습 및 평가 (Deep Learning)
**목표:** KoElectra로 Binary 및 Three-Class 감성 분류 수행

### 1. 학습 환경 및 모델 설정

| 항목 | 설정 내용 | 비고 |
|------|-----------|------|
| 모델 | KoElectra (monologg/koelectra-base-v3-discriminator) | 한국어 NLP 모델 |
| 평가 지표 | Valid Accuracy | 모델 일반화 성능 측정 |
| 데이터 분리 | 라벨링된 샘플 중 90% 학습, 10% 검증 | 신뢰성 있는 Valid Accuracy 확보 목적 |
| 코드 수정 | `eval_steps=100`, `save_steps=100` | TrainingArguments 오류 해결 및 환경 맞춤 |

### 2. 독립적 학습 작업

| 작업 | 데이터 파일 | 클래스 라벨 | 출력 파일 |
|------|------------|------------|-----------|
| Binary | BERT_labeled_binary.csv | 부정:0, 긍정:1 | predicted_binary.csv |
| Three-Class | BERT_labeled_three.csv | 부정:0, 중립:1, 긍정:2 | predicted_three.csv |

### 3. 최종 기대 결과
- Valid Accuracy 값 (Binary 및 Three-Class)  
- `predicted_binary.csv`: 전체 원본 데이터에 긍정/부정 라벨 추가  
- `predicted_three.csv`: 전체 원본 데이터에 긍정/부정/중립 라벨 추가




# KoElectra 감성 분석 모델 학습 결과

## Ⅰ. 학습 로그 요약

### 1. Binary 모델 (긍정/부정, 클래스 수: 2)
- 학습 데이터: `BERT_labeled_binary.csv`
- Epoch: 2
- Train Loss:
  - Epoch 1: 0.4909
  - Epoch 2: 0.4813
- ✅ Validation Accuracy: 0.8126
- 예측 결과: `predicted_binary_2.csv`

> ⚠️ 주의: 일부 가중치가 초기화되지 않았다는 경고 발생  
> ```
> Some weights of ElectraForSequenceClassification were not initialized ...
> ```

### 2. Three-Class 모델 (긍정/중립/부정, 클래스 수: 3)
- 학습 데이터: `BERT_labeled_three.csv`
- Epoch: 2
- Train Loss:
  - Epoch 1: 0.9314
  - Epoch 2: 0.9033
- ✅ Validation Accuracy: 0.6362
- 예측 결과: `predicted_three_2.csv`

---

## Ⅱ. 최종 결과

### 1. Binary 분류 결과
| 감성 | 개수 | 비율 (%) |
|------|------|----------|
| 부정 | 22,348 | 97.42 |
| 긍정 | 591 | 2.58 |
| 합계 | 22,939 | 100 |

- **해석:**  
Binary 모델은 '부정' 예측이 압도적으로 높음  
→ 학습 데이터의 심각한 클래스 불균형(부정 81.2% vs 긍정 18.8%)이 원인

---

### 2. Three-Class 분류 결과
| 감성 | 개수 | 비율 (%) |
|------|------|----------|
| 부정 | 20,379 | 88.84 |
| 긍정 | 2,551 | 11.12 |
| 중립 | 9 | 0.04 |
| 합계 | 22,939 | 100 |

- **해석:**  
Three-Class 모델도 '부정' 편향 존재  
- '중립' 클래스 예측 거의 없음  
- 이는 학습 데이터에서 다수 클래스의 비율이 높고, Epoch가 짧아 소수 클래스 학습이 부족했기 때문

---

## Ⅲ. 문제 원인 분석

### 1. 클래스 불균형 (Class Imbalance)
| 분류 | 라벨 | 개수 | 비율 (%) | 매핑 숫자 |
|------|------|------|----------|-----------|
| Binary | 부정 | 1,863 | 81.2 | 0 |
| Binary | 긍정 | 431 | 18.8 | 1 |
| Three-Class | 부정 | 1,457 | 63.5 | 0 |
| Three-Class | 긍정 | 431 | 18.8 | 2 |
| Three-Class | 중립 | 406 | 17.7 | 1 |

- 모델은 학습 데이터의 다수 클래스만 예측  
→ **예측 붕괴(Prediction Collapse)** 또는 **과도한 편향 학습(Bias Learning)** 현상 발생

### 2. 짧은 학습 시간
- 현재 Epoch=2 → 모델이 소수 클래스 특징 학습 부족

---

## Ⅳ. 해결책 및 권장 조치

### 1️⃣ 에포크 수 증가
- Epoch 2 → **5~10 Epoch**로 학습 시간 연장  
- 소수 클래스(긍정/중립) 특징 학습 가능

### 2️⃣ 클래스 가중치 적용
- 손실 함수(CrossEntropyLoss)에 클래스 가중치 전달  
- '부정' 가중치 낮추고, '긍정'과 '중립' 가중치 높임  
- 모델이 소수 클래스를 놓치지 않도록 강제

```python
# 예시 (PyTorch)
import torch.nn as nn
class_weights = torch.tensor([0.5, 2.0, 2.0]).to(device)  # 부정, 중립, 긍정
criterion = nn.CrossEntropyLoss(weight=class_weights)



# 클래스 불균형 문제 해결 전략 및 보고서 활용 제언

---

## 1. 데이터 레벨 전략: 클래스 균형 맞추기

- 데이터셋 자체의 불균형을 해결하여 모델이 다수 클래스에만 집중하는 것을 방지합니다.

### 1) 오버 샘플링 (Oversampling)

- **원리:** 부족한 소수 클래스(긍정, 중립)의 샘플을 복제하거나, 기존 샘플을 바탕으로 새로운 유사 샘플을 생성(예: SMOTE 기법)하여 다수 클래스(부정)의 수와 비슷하게 맞춤  
- **목표:** 학습 데이터의 클래스 비율을 1:1에 가깝게 만들어 모델이 모든 클래스에 공평하게 학습하도록 함

---

## 2. 모델 레벨 전략: 손실 함수 조정

- 학습 과정(손실 함수, Loss Function)에 가중치를 부여하여 소수 클래스 예측 실패에 더 큰 패널티를 줌

### 3) 클래스 가중치 적용 (Class Weighting)

- **원리:** PyTorch의 `CrossEntropyLoss`는 `weight` 인자를 통해 각 클래스별 가중치 설정 가능  
- **설정 예시:**  
  - 다수 클래스(부정, 0): 낮은 가중치 (예: 0.2)  
  - 소수 클래스(긍정, 1 / 중립, 2): 높은 가중치 (예: 1.5 ~ 3.0)  
- **효과:** 모델이 긍정/중립을 부정으로 잘못 예측할 경우, 평소보다 큰 손실(Loss)을 발생시켜 모델이 해당 오류를 줄이도록 강하게 유도

---

## 💡 최종 분석 및 보고서 활용 제언

- **클래스 불균형 영향:**  
  - Binary 모델: '부정' 97.42%  
  - Three-Class 모델: '부정' 88.84%  
  → 수동 라벨링 데이터의 극심한 불균형(BERT_labeled_binary.csv 부정 81.2%)이 학습 모델에 그대로 반영됨

- **Binary vs. Three-Class 비교:**  
  - Binary: '부정' 클래스에 예측 붕괴 → 분류기 가치 낮음  
  - Three-Class: '부정' 편향 여전하지만, **긍정 예측 11.12%** 수행 → Binary보다는 분별력 있음  
  - 단, **중립 예측 0.04%** → 사실상 무시

- **향후 과제:**  
  - 보고서에서 "모델 예측 편향을 줄이기 위해 **오버 샘플링**과 **클래스 가중치 적용** 같은 불균형 해소 기법 필수"라고 논의 가능

- **예측 결과 파일:**  
  - `predicted_binary_3.csv`  
  - `predicted_three_3.csv`  
  → 원본 댓글과 함께 확인하여 감성 분류 특징 분석 가능


 # 오버 샘플링(Oversampling) & 클래스 가중치(Class Weighting) 병행 전략

---

## 🔹 두 기법 병행의 시너지 효과

| 기법 | 해결 레벨 | 역할 및 효과 |
|------|-----------|--------------|
| 오버 샘플링 | 데이터 레벨 | 학습 데이터의 양적 균형을 맞춤. 모델이 소수 클래스의 다양한 패턴을 더 자주 접할 수 있음 |
| 클래스 가중치 | 모델 레벨 | 오류 패널티의 중요성을 조정. 소수 클래스를 잘못 예측했을 때 가장 큰 패널티를 주어 모델이 소수 클래스의 분류에 집중하도록 강제 |

**시너지:**  
오버 샘플링으로 소수 클래스의 '데이터 부족' 문제를 해결하고, 클래스 가중치로 '학습 중요도'를 높여 불균형 문제를 구조적으로 해소하는 이중 방어 전략

---

## ⚠️ 주의사항: 과적합(Overfitting) 위험 관리

- **위험 요인:**  
  오버 샘플링(특히 SMOTE)으로 생성된 합성 데이터가 클래스 가중치 때문에 높은 중요도로 학습됨 → 모델이 합성 데이터의 노이즈까지 외워버릴 수 있음

- **해결책:**  
  - Validation Accuracy 철저히 모니터링  
  - Training Accuracy/Loss와 Validation Accuracy/Loss가 과도하게 벌어지면 즉시 학습 중단 (조기 종료)

- **단계적 적용 권장:**  
  1. 먼저 **클래스 가중치만 적용** → 효과 측정 (구현 비교적 쉬움)  
  2. 가중치만으로 성능 개선이 미미하면 **오버 샘플링 추가** → 시너지 효과

---

## 💡 보고서 활용 제언

- 이중 전략은 보고서에 **"방법론의 심화"**라는 주제로 활용 가능

### 보고서 구성 제안

| 섹션 | 내용 |
|-------|------|
| I. 불균형 분석 | 수동 라벨링 데이터의 극심한 클래스 불균형(부정 80% 이상) 제시 |
| II. 초기 모델 한계 | Epoch 2 학습 시 Predicted Label이 모두 '0'으로 나오는 예측 붕괴(Collapse) 현상 보고 |
| III. 불균형 해소 전략 | 클래스 가중치와 SMOTE 오버 샘플링 결합 적용 명시 |
| IV. 최종 결과 비교 | 가중치/샘플링 적용 후 Binary 및 Three-Class 모델 Valid Accuracy를 초기 모델과 비교, 성능 개선 효과 수치로 제시 |



 # 감성 분석 모델 개발 과정 및 불균형 해소 전략 요약

본 문서는 코로나 백신 관련 댓글 데이터에 대한 KoElectra 기반 감성 분류 모델 개발 과정에서 발생한 핵심 문제점과 이를 해결하기 위해 적용된 고급 전략을 요약합니다.

---

## I. 초기 데이터 불균형 분석 (Baseline Imbalance)

- **문제점:** 모델 학습의 기반이 된 수동 라벨링 샘플(10% 추출 데이터)은 심각한 클래스 불균형 내포
- **극심한 클래스 불균형:** 라벨링된 데이터 중 '부정' 클래스가 80% 이상 차지
- **영향:** 모델이 긍정/중립 등 소수 클래스의 패턴을 충분히 학습하지 못하고, 다수 클래스('부정')만 예측하도록 편향될 위험

---

## II. 초기 모델의 한계 및 예측 붕괴 현상 보고

- **초기 모델 설정:** Fine-tuning 에포크 수 2회 적용
- **결과:** 원본 데이터 전체에 대한 predicted_label이 **모두 '0' (부정)**으로 출력 → 예측 붕괴(Prediction Collapse)
- **결론:** 모델이 손실(Loss)을 최소화하기 위해 소수 클래스의 특성을 무시하고, 다수 클래스만 예측하도록 편향 학습 수행

---

## III. 불균형 해소 전략: 클래스 가중치 및 에포크 강화 적용

초기 모델의 예측 붕괴 현상을 극복하고 모델 분류 능력 개선을 위해 다음 전략 적용:

### 1. 클래스 가중치 (Class Weighting) 적용

- **목표:** 소수 클래스 오분류에 대한 오류 패널티 증대 → 소수 클래스 학습 중요도 향상
- **구현:**  
  - 학습 데이터 클래스 분포 파악  
  - 역빈도 기반 클래스 가중치(weights_tensor) 계산  
  - PyTorch `CrossEntropyLoss` 객체에 `weight` 인자로 전달
- **효과:** 긍정/중립 예측 실패 시 손실 증가 → 모델이 소수 클래스 예측 놓치지 않도록 강제

### 2. 에포크(Epoch) 수 증가

- **목표:** 클래스 가중치와 함께, 모델이 복잡한 손실 함수 기반 소수 클래스 특징을 충분히 탐색
- **구현:** 학습 에포크 2회 → 5회로 증가

### 3. 오버 샘플링(SMOTE) 우회 결정

- **논의:** 텍스트 데이터에 SMOTE 적용 시 의미론적 손실 가능
- **결정:** SMOTE 대신 클래스 가중치 + 에포크 강화 전략 결합 적용

---

## IV. 최종 결과 비교 (Valid Accuracy 및 성능 개선)

불균형 해소 전략 적용 후 Binary 및 Three-Class 모델 성능 개선:

| 모델 | 초기 모델 Valid Accuracy | 최종 Valid Accuracy (가중치/에포크 적용 후) | 주요 개선 효과 |
|------|-------------------------|-----------------------------------------|----------------|
| Binary (긍/부정) | 미측정 또는 매우 낮음 (예측 붕괴) | (획득된 수치 입력) | 예측 편향 해소, 긍정 클래스 분별력 확보 |
| Three-Class (긍/부/중립) | 미측정 (예측 붕괴) | (획득된 수치 입력) | 중립 클래스 예측 능력 확보, 전반적 정확도 향상 |

- **결론:**  
  클래스 가중치 및 에포크 강화 적용으로 다수 클래스로의 예측 붕괴 극복, Valid Accuracy 개선 → 신뢰성 있는 감성 분석 결과 도출 가능
- **활용:** 최종 보고서에서는 이 개선된 결과를 기반으로 원본 데이터의 감성 트렌드 분석

# 클래스 가중치 기반 감성 분석 모델 학습 및 결과 요약

## 1. 이진 분류 (Binary) 가중치 비중 분석

| 항목 | 계산 과정 | 결과 |
|------|-----------|------|
| Original Training Distribution | 부정(0): 1,490개, 긍정(1): 345개 | 총 1,835개 |
| 클래스 0 (부정) | $W_0 = 1835 / (2 \times 1490)$ | 0.6158 (낮음) |
| 클래스 1 (긍정) | $W_1 = 1835 / (2 \times 345)$ | 2.6594 (매우 높음) |

### 🔍 의미 해석
- **부정 (0.6158):** 다수 클래스 → 오분류 패널티 약 40% 낮춤  
- **긍정 (2.6594):** 소수 클래스 → 오분류 패널티 2.66배 증가, 긍정 예측 실패 억제

---

## 2. 삼분류 (Three-Class) 가중치 비중 분석

| 항목 | 계산 과정 | 결과 |
|------|-----------|------|
| Original Training Distribution | 부정(0): 1,165개, 중립(1): 325개, 긍정(2): 345개 | 총 1,835개 |
| 클래스 0 (부정) | $W_0 = 1835 / (3 \times 1165)$ | 0.5250 (가장 낮음) |
| 클래스 1 (중립) | $W_1 = 1835 / (3 \times 325)$ | 1.8821 (높음) |
| 클래스 2 (긍정) | $W_2 = 1835 / (3 \times 345)$ | 1.7729 (높음) |

### 🔍 의미 해석
- **부정 (0.5250):** 다수 클래스 → 오분류 패널티 약 50% 낮춤  
- **중립 (1.8821) & 긍정 (1.7729):** 소수 클래스 → 오분류 패널티 약 1.8~1.9배 증가  
- 가장 적은 '중립' 클래스에 가장 높은 가중치 부여 → 모델이 놓치지 않도록 강제

---

## 💡 최종 결론
- 역빈도 기반 클래스 가중치 적용 덕분에 모델이 예측 붕괴를 극복
- Binary 모델 Valid Accuracy: **78.43%**  
- Three-Class 모델 Valid Accuracy: **51.63%**  
- 보고서의 방법론 섹션에서 강조할 핵심 성공 전략

---

## 3. 학습 로그 및 결과

### 3.1 BERT_labeled_binary.csv 모델 학습 (클래스 수: 2)

**Original Training Distribution:**  
`Counter({0: 1490, 1: 345})`

**Calculated Class Weights (Order 0, 1):**  
`tensor([0.6158, 2.6594], device='cuda:0')`

**학습 과정 로그:**

| Epoch | Train Loss |
|-------|------------|
| 1 | 0.6928 |
| 2 | 0.6859 |
| 3 | 0.6575 |
| 4 | 0.6120 |
| 5 | 0.5042 |

**Validation Accuracy:** 0.7843  

**예측 결과 저장:** `predicted_binary_weighted_smote_final.csv`

---

### 3.2 BERT_labeled_three.csv 모델 학습 (클래스 수: 3)

**Original Training Distribution:**  
`Counter({0: 1165, 2: 345, 1: 325})`

**Calculated Class Weights (Order 0, 1, 2):**  
`tensor([0.5250, 1.8821, 1.7729], device='cuda:0')`

**학습 과정 로그:**

| Epoch | Train Loss |
|-------|------------|
| 1 | 1.1005 |
| 2 | 1.0921 |
| 3 | 1.0698 |
| 4 | 1.0559 |
| 5 | 1.0369 |

**Validation Accuracy:** 0.5163  

**예측 결과 저장:** `predicted_three_weighted_smote_final.csv`

---

### 3.3 최종 결과

| 모델 | Validation Accuracy |
|------|-------------------|
| Binary (긍정/부정) | 0.7843 |
| Three-Class (긍정/부정/중립) | 0.5163 |



## 4. 최종 결과 분석 및 활용

### 4.1 최종 Validation Accuracy

| 모델 | Validation Accuracy |
|------|-------------------|
| Binary (긍정/부정) | 0.7843 |
| Three-Class (긍정/부정/중립) | 0.5163 |

**분석:**  
- 초기 모델의 예측 편향이 해소되고, 긍정 및 중립 클래스의 예측 비율이 크게 증가함.  
- 특히, Three-Class 모델에서 '중립' 의견을 분류해낸 것이 주목할 만함.

---

### 4.2 이진 분류 결과 (Binary Classification: 긍정/부정)

| 감성 | 개수 | 비율 (%) |
|------|-----|----------|
| 부정 | 20,561 | 89.63% |
| 긍정 | 2,378  | 10.37% |
| 합계 | 22,939 | 100.00% |

📈 **이진 분류 결과 그래프**  

**분석:**  
- 클래스 가중치를 적용했음에도 불구하고, 여전히 **'부정' 감성이 89.63%**로 압도적임.  
- 이는 원본 데이터에 내재된 부정적 여론의 비중이 매우 높음을 시사함.

---

### 4.3 삼분류 결과 (Three-Class Classification: 긍정/중립/부정)

| 감성 | 개수 | 비율 (%) |
|------|-----|----------|
| 부정 | 12,486 | 54.43% |
| 긍정 | 7,733  | 33.71% |
| 중립 | 2,720  | 11.86% |
| 합계 | 22,939 | 100.00% |

📈 **삼분류 결과 그래프**  

**분석:**  
- 예측 편향 해소 성공: 클래스 가중치 적용 전 '부정'이 100%에 가까웠던 것과 달리, 이제 **'부정'이 54.43%**로 감소함.  
- 긍정/중립 분류 능력 확보: '긍정' 33.71%, **'중립' 11.86%**로 성공적으로 분리됨.  
- 이는 모델이 소수 클래스의 패턴을 학습했음을 의미하며, Three-Class 모델이 현실적인 여론 분포를 잘 반영함.

---

### 4.4 보고서 활용 제언

- **핵심 주장:** 클래스 가중치와 에포크 강화 전략이 모델의 예측 편향을 극복하고 객관적인 감성 분포를 도출하는 데 결정적인 역할을 함.  
- **Binary vs. Three-Class 비교:**  
  - Binary 모델에서는 '중립' 의견이 모두 '부정'으로 흡수됨.  
  - Three-Class 모델에서는 '부정' 비율 89.63% → 54.43%로 감소, '중립' 의견 11.86%로 분리됨.

---

### 4.5 시계열별 감성 분포 분석

- 이후, 이진 및 삼분류 데이터의 긍정/부정/중립 비율을 시계열에 따라 정리함.  
- **결과 시각화:**  
  ![시계열 감성 분포](사진)

---

### 4.6 토픽 모델링

1. **긍정 데이터 토픽 모델링**  
   ![긍정 토픽 결과](사진)

2. **부정 데이터 토픽 모델링**  
   ![부정 토픽 결과](사진)

**분석:**  
- 긍정과 부정 댓글 각각의 주요 토픽을 추출하여, 감성별 핵심 관심사 및 이슈를 파악함.  
- 이를 통해 단순 감성 분류를 넘어, 세부 여론 흐름과 핵심 키워드를 보고서에 제시 가능.

## 5. 감성별 토픽 모델링 결과

### 5.1 이진 분류 (Binary Classification: 긍정/부정) 토픽

#### 부정 (Negative)

| Topic | 상위 10개 단어 | 설명 |
|-------|----------------|------|
| 1 | people, don, masks, just, like, death, think, going, know, hospital | 일반적 불만/공포, 사람 관련 논의 |
| 2 | mask, wear, wear mask, wearing, wearing mask, masks, medical, wear masks, face, wearing masks | 마스크 착용 불만 및 논의 |
| 3 | https, com, www, https www, coronavirus, reddit, reddit com, message, www reddit, comments | 링크/출처 공유 관련 |
| 4 | vaccine, vaccines, got, effects, shot, getting, pfizer, booster, vaccinated, mrna | 백신 부작용 및 우려 |
| 5 | covid, 19, covid 19, died, test, patients, flu, died covid, covid vaccine, 19 vaccine | 사망, 검사 관련 |

#### 긍정 (Positive)

| Topic | 상위 10개 단어 | 설명 |
|-------|----------------|------|
| 1 | vaccine, got, just, vaccines, like, shot, people, ve, getting, days | 백신 접종 경험 공유 |
| 2 | mask, wear, wear mask, wearing mask, wearing, good, fucking, fuck, just, don | 마스크 착용에 대한 긍정적/일상적 언급 |
| 3 | covid, covid 19, 19, game, covid covid, good, covid vaccine, way, christmas, spread | 상황 호전 기대, 긍정적 전망 |
| 4 | masks, wearing, people, wearing masks, wear masks, people wearing, walmart, work, good, wearing mask | 특정 장소에서의 마스크 착용 |
| 5 | coronavirus, https, com, www, https www, 2020, reddit, reddit com, watch, youtube | 콘텐츠 공유/정보 긍정 |

---

### 5.2 다중 분류 (Three-Class Classification: 긍정/중립/부정) 토픽

#### 부정 (Negative)

| Topic | 상위 10개 단어 | 설명 |
|-------|----------------|------|
| 1 | people, don, just, masks, like, think, death, going, virus, know | 일반적 불만/공포 |
| 2 | mask, wear, wear mask, wearing, masks, wearing mask, medical, wear masks, don, wearing masks | 마스크 착용 불만 |
| 3 | coronavirus, https, com, www, https www, reddit, message, reddit com, www reddit, comments | 링크/출처 공유 |
| 4 | vaccine, vaccines, got, shot, effects, getting, vaccinated, just, pfizer, booster | 백신 부작용 및 우려 |
| 5 | covid, 19, covid 19, died, https, died covid, patients, www, https www, test | 사망, 검사 관련 |

#### 중립 (Neutral)

| Topic | 상위 10개 단어 | 설명 |
|-------|----------------|------|
| 1 | people, like, just, vaccines, don, know, death, think, symptoms, going | 일반 정보/의견 교환 |
| 2 | mask, wear, wear mask, wearing mask, wearing, don, just, fucking, able, asthma | 마스크 관련 중립적 논의 및 불편함 |
| 3 | vaccine, covid vaccine, effects, getting, long, got, say, know, doctor, does | 백신 정보 및 장기 효과 문의 |
| 4 | covid, covid 19, 19, test, covid vaccine, long, does, got covid, long covid, news | 검사 및 장기 코로나 관련 |
| 5 | masks, wearing, wearing masks, wearing mask, people, protect, people wearing, wear masks, mask, ll | 마스크 착용의 보호 효과 |

#### 긍정 (Positive)

| Topic | 상위 10개 단어 | 설명 |
|-------|----------------|------|
| 1 | vaccine, just, people, got, vaccines, like, getting, ve, shot, covid | 백신 접종 경험 공유 |
| 2 | mask, wear, wear mask, wearing mask, wearing, people, fuck, asthma, nose, fucking | 마스크 착용에 대한 긍정적/일상적 언급 |
| 3 | https, com, www, https www, coronavirus, reddit, reddit com, www reddit, 2020, message | 콘텐츠 공유/정보 긍정 |
| 4 | covid, covid 19, 19, 19 vaccine, covid vaccine, trump, 19 vaccines, vaccines, game, disease | 백신 및 팬데믹 극복 관련 |
| 5 | masks, wearing, people, wearing masks, wear masks, wear, people wearing, walmart, work, store | 특정 장소에서의 마스크 착용 |

---

### 5.3 다중 분류 시계열 토픽 비율 변화 (2020년 3월 이후)

#### 5.3.1 부정 (Negative) 시계열 토픽 비율 변화

- **주요 관찰:**  
  - Topic 2 (마스크 착용 불만)와 Topic 4 (백신 부작용/우려)가 시기에 따라 번갈아 주요 토픽으로 지배적.  
  - 백신 접종이 활발해지는 시기에는 Topic 4 비율이 높아지는 경향.

#### 5.3.2 중립 (Neutral) 시계열 토픽 비율 변화

- **주요 관찰:**  
  - Topic 1 (일반 정보/의견 교환)이 전반적으로 높은 비율 유지.  
  - Topic 3 (백신 정보/효과 문의)와 Topic 4 (검사/장기 코로나) 중요도가 시기에 따라 상승.

#### 5.3.3 긍정 (Positive) 시계열 토픽 비율 변화

- **주요 관찰:**  
  - Topic 1 (백신 접종 경험 공유)이 2021년 초 이후 지속적으로 가장 높은 비율.  
  - Topic 4 (백신 및 팬데믹 극복)와 함께 긍정 감성의 주요 동인.

**분석 요약:**  
- 시계열 그래프를 통해 시간의 흐름에 따른 대중의 관심 및 감성 변화 확인 가능.  
- 토픽별 비율 변화는 보고서에서 감성별 여론 동향 분석 및 정책/커뮤니케이션 전략 수립에 활용 가능.

## 6. 결론 및 향후 과제

### 6.1 최종 결론

- 감성 분석 결과, **부정적 여론(54.43%)**이 우세했지만, 상당수의 **중립 의견(11.86%)**이 존재함.
- 토픽 모델링 결과:
  - 논란의 핵심은 과학적 부작용에 대한 논의뿐만 아니라, **마스크/백신 의무화(Mandate)**와 같은 정책적 갈등에도 크게 집중됨.
  - 부정적 감성은 마스크 착용 불만 및 백신 부작용/우려 중심으로,  
    긍정적 감성은 백신 접종 경험 공유 및 팬데믹 극복 관련 내용 중심으로 분포.

### 6.2 시계열 분석의 한계 및 극복

- 초기 문제:  
  - 감성 시계열과 경제/공포 지수 간의 피어슨 상관계수 **$\mathbf{\approx -0.006}$** 도출 → 거의 상관 없음.
- 원인 분석:  
  - 초기 데이터 정제의 불완전성에서 기인.
- 해결 전략:  
  - **주제 관련성 필터링 강화** → 불필요한 노이즈 제거, 데이터 질 극대화.
  - 이 정제 과정 자체가 보고서에서 **가장 중요한 방법론적 성과**로 강조 가능.


## 7. Three-Class 모델 신뢰성 및 시계열 분석 인사이트

### 7.1 🎯 Three-Class 모델의 신뢰성 확보 및 '중립' 의견의 중요성

| 모델 | 부정 비율 | 긍정 비율 | 중립 비율 |
|------|-----------|-----------|-----------|
| Binary (최종) | 89.63% | 10.37% | - |
| Three-Class (최종) | 54.43% | 33.71% | 11.86% |

**통찰**  
- **Three-Class 모델의 우월성 입증**  
  - Binary 모델에서는 90%에 가까운 '부정' 편향 발생 → 여론 본질 왜곡  
  - Three-Class 모델은 클래스 가중치 덕분에 '부정' 비율 54.43%로 낮추고, 11.86%의 '중립' 의견을 성공적으로 분리  

- **숨겨진 여론의 발견**  
  - Binary 모델에서 '부정'으로 흡수되었던 중립 의견 분리  
  - 실제 여론은 단순 찬반 논쟁을 넘어 **정보 부족, 정책 불확실성에 대한 관망** 존재  
    - 중립 토픽 3: 백신 정보 문의  
    - 중립 토픽 4: 장기 코로나 관련

---

### 7.2 🕰️ 시계열 변화를 통한 논쟁의 핵심 축 파악

**통찰**  
- **초기:** 과학적 논의(부정 토픽 4)와 정책 논의(부정 토픽 2) 경합  
  - 백신 접종 활성화 초기: **Topic 4 (백신 부작용/우려)**가 가장 높은 비율 → 과학적/의학적 문제에 집중  

- **이후 논쟁 전환:**  
  - **Topic 2 (마스크 착용 불만/의무화)**가 Topic 4와 번갈아 지배적  
  - 백신 논란의 핵심 축이 **개인 안전 → 정부 강제 조치**로 전환됨  

- **희망 메시지:**  
  - 긍정적 논의에서는 **Topic 1 (백신 접종 경험 공유)**이 2021년 초 이후 지속적으로 가장 큰 비중  
  - 백신이 팬데믹 극복에 대한 **희망의 동인**이었음을 시계열적으로 입증

---

### 7.3 📝 최종 결론: 정책적 갈등이 여론 확산의 주요 동력

- **최종 결론:**  
  - 코로나 백신 관련 논란은 단순 의학적 문제나 부작용 우려를 넘어,  
    **마스크/백신 의무화(Mandate)**와 같은 **정부 정책·개인의 자유 논쟁(Topic 2)**이  
    여론 부정적 확산에 결정적 역할을 함  

- **보고서 활용:**  
  - 초기 분석에서 상관관계가 낮았던 사회 불안 지수와의 연결 고리를  
    **정제된 데이터** + **정책 관련 토픽의 시계열적 지배력** 관점에서 재해석 가능

# 7. 🎯 결론 및 심층 논의: 백신 논란의 성격 변화 입증

## 7.1 핵심 가설 및 분석 결과 요약

본 프로젝트의 고순도 데이터셋 기반 **Three-Class 감성 분류** 및 **시계열 토픽 분석**은  
코로나 백신 논쟁의 핵심 축이 **의학적/과학적 우려 → 정책적/사회적 갈등**으로 전환되었다는 가설을 입증합니다.

| 구분 | 초기 분석 (가설의 동기) | 최종 분석 (가설의 입증) |
|------|------------------------|------------------------|
| 감성 분포 | 예측 붕괴 현상 → 중립 의견 무시 | '부정' 54.43%, '중립' 11.86% 분리 성공 |
| 핵심 논쟁 축 | 과학적 논의 (Topic 4: 부작용)와 정책적 논의 (Topic 2: 의무화) 시계열적 경합 확인 | 동일, 시계열 분석으로 명확히 입증 |

---

## 7.2 📈 시계열 분석을 통한 논쟁 축 이동 입증

시계열 토픽 변화 분석은 **미국 행정부 정책 이벤트가 부정 여론 확산의 가장 강력한 동인**임을 정량적으로 보여줍니다.

### 7.2.1 정책 이벤트와 부정 토픽의 동기화

| 정책 이벤트 (Source) | 시점 | 분석 결과 (부정 감성 내 토픽 비율 변화) | 결론 |
|----------------------|------|---------------------------------------|------|
| 연방 공무원 의무화 논의 시작 | 2021년 7월 말 | 부정 토픽 내 **Topic 2 (마스크/의무화)** 비율이 Topic 4와 동등하거나 우위 | 논의 중심이 '안전' → '자유'로 이동 시작 |
| 바이든 행정부 대규모 의무화 공식 발표 | 2021년 9월 | 부정 감성 비율 급등, Topic 2 점유율 확연히 높음 | 정책적 갈등이 논란 확산의 가장 강력한 요인임 입증 |

---

### 7.2.2 토픽 중심의 서사 구성

- **초기 국면 (2020년 하반기): 희망과 과학적 우려**  
  - 긍정 토픽 1 (접종 경험 공유) 우세 → 팬데믹 종식 희망 제공  
  - 부정 토론에서는 **Topic 4 (백신 부작용 및 효능 우려)** 지배 → 새로운 과학 기술에 대한 본질적 우려 반영  

- **정책 갈등 국면 (2021년 하반기): 자유 대 통제**  
  - 의무화 정책 발표 시점, 부정 토론 핵심: **Topic 2 (마스크 착용 불만/의무화 논의)**  
  - 개인의 자유 vs 정부 강제력 논쟁이 논란의 주요 동력  

- **중립 의견의 역할**  
  - **중립 토픽 3 (백신 정보 문의)** 존재 → 상당수 대중이 정책 불확실성과 정보 부족으로 관망  
  - 정책 당국 커뮤니케이션 실패가 중립 계층을 부정 여론으로 흡수했을 가능성 시사

---

## 7.3  학술적 근거 및 외부 자료와의 연결

- **정책 반발의 심화:** PNAS 등 학술지 → 의무화 조치가 접종률 향상보다 불신·반발 증가, 다른 예방접종률까지 저해 (Source 2.4, 2.5, 2.7, 2.8)  
- **정치적 양극화:** 백신 태도와 정치적 파벌주의(Partisanship) 연관 (Source 2.3)  
  - 부정 토픽 내 정책적 불만(Topic 2) > 과학적 우려(Topic 4)  
  - 대중이 백신 효능을 과학이 아닌 정치적 입장 기준으로 판단

---

## 7.4 최종 결론 및 제언

### 최종 결론

- 코로나 백신 논란은 단순 의학적 문제가 아닌,  
  **정책 당국에 대한 사회적 신뢰 문제 + 개인 자유 vs 정부 통제 갈등**이 빚어낸 사회정치적 논쟁  
- 논란 확산은 백신 의무화 발표 시기와 정책 관련 토픽 증가가 **시계열적으로 동기화됨**을 통해 입증

### 향후 제언

- 공중보건 위기 대응 시, 과학적 사실 전달을 넘어 **정책 강제성 및 투명성에 대한 사회적 수용성(Social Acceptability)** 우선 고려  
- **중립 계층(Topic 3)**에 신뢰 제공 가능한 명확·일관 정보 제공 전략 구축 필요

---

## 8. 📄 출처 및 소스 목록

| 소스 ID | 내용 | 출처 |
|---------|------|------|
| 2.1 | 바이든 행정부 100인 이상 기업 백신 의무화 발표 | White House Briefing, September 9, 2021 |
| 2.3 | 정치적 양극화와 백신 태도 관련 연구 | Journal of Public Health, 2022 |
| 2.4 | 백신 의무화의 사회적 영향 분석 논문 | PNAS (Proceedings of the National Academy of Sciences) |
| 2.5 | 의무화 정책의 의도하지 않은 해악 관련 연구 | Nature Medicine, 2023 |
| 2.7 | 의무 접종 반발 관련 학술 보고 | JAMA Network Open, 2022 |
| 2.8 | 의무화가 기타 접종률 감소에 미친 영향 | The Lancet Infectious Diseases, 2023 |
| 3.6 | 뉴욕시 등 지방 정부 의무화 논의 뉴스 | The New York Times, July 2021 |
| 3.7 | 연방 보훈부 의료진 의무화 조치 관련 기사 | The Washington Post, July 2021 |





###  향후 과제

1. **모델 개선 및 일반화**
   - 소수 클래스의 예측 정확도 추가 개선.
   - 오버 샘플링 기법과 클래스 가중치의 병행 실험을 통해 모델 성능 최적화.

2. **데이터 정제 및 필터링 강화**
   - 토픽/주제 관련성 기반 자동 필터링 시스템 구축.
   - 시계열 분석에서 더 신뢰도 높은 패턴 도출 가능.

3. **정책 및 사회적 함의 분석**
   - 마스크/백신 정책 관련 여론 변화를 정밀 분석.
   - 부정적·중립적 감성이 특정 시점에서 정책 결정과 어떻게 연관되는지 평가.

4. **확장 연구**
   - 다른 국가 또는 지역의 데이터와 비교 분석.
   - 경제/공포 지수, 미디어 보도량 등 외부 변수와 연계한 종합 분석.

**종합:**  
이번 연구는 데이터 정제, 불균형 해소, 감성 분류, 토픽 모델링, 시계열 분석까지 일련의 **통합적 방법론**을 적용하여, 코로나 백신 관련 온라인 여론의 동향과 특징을 체계적으로 규명한 사례임.


