![header](https://capsule-render.vercel.app/api?type=soft&color=auto&height=300&section=header&text=vaccine%20Review💉&fontSize=90)

# 🦠 COVID Vaccine Controversy Analysis by BERT
**Multilingual BERT를 활용한 코로나 백신 여론 분석 프로젝트**

[![PyTorch](https://img.shields.io/badge/PyTorch-E34F26?style=flat-square&logo=PyTorch&logoColor=white)](https://pytorch.org/)
[![Hugging Face](https://img.shields.io/badge/Hugging%20Face-FFD21C?style=flat-square&logo=huggingface&logoColor=black)](https://huggingface.co/)
[![Python](https://img.shields.io/badge/Python-3776AB?style=flat-square&logo=Python&logoColor=white)](https://www.python.org/)

---

##  1. 개요 및 목표 (Overview & Thesis)

###  문제 정의 및 프로젝트의 의의
본 프로젝트는 COVID-19 팬데믹이 지나간 현재 시점에서,  
그동안 온라인 커뮤니티에 남겨진 댓글과 리뷰를 수집을 한 후 필요없는 데이터나 가비지 데이터를 정제한 후, 유의미한 정보만을 남기고 그것을 분석해 보는 것을 통해서 어떤 새로운 결론을 찾는 것을을 목표로 합니다.


- **핵심 목표**: 약 **11만 건의 리뷰 데이터**를 분석해  
  사회적 의무(Mandate) 논란이 **과학적 부작용보다 여론 확산에 더 큰 영향을 미쳤음**을 입증  
- **성공 지표 1.**: 2만 건의 수동 라벨링 데이터 기반 **validation accuracy 0.8>=** 달성 → 모델 신뢰성 확보
- **성공 지표 2.**:[Sun Woong Kim (2021). COVID-19 Fear Index and Stock Market. Journal of Convergence for Information Technology, 11(9), 84-93](https://www.kci.go.kr/kciportal/ci/sereArticleSearch/ciSereArtiView.kci?sereArticleSearchBean.artiId=ART002756191)  
  →  위 논문에 따르면 기존 연구에서는 코로나와 공포지수 간 관련성을 확인 가능하기 때문에 직접 얻는 데이터가 공포지수와 관련이 있으면 잘 정재했음을 증명할 수 있음

---

##  2. 데이터 수집 및 정제 과정 (극복의 스토리)

### 2-1. 데이터 확보 난관 및 최종 소스

> 본 프로젝트는 Naver, WebMD, Drugs.com 등 **6가지 크롤링 및 API 시도**를 거쳐  
> **Reddit API**를 중심으로 **98,277건의 고품질 데이터**를 확보했음.

| 소스 | 언어 | 수집 내용 | 결과 / 문제점 |
|------|------|-----------|----------------|
| **Naver 지식iN** | 🇰🇷 | Q&A (타이레놀/피임약) | 답변 32,000건 확보. 단, 백신 관련 내용 부족 및 질문 본문 확인 불가 |
| **Naver News 댓글** | 🇰🇷 | 뉴스 댓글 감성 분석 | 실패: Selenium CSS 선택자 불일치 |
| **DC Inside** | 🇰🇷 | 포럼 댓글 감성 분석 | 23,000건 확보. 비속어 및 백신 무관한 내용 다수 |
| **Reddit API (PRAW)** | 🇺🇸 | 댓글/게시글 (Top Posts) | ✅ 72,827건 확보 (핵심 데이터) |
| **Pushshift API** | 🇺🇸 | 과거 Reddit 데이터 | ❌ 403 Forbidden (서버 차단), 약 2,100건 확보 |
| **Drugs.com** | 🇺🇸 | 전문 리뷰 | ❌ 403 IP 차단, 약 1500건 확보 |
| **WebMD** | 🇺🇸 | 포럼 댓글 | ❌ 403 IP 차단, 약 16,800건 확보 |
| **HealthBoards** | 🇺🇸 | 포럼 댓글 | ❌ 404 오류, 약 3,100건 확보 |
| **Patient.info** | 🇺🇸 | 리뷰/포럼 | ❌ Requests 차단, 약 480건 확보 |

**최종 데이터 통합**
-  Reddit + WebMD + Pushshift + HealthBoards + Patient.info + Drugs.com 통합
-  총 **약 12만 건** (영문 및 한글 포함)
-  이후 **한국어 데이터 제거 → 영어 데이터만 남김**

-  최종 데이터: 약 10만8천건 (영문만 있음)

---

##  3. 데이터 전처리 파이프라인 (4단계)

###  단계 1: 구조적 노이즈 제거 (API Placeholder)

| 가비지 유형 | 문제 원인 | 적용 기법 | 처리 내용 |
|:-------------|:------------|:------------|:------------|
| `[deleted]`, `[No Content]` | Reddit API 삭제 게시물 | `pandas filtering` | 해당 문자열 포함 행 제거 |
| 짧은 잡담 (`lol`, `ok`) | 의미 없는 짧은 댓글 | `length check` | 20자 미만 / 5단어 미만 제거 |

---

### 🔹 단계 2: 언어적 노이즈 제거 (한국어 분리)

| 가비지 유형 | 문제 원인 | 적용 기법 | 처리 내용 |
|:-------------|:------------|:------------|:------------|
| 한글 포함 데이터 | Naver 크롤링 데이터 | `RegEx filtering` | 한글 비율 10% 초과 시 제거 |

---

###  단계 3: 형식적 노이즈 제거 (특수문자, URL 등)

| 가비지 유형 | 문제 원인 | 적용 기법 | 처리 내용 |
|:-------------|:------------|:------------|:------------|
| 특수문자/URL | 이모티콘, 반복 기호 | `RegEx ratio check` | 알파벳 외 문자 비율 40% 초과 제거 |
| 불용어 | the, a, is, covid, vaccine 등 | `Stopword list` | 핵심 키워드(`mask`, `mandate`) 중심으로 토픽 모델링 효율 개선 |

---
# 데이터 정제 및 라벨링 과정

이 프로젝트에서는 초기 데이터 약 **108,000건**에서 불필요/중복 데이터를 제거하여 **97,000건**으로 정제하였음.

이후 전체 데이터에서 **10% 무작위 샘플**을 추출하여 0은 부정 1은 긍적으로 직접 긍정/부정을 라벨링했음.  
- 샘플 내 **긍정/부정 비율**: 3.5 : 7.5  
- 추가적으로, 백신(`vaccine`), 코로나(`covid`), 부작용(`side effect`) 관련 언급 여부를 확인하여 True/False로 라벨링  
  - 결과: `False = 84%`, `True = 16%`  

이 데이터를 기반으로 **KoELECTRA 모델**을 활용한 머신러닝 예측을 수행하여, 전체 데이터에 대한 감정 분포와 관련 여부를 추정하였음.

---

## 1. 전체 감정 분포

| Predicted_Sentiment | Count   | Ratio (%) |
|--------------------|--------:|-----------:|
| Negative           | 74,954  | 76.27     |
| Positive           | 23,323  | 23.73     |

분석: 전체 데이터에서 부정적 의견이 약 **76%**로 다수를 차지하며, 긍정은 약 24%로 나타났다.

![긍부정 비율](1.png)

---

## 2. 관련 여부(True/False) 비율

| related_to_vaccine | Ratio (%) |
|------------------|-----------|
| False             | 83.29     |
| True              | 16.71     |

분석: 전체 데이터 중 백신/코로나/부작용 관련 언급이 있는 글은 약 **16.7%**에 불과함.

![True false 비율](2_2.png)

---

## 3. 모델 최종 성능

- ✅ **Accuracy (정확도)**: 0.8204  
- ✅ **F1 Score (균형 점수)**: 0.6438  

분석: 비교적 높은 정확도로 감성 예측 가능하며, F1 Score를 통해 소수 클래스(긍정) 예측 성능도 확인됨.

---

## 4. 시계열 분석: 부정 비율 변화

모델 예측 결과를 기반으로, **시간의 흐름에 따라 부정 감성 비율**이 어떻게 변화하는지 시각화함.  

- 시계열 도표를 통해 월별 또는 분기별 부정 비율 추세를 확인할 수 있음  
- 초기 코로나 확산기에는 부정 비율이 비교적 낮다가, 백신 논란과 정책 발표 시점에 상승하는 경향 확인  
- 장기적으로 부정 의견이 꾸준히 높은 수준을 유지하며, 정책 이벤트 및 사회적 이슈에 따라 변동이 관찰됨  



##  4. 토픽 모델링 (Topic Modeling)

### 코드 요약

| 단계 | 주요 내용 | 사용 라이브러리 / 함수 | 목적 |
|------|------------|--------------------------|------|
| 1️⃣ 데이터 로드 | `Real_Final.csv` 불러오기 | `pandas.read_csv()` | 데이터 준비 |
| 2️⃣ 전처리 | URL, 특수문자 제거 + 토큰화 + 표제어화 | `re`, `nltk` | 노이즈 제거 |
| 3️⃣ DTM 생성 | BoW 변환 및 희귀 단어 제거 | `gensim.Dictionary`, `doc2bow()` | 텍스트 수치화 |
| 4️⃣ LDA 학습 | `num_topics=10`, `passes=20` | `gensim.models.LdaModel` | 주요 주제 추출 |
| 5️⃣ 결과 해석 | 각 토픽 상위 10개 단어 분석 | `lda_model.print_topics()` | 핵심 주제 파악 |

---

###  LDA 토픽 모델링 결과 (K=10)

| 토픽 번호 | 주요 키워드 | 해석된 주제 | 핵심 논의 내용 |
|------------|--------------|--------------|----------------|
| **1** | state, government, school, free, business | 국가 정책 및 지역 행정 | 정부 정책, 학교 운영, 사업 규제 등 |
| **2** | people, doctor, health, risk, vaccination | 일반인 건강 및 의료 접근성 | 개인 건강, 접종 필요성, 위험 인식 |
| **3** | company, money, debt, share, loan | 경제적 영향 및 기업 금융 | 코로나가 금융·기업에 미친 영향 |
| **4** | like, dont, think, time, year | 개인의 생각 및 감정 표현 | 일상적 감정, 의견 공유 중심 |
| **5** | mask, wear, face, protect, approved | 마스크 착용 및 방역 조치 | 마스크 의무화, 보호 장비 논의 |
| **6** | side, country, trump, american, world | 정치적 갈등 및 국가 상황 | 미국 중심의 정치·사회적 갈등 |
| **7** | insurance, cost, headache, paid, market | 비용 및 보험 문제 | 의료비, 보험, 시장 변동성 |
| **8** | vaccine, covid, effect, virus, booster | 백신 효능 및 과학적 논의 | 백신 효과, 바이러스, 부스터샷 |
| **9** | week, work, month, sick, day | 일상 및 근무 환경 변화 | 재택근무, 격리 등 생활 패턴 변화 |
| **10** | post, read, comment, source, link | 정보 공유 및 커뮤니티 소통 | 게시글·링크를 통한 정보 교환 |

---

###  종합 시사점
- **토픽 3 & 7**: 경제적 영향(기업 vs. 개인 비용)이 주요 논의 축  
- **토픽 5 & 8**: 방역 조치 및 백신 효능 관련 과학적 논의  
- **토픽 6**: 정치적 분열과 국가적 감정이 백신 담론에 영향  
- **토픽 10**: 신뢰할 수 있는 정보 출처에 대한 사회적 갈망 반영


## 결론과 한계점 
- **사회적 논란의 핵심 축**은 과학적 부작용보다 **정치·경제·사회적 이슈**에 집중.
- **LDA와 빈도 분석** 결과가 서로 일치하며, **마스크·백신·정부정책·경제영향**이 공통 핵심 키워드로 등장함 
- 이는 코로나 백신 논란이 단순한 의학적 문제를 넘어, **사회적 신뢰와 정책적 갈등의 문제**였음을 시사한다.
따라서 일반적으로 사회적 신뢰와 정책적 갈등이 심할때 사회 불안지수, 경재 불안지수가 높아지기에 두 그래프를 X을 시간을 기준으로 비교해 보기로 했다
시계열 데이터를 따라서 시간이 변함에 따라 부정의 비율이 어떻게 나오는지 도표를 통해서 확인해 봤다.

![시계열에 따른 공포지수](fear.png)
![시계열에 따른 부정비](4.png)

## 두 그래프 비교 결과

- **피어슨 상관계수**: -0.006  
- **DTW(Dynamic Time Warping) 거리**: 1280

  ![시계열에 따른 부정비](5.png)

분석:  

- 피어슨 상관계수 ≈ -0.006은 0에 매우 가까움 → 두 그래프의 선 모양은 거의 상관이 없음  
  - 즉, 한 그래프가 올라가면 다른 그래프가 올라가거나 내려가는 경향이 거의 없다는 의미  
- DTW는 두 시계열의 형태 차이를 측정하는 지표로, 값이 클수록 패턴이 다름을 의미  
  - 1280 정도면 두 그래프의 모양이 상당히 다르다는 것을 보여줌  

💡 추가 관찰:

- 코로나 팬데믹이 과거가 된 시점에서, 이 결론은 다소 **예상 가능한 결론**임  
- 관련 문헌 참고:  
  - [Sun Woong Kim (2021). COVID-19 Fear Index and Stock Market. Journal of Convergence for Information Technology, 11(9), 84-93](https://www.kci.go.kr/kciportal/ci/sereArticleSearch/ciSereArtiView.kci?sereArticleSearchBean.artiId=ART002756191)  
  → 기존 연구에서는 코로나와 공포지수 간 관련성을 확인함  
- 그러나 직접 뽑아서 분석한 그래프에서는 수치상에서 **관련성이 거의 없는 것으로 나타남**  

추가 실사례 확인:

- 전체 데이터에서 무작위 1,000건 샘플링 후 수작업 검토 결과  
  - `False`로 분류된 경우에도 **코로나/백신 관련 코멘트가 다수 존재**  
  - 긍정/부정 분류가 부정으로 나왔지만 **중립적이거나 정치적 논의**가 포함된 경우가 많음  

---

## 결론

- 초기 데이터 전처리 과정에 **문제가 존재**함을 확인  
- 이에 따라 **데이터 전처리 방식을 처음부터 재검토**하고, 주제 관련성 필터링을 강화하기로 결정  
- 이 과정이 이후 모델 학습 및 시계열 분석의 정확성을 높이는 **핵심 방법론적 성과**로 연결됨


---


## 1️⃣ 다시 한번 개요 및 목표 (Overview & Thesis)

### 🎯 문제 정의 및 프로젝트의 의의  
본 프로젝트는 **COVID-19 팬데믹 기간 동안 온라인 커뮤니티에 남겨진 약 11만 건의 원천 데이터**를 확보하고,  
**합리적이고 단계적인 정제 과정**을 거쳐 최종 분석의 **신뢰성을 극대화**하는 것을 최우선 목표로 삼았다.

- **핵심 목표:**  
  데이터 정제 과정을 통해 확보된 **고순도(High-purity) 데이터셋**을 분석하여 새로운 결론을 찾는 것.




---

##  다시 한번 더  데이터 전처리 파이프라인 (노이즈 제거의 합리성)

### 🧠 논리적 동기: 초기 LDA 결과의 문제점  
초기 원천 데이터를 최소 전처리 후 LDA로 분석한 결과,  
**URLs, 감탄사, 정치인 이름 등 가비지 토픽**이 다수 등장 → 고노이즈 데이터로 판정.  
이에 따라 **4단계의 정제 파이프라인**을 설계함.

---

### 🔹 단계 1: 구조적 노이즈 제거 (API Placeholder 및 길이 필터링)

| 가비지 유형 | 적용 기법 | 처리 내용 | 근거 |
|--------------|------------|------------|------|
| [deleted], [No Content] | pandas filtering | 삭제된 게시물 제거 | 의미 없는 구조적 잡음 제거 |
| 짧은 잡담 (lol, ok 등) | length check | 20자 미만 / 5단어 미만 텍스트 제거 | 학습 아웃라이어 제거, 모델 견고성 향상 |

---

### 🔹 단계 2: 언어적 노이즈 제거 (비영어 비율 10% 기준)

| 가비지 유형 | 적용 기법 | 처리 내용 | 근거 |
|--------------|------------|------------|------|
| 한글/타언어 포함 | RegEx filtering | 비영어 비율 10% 초과 시 제거 | 언어적 순도 향상 및 학습 효율 극대화 |

---

### 🔹 단계 3: 형식적 노이즈 제거 (특수문자 및 불용어)

| 가비지 유형 | 적용 기법 | 처리 내용 | 근거 |
|--------------|------------|------------|------|
| 특수문자 / URL | RegEx ratio check | 알파벳 외 문자 40% 초과 제거 | 인코딩 오류 및 스팸 방지 |
| 불용어 | Stopword list | the, a, is, covid, vaccine 등 제거 | 핵심 단어 가중치 향상 및 주제 분리도 개선 |

---

## 4️ 분석의 엄밀성: 최종 주제 관련성 필터링 (Analytical Refinement)

###  단계 4: 주제 무관 데이터 제거 (Relevance Filtering)
물리적 정제 이후에도 여전히 ‘like, think, time’ 등의 **비주제적 단어**가 남아 있었기 때문에,  
**COVID-19 관련 키워드**를 포함한 데이터만 남기도록 필터링했음음.


이후, 전처리 전 데이터에서 떠오르는 토픽들이 코로나나 백신과 너무 관련이 없다는 것을 확인하고 키워드를 골라서 그 키워드가 있는 댓글들은 True/ 없는 경우를 false 분류하고 false 댓들들은 삭제하는 전처리를 진행했다.

#  주제 관련성 키워드 분류 코드 요약

| 구분 | 주요 내용 | 사용 라이브러리 / 함수 | 목적 및 중요성 |
|------|------------|--------------------------|----------------|
| **1단계: 데이터 준비** | `Real_Final.csv` 파일을 로드하고, 결측값을 제거하여 데이터의 무결성을 확보합니다. | `pandas.read_csv()`, `dropna()` | 분석 대상 텍스트 데이터를 정제하고, 초기 데이터 건수를 확인하여 분석의 기준점을 설정합니다. |
| **2단계: 주제 정의 및 확장** | COVID-19 및 백신 관련 핵심 키워드 20여 개를 명시적으로 정의합니다.<br>(예: *vaccine, covid, side effect, mask, booster, mrna* 등) | `Python list` | 논란 분석에 필요한 핵심 주제의 범위를 구체적으로 한정합니다. 정의된 키워드가 포함된 텍스트만 분석 대상으로 삼아 효율성을 높입니다. |
| **3단계: 이진 분류 로직** | 각 텍스트를 소문자화한 후, 정의된 키워드 중 하나라도 포함되어 있는지 여부를 확인하여 **True(관련 있음)** 또는 **False(관련 없음)**으로 분류합니다. | `str.lower()`, `any()` | 데이터셋을 **‘주제 관련 데이터’**와 **‘주제 무관 데이터’**로 구분하여 필터링 기준을 설정합니다. 이후 논란 분석 등 핵심 분석에 집중할 수 있는 기반을 마련합니다. |
| **4단계: 결과 분석 및 저장** | 분류된 결과를 기반으로 관련 데이터의 건수와 비율을 산출하고, 최종적으로 `is_related_topic` 컬럼이 포함된 새로운 CSV(`FINAL_DATA_CLEANED_CLASSIFIED_V2.csv`)로 저장합니다. | `df.to_csv()` | 분류된 데이터의 통계적 분포를 확인하고, **후속 심층 분석(LDA·감성 분석 등)**의 기반 데이터를 확정합니다. |
---

### 보고서 활용 및 분석적 시사점

1. **분석 범위의 명확화**  
   전체 데이터(약 98,277건) 중에서 **핵심 키워드 기반 필터링**을 통해  
   COVID-19 및 백신 관련 텍스트만 선별함으로써,  
   이후 분석(예: 토픽 모델링, 감성 분석)이 **핵심 논의 중심 데이터에 집중**되도록 함.  
  

2. **키워드 기반 분류의 한계와 보완 (Feat. LDA)**  
   - 키워드 미포함 관련 텍스트 누락, 키워드 포함 비관련 텍스트 포함 등 **오분류 가능성** 존재  
   - 하지만, **LDA 토픽 모델링 결과를 바탕으로 핵심 키워드를 확장 정의**하여  
     이 단계를 **전략적 필터링 과정**으로 활용할 수 있음  
     - 즉, “LDA로 주제 후보를 도출 → 본 코드로 해당 주제를 대표하는 텍스트 선별”의 **2단계 분석 체계**로 설명 가능

---

## 핵심 키워드 정의

```python
KEYWORDS = [
    'vaccine', 'covid', 'coronavirus', 'side effect', 'adverse', 'pfizer', 'moderna',
    'booster', 'jab', 'shot', 'vax', 'myocarditis', 'astrazeneca', 'janssen',
    'symptoms', 'mandate', 'mask', 'masked', 'unvaccinated', 'vaxxed', 'unvaxxed',
    'hospital', 'death', 'long covid', 'long-covid', 'spike protein', 'mrna'
]
```
**다음과 같이 정한 이유**: 위와 같이 정의 한 이유는 앞서 실패했던 전처리 과정에서 실제로는 코로나와 관련이 있었던 댓글들 대부분이 포함하고 있었던 키워드들을 경험적으로 선정하였다.
---

###  필터링 결과

| 결과 구분 | 건수 | 비율 | 통찰 |
|------------|------|------|------|
| ✅ True (관련 있음) | 23,939 | 23.6% | 최종 분석용 고순도 데이터 |
| ❌ False (무관함) | 75,338 | 76.4% | 잡담, 뉴스 등 제거 |

![True false 비율 ](6.png)

--->

false는 모두 지우고 True만 남기여서 FINAL_DATA_FILTERED_TRUE.csv로 저장.
---

## 검증
이 FINAL_DATA_FILTERED_TRUE.csv 데이터가 과연 정말로 코로나 백신 대이터로써 좋은 데이터인지 검증하기 위해 또 10%(약 2,200개)를 무작위로 뽑아 직접 읽어보면서 코로나와 정말로 관련이 있는지 확인하는 작업을 거쳤다.

결과를 보니 대부분 정말로 코로나와 관련이 있는 데이터였지만, 종종 의료관련업계 사람들이 코로나 백신에 대한 자신의 의견이 없이 여론이 아닌 논문의 링크나 기사의 링크는 보내는 경우가 종종 보였기 때문에 [ex) See the rest of the article by infectious disease expert [Dr. Siouxsie Wiles](https://en.wikipedia.org/wiki/Siouxsie_Wiles) (PhD from Oxford) [here](https://thespinoff.co.nz/society/09-03-2020/the-three-phases-of-covid-19-and-how-we-can-make-it-manageable/). 이런식으로]  추가적으로 FINAL_DATA_FILTERED_TRUE.csv 데이터에서 그런 데이터를 지우는 전처리를 진행했다. 또한 앞서 나온 토픽 모델링에서 그런 경우가 적지 않게 나왔기 때문에 이 가비지 데이터를 없에는 것이 꽤나 의미할꺼라 예상된다. 
#결과
✅ 원본 데이터 (23939 행) 불러오기 완료.
✅ 클리닝 완료. 총 1010개의 행이 삭제되었습니다.
🎉 클리닝된 데이터 (22929 행)가 'FINAL_DATA_ROWS_DELETED.csv'(으)로 성공적으로 저장되었습니다.

다만, 기사를 인용하면서도 단순 기사 공유가 아닌 경우에도 있을 수 있을 것 같아서 1010개를 직접적으로 확인해 보고 쓸 수 있는 데이터라고 판단한 423개는 다시 추가하여 'FINAL_DATA_ROWS_DELETED_2.csv'(23,352개)로 저장하였다.


> ✔️ **결론:** 데이터의 양보다 질을 선택 — 감성 분석의 초점이 백신 논란의 본질에 집중되도록 보장
>
> 이 정제된 FINAL_DATA_ROWS_DELETED.csv를 사용할 것이다

---


## 5. 지금까지 전처리한 데이터 단어 빈도 분석 (Word Frequency Analysis)

### 코드 요약

| 단계 | 주요 내용 | 사용 라이브러리 | 목적 |
|------|------------|----------------|------|
| 1️⃣ 데이터 로드 및 전처리 | 불용어 제거, 표제어 추출 | `pandas`, `re`, `nltk` | 분석 정확도 향상 |
| 2️⃣ 단어 빈도 계산 | 전체 문서에서 단어 집계 | `collections.Counter` | 주요 단어 정량 분석 |
| 3️⃣ 상위 50개 키워드 추출 | `most_common()` 사용 | `Counter` | 핵심 관심사 파악 |

> **LDA vs. 단어 빈도 비교**  
> - LDA: 단어 간 *연관성* 기반 주제 도출  
> - 단어 빈도: 단순 *언급 횟수* 기반 주요 키워드 파악  
> - 두 결과를 교차 검증하여 분석 신뢰도 강화

### 주요 단어 결과
1. people  
2. covid  
3. vaccine  
4. get  
5. dont  
6. mask  

> 분석 해석:  
> - 2위와 3위를 통해 코로나 관련 논의가 활발함  
> - 1위는 일반 대중에 대한 논의  
> - 4,5,6위를 통해 부정적 의견 및 마스크 관련 언급 많음

> - ![지금까지 전처리한 데이터 단어 빈도 분석](7.png)

---

### 데이터 라벨링
- 전체 데이터의 10% (약 2,100개) 샘플링 후 수동 라벨링 진행
- 이진 분류와 삼분류 동시에 수행

**이진 분류 결과 비율**

| sentiment_binary | 비율 (%) |
|-----------------|----------|
| 부정            | 81.20    |
| 긍정            | 18.80    |

**삼분류 결과 비율**

| sentiment_three | 비율 (%) |
|----------------|----------|
| 부정           | 63.51    |
| 긍정           | 18.99    |
| 중립           | 17.60    |

![True false 비율 ](8.png)
![True false 비율 ](9.png)


---

## Ⅰ. 데이터 개요 및 탐색적 분석 (EDA)
**목표:** 댓글 데이터에서 자주 등장하는 단어 파악 및 트렌드 분석  

### 1. 전처리 및 주요 단어 추출
- 소문자 변환, URL 제거, 비알파벳 문자 제거  
- 불용어(Stopwords) 및 3글자 미만 단어 제거  
- 결과물: `top_words_frequency.png` (상위 20개 단어 빈도)

### 2. 시계열 단어 빈도 분석
- 상위 5개 단어를 월별 상대적 빈도로 계산  
- 결과물:  
  - `word_frequency_over_time.png` (월별 빈도 꺾은선 그래프)  
  - `monthly_word_frequency_ts.csv` (월별 빈도 데이터)

---

## Ⅱ. 딥러닝 학습 데이터 준비 및 라벨링 (Human Annotation)
**목표:** KoElectra 학습용 고품질 수동 라벨링 데이터 준비

### 1. 샘플링 및 인코딩 문제 해결
- 원본 데이터 약 22,939개 중 10% 샘플링 (약 2,294개)  
- 깨진 문자(Mojibake) 문제 해결: `pd.read_csv(encoding='utf-8' 또는 'cp949')`  
- 시간 정보 포함하여 라벨링 파일 생성:
  - `KOEL_labeled_binary.csv` (긍정/부정)  
  - `KOEL_labeled_three.csv` (긍정/부정/중립)

---

## Ⅲ. KoElectra 모델 학습 및 평가 (Deep Learning)
**목표:** KoElectra로 Binary 및 Three-Class 감성 분류 수행

### 1. 학습 환경 및 모델 설정

| 항목 | 설정 내용 | 비고 |
|------|-----------|------|
| 모델 | KoElectra (monologg/koelectra-base-v3-discriminator) | 한국어 NLP 모델 |
| 평가 지표 | Valid Accuracy | 모델 일반화 성능 측정 |
| 데이터 분리 | 라벨링된 샘플 중 90% 학습, 10% 검증 | 신뢰성 있는 Valid Accuracy 확보 목적 |
| 코드 수정 | `eval_steps=100`, `save_steps=100` | TrainingArguments 오류 해결 및 환경 맞춤 |

### 2. 독립적 학습 작업

| 작업 | 데이터 파일 | 클래스 라벨 | 출력 파일 |
|------|------------|------------|-----------|
| Binary | KOEL_labeled_binary.csv | 부정:0, 긍정:1 | predicted_binary.csv |
| Three-Class | KOEL_labeled_three.csv | 부정:0, 중립:1, 긍정:2 | predicted_three.csv |

### 3. 최종 기대 결과
- Valid Accuracy 값 (Binary 및 Three-Class)  
- `predicted_binary.csv`: 전체 원본 데이터에 긍정/부정 라벨 추가  
- `predicted_three.csv`: 전체 원본 데이터에 긍정/부정/중립 라벨 추가




# KoElectra 감성 분석 모델 학습 결과

## Ⅰ. 학습 로그 요약

### 1. Binary 모델 (긍정/부정, 클래스 수: 2)
- 학습 데이터: `KOEL_labeled_binary.csv`
- Epoch: 2
- Train Loss:
  - Epoch 1: 0.4909
  - Epoch 2: 0.4813
- ✅ Validation Accuracy: 0.8126
- 예측 결과: `predicted_binary_2.csv`


### 2. Three-Class 모델 (긍정/중립/부정, 클래스 수: 3)
- 학습 데이터: `KOEL_labeled_three.csv`
- Epoch: 2
- Train Loss:
  - Epoch 1: 0.9314
  - Epoch 2: 0.9033
- ✅ Validation Accuracy: 0.6362
- 예측 결과: `predicted_three_2.csv`

---

## Ⅱ. 최종 결과

### 1. Binary 분류 결과
| 감성 | 개수 | 비율 (%) |
|------|------|----------|
| 부정 | 22,348 | 97.42 |
| 긍정 | 591 | 2.58 |
| 합계 | 22,939 | 100 |

![Binary 분류 결과 ](10.png)

- **해석:**  
Binary 모델은 '부정' 예측이 압도적으로 높음  
→ 학습 데이터의 심각한 클래스 불균형(부정 81.2% vs 긍정 18.8%)이 원인

---

### 2. Three-Class 분류 결과
| 감성 | 개수 | 비율 (%) |
|------|------|----------|
| 부정 | 20,379 | 88.84 |
| 긍정 | 2,551 | 11.12 |
| 중립 | 9 | 0.04 |
| 합계 | 22,939 | 100 |

![Three-Class 분류 결과 ](11.png)

- **해석:**  
Three-Class 모델도 '부정' 편향 존재  
- '중립' 클래스 예측 거의 없음  
- 이는 학습 데이터에서 다수 클래스의 비율이 높고, Epoch가 짧아 소수 클래스 학습이 부족했기 때문

---

## Ⅲ. 문제 원인 분석

### 1. 클래스 불균형 (Class Imbalance)
| 분류 | 라벨 | 개수 | 비율 (%) | 매핑 숫자 |
|------|------|------|----------|-----------|
| Binary | 부정 | 1,863 | 81.2 | 0 |
| Binary | 긍정 | 431 | 18.8 | 1 |
| Three-Class | 부정 | 1,457 | 63.5 | 0 |
| Three-Class | 긍정 | 431 | 18.8 | 2 |
| Three-Class | 중립 | 406 | 17.7 | 1 |

- 모델은 학습 데이터의 다수 클래스만 예측  
→ **예측 붕괴(Prediction Collapse)** 또는 **과도한 편향 학습(Bias Learning)** 현상 발생

### 2. 짧은 학습 시간
- 현재 Epoch=2 → 모델이 소수 클래스 특징 학습 부족

---

## Ⅳ. 해결책 및 권장 조치

### 1️⃣ 에포크 수 증가
- Epoch 2 → **5~10 Epoch**로 학습 시간 연장  
- 소수 클래스(긍정/중립) 특징 학습 가능

### 2️⃣ 클래스 가중치 적용
- 손실 함수(CrossEntropyLoss)에 클래스 가중치 전달  
- '부정' 가중치 낮추고, '긍정'과 '중립' 가중치 높임  
- 모델이 소수 클래스를 놓치지 않도록 강제

```python
# 예시 (PyTorch)
import torch.nn as nn
class_weights = torch.tensor([0.5, 2.0, 2.0]).to(device)  # 부정, 중립, 긍정
criterion = nn.CrossEntropyLoss(weight=class_weights)
```



---

## 1. 데이터 레벨 전략: 클래스 균형 맞추기

- 데이터셋 자체의 불균형을 해결하여 모델이 다수 클래스에만 집중하는 것을 방지하기로 함함.

### 1) 오버 샘플링 (Oversampling)

- **원리:** 부족한 소수 클래스(긍정, 중립)의 샘플을 복제하거나, 기존 샘플을 바탕으로 새로운 유사 샘플을 생성(예: SMOTE 기법)하여 다수 클래스(부정)의 수와 비슷하게 맞춤  
- **목표:** 학습 데이터의 클래스 비율을 1:1에 가깝게 만들어 모델이 모든 클래스에 공평하게 학습하도록 함

---

## 2. 모델 레벨 전략: 손실 함수 조정

- 학습 과정(손실 함수, Loss Function)에 가중치를 부여하여 소수 클래스 예측 실패에 더 큰 패널티를 줌

### 3) 클래스 가중치 적용 (Class Weighting)

- **원리:** PyTorch의 `CrossEntropyLoss`는 `weight` 인자를 통해 각 클래스별 가중치 설정 가능  
- **설정 예시:**  
  - 다수 클래스(부정, 0): 낮은 가중치 (예: 0.2)  
  - 소수 클래스(긍정, 1 / 중립, 2): 높은 가중치 (예: 1.5 ~ 3.0)  
- **효과:** 모델이 긍정/중립을 부정으로 잘못 예측할 경우, 평소보다 큰 손실(Loss)을 발생시켜 모델이 해당 오류를 줄이도록 강하게 유도

---

## 💡 최종 분석 및 보고서 활용 제언

- **클래스 불균형 영향:**  
  - Binary 모델: '부정' 97.42%  
  - Three-Class 모델: '부정' 88.84%  
  → 수동 라벨링 데이터의 극심한 불균형(KOEL_labeled_binary.csv 부정 81.2%)이 학습 모델에 그대로 반영됨

- **Binary vs. Three-Class 비교:**  
  - Binary: '부정' 클래스에 예측 붕괴 → 분류기 가치 낮음  
  - Three-Class: '부정' 편향 여전하지만, **긍정 예측 11.12%** 수행 → Binary보다는 분별력 있음  
  - 단, **중립 예측 0.04%** → 사실상 무시

- **향후 과제:**  
  - 보고서에서 "모델 예측 편향을 줄이기 위해 **오버 샘플링**과 **클래스 가중치 적용** 같은 불균형 해소 기법 필수"라고 논의 가능

- **예측 결과 파일:**  
  - `predicted_binary_3.csv`  
  - `predicted_three_3.csv`  
  → 원본 댓글과 함께 확인하여 감성 분류 특징 분석 가능


 # 오버 샘플링(Oversampling) & 클래스 가중치(Class Weighting) 병행 전략

---

## 🔹 두 기법 병행의 시너지 효과

| 기법 | 해결 레벨 | 역할 및 효과 |
|------|-----------|--------------|
| 오버 샘플링 | 데이터 레벨 | 학습 데이터의 양적 균형을 맞춤. 모델이 소수 클래스의 다양한 패턴을 더 자주 접할 수 있음 |
| 클래스 가중치 | 모델 레벨 | 오류 패널티의 중요성을 조정. 소수 클래스를 잘못 예측했을 때 가장 큰 패널티를 주어 모델이 소수 클래스의 분류에 집중하도록 강제 |

**시너지:**  
오버 샘플링으로 소수 클래스의 '데이터 부족' 문제를 해결하고, 클래스 가중치로 '학습 중요도'를 높여 불균형 문제를 구조적으로 해소하는 이중 방어 전략

---

## ⚠️ 주의사항: 과적합(Overfitting) 위험 관리

- **위험 요인:**  
  오버 샘플링(특히 SMOTE)으로 생성된 합성 데이터가 클래스 가중치 때문에 높은 중요도로 학습됨 → 모델이 합성 데이터의 노이즈까지 외워버릴 수 있음

- **해결책:**  
  - Validation Accuracy 철저히 모니터링  
  - Training Accuracy/Loss와 Validation Accuracy/Loss가 과도하게 벌어지면 즉시 학습 중단 (조기 종료)

- **단계적 적용 권장:**  
  1. 먼저 **클래스 가중치만 적용** → 효과 측정 (구현 비교적 쉬움)  
  2. 가중치만으로 성능 개선이 미미하면 **오버 샘플링 추가** → 시너지 효과

---


### 보고서 구성 제안

| 섹션 | 내용 |
|-------|------|
| I. 불균형 분석 | 수동 라벨링 데이터의 극심한 클래스 불균형(부정 80% 이상) 제시 |
| II. 초기 모델 한계 | Epoch 2 학습 시 Predicted Label이 모두 '0'으로 나오는 예측 붕괴(Collapse) 현상 보고 |
| III. 불균형 해소 전략 | 클래스 가중치와 SMOTE 오버 샘플링 결합 적용 명시 |
| IV. 최종 결과 비교 | 가중치/샘플링 적용 후 Binary 및 Three-Class 모델 Valid Accuracy를 초기 모델과 비교, 성능 개선 효과 수치로 제시 |



 # 감성 분석 모델 개발 과정 및 불균형 해소 전략 요약

본 문서는 코로나 백신 관련 댓글 데이터에 대한 KoElectra 기반 감성 분류 모델 개발 과정에서 발생한 핵심 문제점과 이를 해결하기 위해 적용된 고급 전략을 요약합니다.

---

## I. 초기 데이터 불균형 분석 (Baseline Imbalance)

- **문제점:** 모델 학습의 기반이 된 수동 라벨링 샘플(10% 추출 데이터)은 심각한 클래스 불균형 내포
- **극심한 클래스 불균형:** 라벨링된 데이터 중 '부정' 클래스가 80% 이상 차지
- **영향:** 모델이 긍정/중립 등 소수 클래스의 패턴을 충분히 학습하지 못하고, 다수 클래스('부정')만 예측하도록 편향될 위험

---

## II. 초기 모델의 한계 및 예측 붕괴 현상 보고

- **초기 모델 설정:** Fine-tuning 에포크 수 2회 적용
- **결과:** 원본 데이터 전체에 대한 predicted_label이 **모두 '0' (부정)**으로 출력 → 예측 붕괴(Prediction Collapse)
- **결론:** 모델이 손실(Loss)을 최소화하기 위해 소수 클래스의 특성을 무시하고, 다수 클래스만 예측하도록 편향 학습 수행

---

## III. 불균형 해소 전략: 클래스 가중치 및 에포크 강화 적용

초기 모델의 예측 붕괴 현상을 극복하고 모델 분류 능력 개선을 위해 다음 전략 적용:

### 1. 클래스 가중치 (Class Weighting) 적용

- **목표:** 소수 클래스 오분류에 대한 오류 패널티 증대 → 소수 클래스 학습 중요도 향상
- **구현:**  
  - 학습 데이터 클래스 분포 파악  
  - 역빈도 기반 클래스 가중치(weights_tensor) 계산  
  - PyTorch `CrossEntropyLoss` 객체에 `weight` 인자로 전달
- **효과:** 긍정/중립 예측 실패 시 손실 증가 → 모델이 소수 클래스 예측 놓치지 않도록 강제

### 2. 에포크(Epoch) 수 증가

- **목표:** 클래스 가중치와 함께, 모델이 복잡한 손실 함수 기반 소수 클래스 특징을 충분히 탐색
- **구현:** 학습 에포크 2회 → 5회로 증가

### 3. 오버 샘플링(SMOTE) 우회 결정

- **논의:** 텍스트 데이터에 SMOTE 적용 시 의미론적 손실 가능
- **결정:** SMOTE 대신 클래스 가중치 + 에포크 강화 전략 결합 적용

---

## IV. 최종 결과 비교 (Valid Accuracy 및 성능 개선)

불균형 해소 전략 적용 후 Binary 및 Three-Class 모델 성능 개선:

| 모델 | 초기 모델 Valid Accuracy | 최종 Valid Accuracy (가중치/에포크 적용 후) | 주요 개선 효과 |
|------|-------------------------|-----------------------------------------|----------------|
| Binary (긍/부정) | 미측정 또는 매우 낮음 (예측 붕괴) | (획득된 수치 입력) | 예측 편향 해소, 긍정 클래스 분별력 확보 |
| Three-Class (긍/부/중립) | 미측정 (예측 붕괴) | (획득된 수치 입력) | 중립 클래스 예측 능력 확보, 전반적 정확도 향상 |

- **결론:**  
  클래스 가중치 및 에포크 강화 적용으로 다수 클래스로의 예측 붕괴 극복, Valid Accuracy 개선 → 신뢰성 있는 감성 분석 결과 도출 가능
- **활용:** 최종 보고서에서는 이 개선된 결과를 기반으로 원본 데이터의 감성 트렌드 분석

# 클래스 가중치 기반 감성 분석 모델 학습 및 결과 요약

## 1. 이진 분류 (Binary) 가중치 비중 분석

| 항목 | 계산 과정 | 결과 |
|------|-----------|------|
| Original Training Distribution | 부정(0): 1,490개, 긍정(1): 345개 | 총 1,835개 |
| 클래스 0 (부정) | $W_0 = 1835 / (2 \times 1490)$ | 0.6158 (낮음) |
| 클래스 1 (긍정) | $W_1 = 1835 / (2 \times 345)$ | 2.6594 (매우 높음) |

### 🔍 의미 해석
- **부정 (0.6158):** 다수 클래스 → 오분류 패널티 약 40% 낮춤  
- **긍정 (2.6594):** 소수 클래스 → 오분류 패널티 2.66배 증가, 긍정 예측 실패 억제

---

## 2. 삼분류 (Three-Class) 가중치 비중 분석

| 항목 | 계산 과정 | 결과 |
|------|-----------|------|
| Original Training Distribution | 부정(0): 1,165개, 중립(1): 325개, 긍정(2): 345개 | 총 1,835개 |
| 클래스 0 (부정) | $W_0 = 1835 / (3 \times 1165)$ | 0.5250 (가장 낮음) |
| 클래스 1 (중립) | $W_1 = 1835 / (3 \times 325)$ | 1.8821 (높음) |
| 클래스 2 (긍정) | $W_2 = 1835 / (3 \times 345)$ | 1.7729 (높음) |

### 🔍 의미 해석
- **부정 (0.5250):** 다수 클래스 → 오분류 패널티 약 50% 낮춤  
- **중립 (1.8821) & 긍정 (1.7729):** 소수 클래스 → 오분류 패널티 약 1.8~1.9배 증가  
- 가장 적은 '중립' 클래스에 가장 높은 가중치 부여 → 모델이 놓치지 않도록 강제

---

## 💡 최종 결론
- 역빈도 기반 클래스 가중치 적용 덕분에 모델이 예측 붕괴를 극복
- Binary 모델 Valid Accuracy: **78.43%**  
- Three-Class 모델 Valid Accuracy: **51.63%**  

**Binary 모델 (78.43%) — 양호한 결과**

| 항목 | 수치 | 의미 |
|------|------|------|
| **Valid Accuracy** | **78.43%** | 모델이 학습하지 않은 데이터에서 8개 중 약 6~7개를 정확히 분류함 |

**배경:**  
- 클래스 가중치(Class Weight)를 적용하기 전, 모델은 **초기 예측 붕괴 현상(0% 예측)** 을 겪음  
- 이후 **클래스 가중치 적용**으로 편향을 극복하며 유의미한 성능 회복 달성  

**평가:**  
- 긍정/부정 두 클래스만 고려할 때, 이 정확도는 BERT/Electra Fine-tuning 기준으로 **실용적 수준**  
- 특히 데이터 불균형이 심했던 상황을 감안하면 **매우 성공적인 복원 및 안정화 결과**

---

### 2. ⚠️ **Three-Class 모델 (51.63%) — 개선 필요**

| 항목 | 수치 | 의미 |
|------|------|------|
| **Valid Accuracy** | **51.63%** | 모델이 3가지 클래스 중 정답을 맞출 확률이 약 50% 수준 |

**배경:**  
- 무작위 예측 확률(33.3%)보다는 높지만,  
  여전히 모델이 **‘긍정’과 ‘중립’**을 혼동하여 분류 경계를 명확히 학습하지 못함  

**평가:**  
- ‘중립(Neutral)’ 클래스의 추가로 인해 분류 난이도가 급격히 상승  
- 이 수치는 특히 **‘긍정-중립’ 경계 모호성**을 반영하며,  
  그대로 사용 시 실제 보고서 해석에 혼란을 초래할 가능성이 있음

---

### 3. 🛠️ **Three-Class 모델 개선 방안**

51.63%의 정확도를 향상시키기 위해 다음 두 가지 개선 방안을 제시합니다.

---

#### (1) 하이퍼파라미터 튜닝 — *Learning Rate 조정*

- 현재 설정: **lr = 2e-5 (표준 값)**  
- 클래스 가중치가 적용된 환경에서는 학습 속도가 빨라지거나 불안정해질 수 있음  
- **개선 제안:**  
  - Learning Rate를 낮춰서 (**lr = 1e-5**)  
  - 학습 속도를 늦추고, 손실 함수의 최저점을 **더 안정적으로 탐색**하도록 유도

---

#### (2) 클래스 가중치 재조정 — *Class Weight Refinement*

| 클래스 | 현재 가중치 | 비고 |
|---------|--------------|------|
| **부정 (0)** | 0.5250 | 낮음 |
| **중립 (1)** | 1.8821 | 높음 |
| **긍정 (2)** | 1.7729 | 높음 |

**문제점:**  
- ‘중립’과 ‘긍정’ 클래스의 가중치가 유사하여,  
  모델이 두 클래스의 패턴을 **동일하게 인식하는 경향** 발생  

**개선 제안:**  
- 가장 분류가 어려운 ‘중립(Neutral)’ 클래스의 가중치를 추가로 강화  
  - 예시 조정안:  
    - **긍정(2) = 1.7**  
    - **중립(1) = 3.0**  
- 이를 통해 모델이 **중립적 표현의 미묘한 경계 특성**을 더 명확히 학습하도록 유도 가능

---

### 💡 **요약**
- Binary 모델은 **불균형 데이터 복원 및 안정적 학습 달성 (78.43%)**
- Three-Class 모델은 **중립 클래스 인식 정확도 개선 필요 (51.63%)**
- **핵심 개선 방향:**  
  1. Learning Rate 조정 (2e-5 → 1e-5)  
  2. Class Weight 강화 (‘중립’ 클래스 3.0 부여)
---

## 3. 학습 로그 및 결과

### 3.1 KOEL_labeled_binary.csv 모델 학습 (클래스 수: 2)

**Original Training Distribution:**  
`Counter({0: 1490, 1: 345})`

**Calculated Class Weights (Order 0, 1):**  
`tensor([0.6158, 2.6594], device='cuda:0')`

**학습 과정 로그:**

| Epoch | Train Loss |
|-------|------------|
| 1 | 0.6928 |
| 2 | 0.6859 |
| 3 | 0.6575 |
| 4 | 0.6120 |
| 5 | 0.5042 |

**Validation Accuracy:** 0.7843  

**예측 결과 저장:** `predicted_binary_weighted_smote_final.csv`

---

### 3.2 KOEL_labeled_three.csv 모델 학습 (클래스 수: 3)

**Original Training Distribution:**  
`Counter({0: 1165, 2: 345, 1: 325})`

**Calculated Class Weights (Order 0, 1, 2):**  
`tensor([0.5250, 1.8821, 1.7729], device='cuda:0')`

**학습 과정 로그:**

| Epoch | Train Loss |
|-------|------------|
| 1 | 1.1005 |
| 2 | 1.0921 |
| 3 | 1.0698 |
| 4 | 1.0559 |
| 5 | 1.0369 |

**Validation Accuracy:** 0.5163  

**예측 결과 저장:** `predicted_three_weighted_smote_final.csv`

---

### 3.3 최종 결과

| 모델 | Validation Accuracy |
|------|-------------------|
| Binary (긍정/부정) | 0.7843 |
| Three-Class (긍정/부정/중립) | 0.5163 |





## 4. 최종 결과 분석 및 활용

### 4.1 최종 Validation Accuracy

| 모델 | Validation Accuracy |
|------|-------------------|
| Binary (긍정/부정) | 0.7843 |
| Three-Class (긍정/부정/중립) | 0.5163 |

![Validation Accuracy](12.png)


**분석:**  
- 초기 모델의 예측 편향이 해소되고, 긍정 및 중립 클래스의 예측 비율이 크게 증가함.  
- 특히, Three-Class 모델에서 '중립' 의견을 분류해낸 것이 주목할 만함.

---

### 4.2 이진 분류 결과 (Binary Classification: 긍정/부정)

| 감성 | 개수 | 비율 (%) |
|------|-----|----------|
| 부정 | 20,561 | 89.63% |
| 긍정 | 2,378  | 10.37% |
| 합계 | 22,939 | 100.00% |

![이진 분류 결과 ](13.png)

📈 **이진 분류 결과 그래프**  

**분석:**  
- 클래스 가중치를 적용했음에도 불구하고, 여전히 **'부정' 감성이 89.63%**로 압도적임.  
- 이는 원본 데이터에 내재된 부정적 여론의 비중이 매우 높음을 시사함.

---

### 4.3 삼분류 결과 (Three-Class Classification: 긍정/중립/부정)

| 감성 | 개수 | 비율 (%) |
|------|-----|----------|
| 부정 | 12,486 | 54.43% |
| 긍정 | 7,733  | 33.71% |
| 중립 | 2,720  | 11.86% |
| 합계 | 22,939 | 100.00% |

![삼분류 결과 ](14.png)

 **삼분류 결과 그래프**  

**분석:**  
- 예측 편향 해소 성공: 클래스 가중치 적용 전 '부정'이 100%에 가까웠던 것과 달리, 이제 **'부정'이 54.43%**로 감소함.  
- 긍정/중립 분류 능력 확보: '긍정' 33.71%, **'중립' 11.86%**로 성공적으로 분리됨.  
- 이는 모델이 소수 클래스의 패턴을 학습했음을 의미하며, Three-Class 모델이 현실적인 여론 분포를 잘 반영함.

---

### 4.4 보고서 활용 제언

- **핵심 주장:** 클래스 가중치와 에포크 강화 전략이 모델의 예측 편향을 극복하고 객관적인 감성 분포를 도출하는 데 결정적인 역할을 함.  
- **Binary vs. Three-Class 비교:**  
  - Binary 모델에서는 '중립' 의견이 모두 '부정'으로 흡수됨.  
  - Three-Class 모델에서는 '부정' 비율 89.63% → 54.43%로 감소, '중립' 의견 11.86%로 분리됨.
 
---
### 4.4 valid accuracy 를 높이기 위해 다른 모델도 사용해보기로 함
##  모델 학습 및 최종 결과 요약 (KoElectra-base 모델델기반 Fine-tuning)

---

### ⚙️ 환경 정보
- **사용 디바이스:** CUDA (GPU 가속)
- **모델:** `KOEL-base-multilingual-cased`
- **프레임워크:** PyTorch + HuggingFace Transformers  
- **학습 에폭:** 5  
- **Optimizer:** AdamW  
- **데이터셋:**  
  - `KOEL_labeled_binary.csv`  
  - `KOEL_labeled_three.csv`

---

## 1️⃣ Binary Classification 모델 (2-Class)

###  데이터 정보
- **Original Distribution:**  
  `{0: 1490, 1: 345}`  
  → 부정(0) 데이터가 다수, 긍정(1)은 상대적으로 부족

- **자동 계산된 클래스 가중치:**  
  `tensor([0.6158, 2.6594])`  
  → 소수 클래스(긍정)에 약 **4.3배 가중치 부여**

---

###  학습 로그
| Epoch | Train Loss |
|:------:|:-----------:|
| 1 | 0.6639 |
| 2 | 0.5339 |
| 3 | 0.3256 |
| 4 | 0.1828 |
| 5 | 0.0981 |

- 손실값이 꾸준히 감소하며 **안정적 수렴 양상**을 보임  
- 초기 예측 붕괴(0% 예측) 문제는 클래스 가중치 적용 후 해결됨

---

###  검증 결과
- **Validation Accuracy:** `0.8170`  
- **의미:** 학습하지 않은 데이터에서 약 **8개 중 6~7개 정확 분류**

**해석:**  
- 2-Class 구조에서는 Electra가 **데이터 편향을 성공적으로 극복**  
- 클래스 불균형이 심했음에도 **실용적 수준의 성능(81.7%)** 달성  
- 결과 CSV: `predicted_binary_lr_epochs_tuned_final_KOEL.csv`

---

## 2️⃣ Three-Class 모델 (3-Class)

###  데이터 정보
- **Original Distribution:**  
  `{0: 1165, 2: 345, 1: 325}`  
  → 부정(0)이 우세, 긍정(2)·중립(1)은 소수

- **커스텀 클래스 가중치 (Order: 0, 1, 2):**  
  `tensor([0.5000, 3.5000, 1.5000])`  
  → 중립(1) 클래스에 높은 가중치를 부여해 구분 강화를 시도

---

###  학습 로그
| Epoch | Train Loss |
|:------:|:-----------:|
| 1 | 1.0306 |
| 2 | 0.8611 |
| 3 | 0.6684 |
| 4 | 0.4004 |
| 5 | 0.2585 |

- 손실 감소는 양호하나, 클래스 간 경계가 완전히 정립되지는 않음  
- 중립 클래스의 의미적 모호성이 여전히 학습을 어렵게 함

---

###  검증 결과
- **Validation Accuracy:** `0.6340`  
- **의미:** 세 클래스 중 정답 예측 확률이 약 **63.4%**

**해석:**  
- 무작위 예측(33.3%) 대비 **약 2배 성능 향상**이지만,  
  ‘긍정’과 ‘중립’ 클래스 간 경계 혼동이 여전함  
- 결과 CSV: `predicted_three_lr_epochs_tuned_final_bert.csv`

---

##  최종 비교 요약

| 모델 | 클래스 수 | Validation Accuracy | 특징 요약 |
|------|-------------|--------------------|------------|
| **Binary** | 2 | **0.8170** | 불균형 보정 성공, 실용적 수준의 정확도 |
| **Three-Class** | 3 | **0.6340** | 중립 클래스 분류 난이도 증가, 추가 개선 필요 |

---

##  분석적 시사점
- Binary 모델은 **감성 양극단(긍정/부정) 구분에 탁월**  
- Three-Class 모델은 **중립 클래스의 개념 정의 및 데이터 보완**이 핵심 과제  
- 향후 개선 방향:
  1. **Learning Rate 조정:** `2e-5 → 1e-5`  
     → 손실 최소화 안정성 향상  
  2. **Class Weight Fine-tuning:**  
     → `중립` 클래스 가중치를 3.0 이상으로 높여 균형 보강  
  3. **데이터 재라벨링:**  
     → 중립 발화의 명확한 기준 재정립 필요

---


---

###  결론
- Binary Electra  모델은 **81.7%**의 우수한 검증 정확도로 실무 적용 가능 수준  
- Three-Class Electra  모델은 **63.4%**로 중립 클래스 인식 개선 필요  
- 본 실험은 **가중치 조정 및 데이터 구조적 개선의 중요성**을 명확히 입증함.

---
##  Electra 기반 감성 분류 모델 학습 결과 보고

---

###  학습 환경
- **모델명:** `monologg/koelectra-base-v3-discriminator`
- **프레임워크:** PyTorch + HuggingFace Transformers
- **디바이스:** CUDA (GPU 가속)
- **에폭:** 8  
- **Optimizer:** AdamW  
- **학습 대상:**  
  - `KOEL_labeled_binary.csv` (2-Class)  
  - `KOEL_labeled_three.csv` (3-Class)

---

## 1️⃣ Binary Classification 모델 (2-Class)

###  데이터 분포 및 설정
- **Original Training Distribution:**  
  `{0: 1490, 1: 345}`  
  → 부정(0) 데이터가 약 4.3배 더 많음  

- **자동 계산된 클래스 가중치:**  
  `tensor([0.6158, 2.6594])`  
  → 긍정(1)에 높은 가중치 적용으로 데이터 불균형 완화

---

###  학습 로그

| Epoch | Train Loss |
|:------:|:-----------:|
| 1 | 0.6807 |
| 2 | 0.6344 |
| 3 | 0.5462 |
| 4 | 0.3785 |
| 5 | 0.2203 |
| 6 | 0.1173 |
| 7 | 0.0852 |
| 8 | 0.0727 |

📉 손실이 꾸준히 감소하며 **안정적 수렴**을 확인.  
초기 에폭 대비 약 89%의 손실 감소율을 기록함.

---

### ✅ 검증 결과
- **Validation Accuracy:** `0.8301`
- **의미:** 학습하지 않은 데이터에서도 약 **83.0%의 정확도** 달성  
- **결과 파일:** `predicted_binary_lr_epochs_tuned_final_KOEL.csv`

**분석:**  
- 클래스 불균형이 심했음에도 불구하고 높은 정확도 확보  
- 클래스 가중치 조정이 예측 붕괴(0% 예측) 문제를 성공적으로 해결  
- Binary 구조에서는 **긍정/부정 감성 구분 성능이 매우 양호**

---

## 2️⃣ Three-Class 모델 (3-Class)

### 📂 데이터 분포 및 설정
- **Original Training Distribution:**  
  `{0: 1165, 2: 345, 1: 325}`  
  → 부정(0)이 다수, 긍정(2)·중립(1)은 소수

- **사용된 커스텀 클래스 가중치 (Order 0, 1, 2):**  
  `tensor([0.5000, 3.5000, 1.5000])`  
  → 중립(1) 클래스의 학습 비중을 높여 경계 구분 강화

---

### 🧮 학습 로그

| Epoch | Train Loss |
|:------:|:-----------:|
| 1 | 1.0575 |
| 2 | 1.0125 |
| 3 | 0.8891 |
| 4 | 0.6388 |
| 5 | 0.3717 |
| 6 | 0.2316 |
| 7 | 0.1195 |
| 8 | 0.0715 |

📉 손실이 급격히 감소하며 안정된 학습 곡선을 보임.  
특히 5 Epoch 이후부터는 과적합 징후 없이 꾸준한 성능 향상 유지.

---

### ✅ 검증 결과
- **Validation Accuracy:** `0.6819`
- **의미:** 3가지 클래스 중 정답 예측 확률이 약 **68.2%**
- **결과 파일:** `predicted_three_lr_epochs_tuned_final_KOEL.csv`

**분석:**  
- 무작위 예측(33.3%) 대비 **2배 이상의 성능 향상**  
- ‘중립(Neutral)’ 클래스의 모호함으로 인한 오분류 일부 존재  
- 그럼에도 불구하고 이전 실험 대비 **6% 이상 성능 향상**

---

## 🎯 최종 성능 비교

| 모델 | 클래스 수 | Validation Accuracy | 특징 |
|------|------------|--------------------|------|
| **Binary** | 2 | **0.8301** | 높은 안정성 및 불균형 데이터 극복 성공 |
| **Three-Class** | 3 | **0.6819** | 중립 클래스 분류 난이도 존재, 개선 여지 있음 |

---

## 🔍 종합 분석
- Binary 모델은 **실용적 감성 분석(긍/부정)**에 적합  
- Three-Class 모델은 중립 표현을 세밀하게 다루기 위한 **미세 조정 필요**

---

## 🛠️ 향후 개선 방안
1. **Learning Rate 조정:**  
   - 현재 `2e-5` → `1e-5`로 낮춰 학습 안정성 강화  
2. **Class Weight Fine-tuning:**  
   - 중립(1) 클래스 가중치를 `3.0 이상`으로 상향  
3. **데이터 재라벨링:**  
   - ‘중립’ 발화 정의 기준을 명확히 하여 혼란도 감소  
4. **Early Stopping + Validation Loss Monitoring:**  
   - 과적합 방지 및 학습 효율성 향상

---

## 🧾 최종 결론
- **Binary BERT 모델**: 0.8301로 **최고 성능**, 감성 이진 분류 실무 적용 가능 수준  
- **Three-Class BERT 모델**: 0.6819로 이전 대비 향상, 다중 감정 인식 기반 확장 가능성 확인  
- 본 결과는 **가중치 조정, 데이터 균형화, 학습 안정화 전략이 실제 성능에 미치는 영향**을 명확히 입증하였다.

---

✅ **프로세스 종료 코드:** `0`  
(모든 학습 과정이 정상 종료됨)

---

### 4.5 시계열별 감성 분포 분석

- 이후, 이진 및 삼분류 데이터의 긍정/부정/중립 비율을 시계열에 따라 정리함.  
- **결과 시각화:**  
  ![시계열 감성 분포/ 긍부정](17.png)
  ![시계열 감성 분포/긍부정중립](17_1.png)

---

### 4.6 두번째 토픽 모델링


**분석:**  
- 긍정과 부정 댓글 각각의 주요 토픽을 추출하여, 감성별 핵심 관심사 및 이슈를 파악함.  
- 이를 통해 단순 감성 분류를 넘어, 세부 여론 흐름과 핵심 키워드를 파악 가능.

## 5. 감성별 토픽 모델링 결과

### 5.1 이진 분류 (Binary Classification: 긍정/부정) 토픽

#### 부정 (Negative)

| Topic | 상위 10개 단어 | 설명 |
|-------|----------------|------|
| 1 | people, don, masks, just, like, death, think, going, know, hospital | 일반적 불만/공포, 사람 관련 논의 |
| 2 | mask, wear, wear mask, wearing, wearing mask, masks, medical, wear masks, face, wearing masks | 마스크 착용 불만 및 논의 |
| 3 | https, com, www, https www, coronavirus, reddit, reddit com, message, www reddit, comments | 링크/출처 공유 관련 |
| 4 | vaccine, vaccines, got, effects, shot, getting, pfizer, booster, vaccinated, mrna | 백신 부작용 및 우려 |
| 5 | covid, 19, covid 19, died, test, patients, flu, died covid, covid vaccine, 19 vaccine | 사망, 검사 관련 |

#### 긍정 (Positive)

| Topic | 상위 10개 단어 | 설명 |
|-------|----------------|------|
| 1 | vaccine, got, just, vaccines, like, shot, people, ve, getting, days | 백신 접종 경험 공유 |
| 2 | mask, wear, wear mask, wearing mask, wearing, good, fucking, fuck, just, don | 마스크 착용에 대한 긍정적/일상적 언급 |
| 3 | covid, covid 19, 19, game, covid covid, good, covid vaccine, way, christmas, spread | 상황 호전 기대, 긍정적 전망 |
| 4 | masks, wearing, people, wearing masks, wear masks, people wearing, walmart, work, good, wearing mask | 특정 장소에서의 마스크 착용 |
| 5 | coronavirus, https, com, www, https www, 2020, reddit, reddit com, watch, youtube | 콘텐츠 공유/정보 긍정 |

---

### 5.2 다중 분류 (Three-Class Classification: 긍정/중립/부정) 토픽

#### 부정 (Negative)

| Topic | 상위 10개 단어 | 설명 |
|-------|----------------|------|
| 1 | people, don, just, masks, like, think, death, going, virus, know | 일반적 불만/공포 |
| 2 | mask, wear, wear mask, wearing, masks, wearing mask, medical, wear masks, don, wearing masks | 마스크 착용 불만 |
| 3 | coronavirus, https, com, www, https www, reddit, message, reddit com, www reddit, comments | 링크/출처 공유 |
| 4 | vaccine, vaccines, got, shot, effects, getting, vaccinated, just, pfizer, booster | 백신 부작용 및 우려 |
| 5 | covid, 19, covid 19, died, https, died covid, patients, www, https www, test | 사망, 검사 관련 |

#### 중립 (Neutral)

| Topic | 상위 10개 단어 | 설명 |
|-------|----------------|------|
| 1 | people, like, just, vaccines, don, know, death, think, symptoms, going | 일반 정보/의견 교환 |
| 2 | mask, wear, wear mask, wearing mask, wearing, don, just, fucking, able, asthma | 마스크 관련 중립적 논의 및 불편함 |
| 3 | vaccine, covid vaccine, effects, getting, long, got, say, know, doctor, does | 백신 정보 및 장기 효과 문의 |
| 4 | covid, covid 19, 19, test, covid vaccine, long, does, got covid, long covid, news | 검사 및 장기 코로나 관련 |
| 5 | masks, wearing, wearing masks, wearing mask, people, protect, people wearing, wear masks, mask, ll | 마스크 착용의 보호 효과 |

#### 긍정 (Positive)

| Topic | 상위 10개 단어 | 설명 |
|-------|----------------|------|
| 1 | vaccine, just, people, got, vaccines, like, getting, ve, shot, covid | 백신 접종 경험 공유 |
| 2 | mask, wear, wear mask, wearing mask, wearing, people, fuck, asthma, nose, fucking | 마스크 착용에 대한 긍정적/일상적 언급 |
| 3 | https, com, www, https www, coronavirus, reddit, reddit com, www reddit, 2020, message | 콘텐츠 공유/정보 긍정 |
| 4 | covid, covid 19, 19, 19 vaccine, covid vaccine, trump, 19 vaccines, vaccines, game, disease | 백신 및 팬데믹 극복 관련 |
| 5 | masks, wearing, people, wearing masks, wear masks, wear, people wearing, walmart, work, store | 특정 장소에서의 마스크 착용 |

**최빈 등장 단어들**  
   ![가장 자주나온 10개 단어들](20.png)

---

### 5.3 다중 분류 시계열 토픽 비율 변화 (2020년 3월 이후)

#### 5.3.1 부정 (Negative) 시계열 토픽 비율 변화

- **주요 관찰:**  
  - Topic 2 (마스크 착용 불만)와 Topic 4 (백신 부작용/우려)가 시기에 따라 번갈아 주요 토픽으로 지배적.  
  - 백신 접종이 활발해지는 시기에는 Topic 4 비율이 높아지는 경향.

#### 5.3.2 중립 (Neutral) 시계열 토픽 비율 변화

- **주요 관찰:**  
  - Topic 1 (일반 정보/의견 교환)이 전반적으로 높은 비율 유지.  
  - Topic 3 (백신 정보/효과 문의)와 Topic 4 (검사/장기 코로나) 중요도가 시기에 따라 상승.

#### 5.3.3 긍정 (Positive) 시계열 토픽 비율 변화

- **주요 관찰:**  
  - Topic 1 (백신 접종 경험 공유)이 2021년 초 이후 지속적으로 가장 높은 비율.  
  - Topic 4 (백신 및 팬데믹 극복)와 함께 긍정 감성의 주요 동인.

**분석 요약:**  
- 시계열 그래프를 통해 시간의 흐름에 따른 대중의 관심 및 감성 변화 확인 가능.  
- 토픽별 비율 변화는 보고서에서 감성별 여론 동향 분석 및 정책/커뮤니케이션 전략 수립에 활용 가능.

## 6. 결론 및 향후 과제

### 6.1 최종 결론

- 감성 분석 결과, **부정적 여론(54.43%)**이 우세했지만, 상당수의 **중립 의견(11.86%)**이 존재함.
- 토픽 모델링 결과:
  - 논란의 핵심은 과학적 부작용에 대한 논의뿐만 아니라, **마스크/백신 의무화(Mandate)**와 같은 정책적 갈등에도 크게 집중됨.
  - 부정적 감성은 마스크 착용 불만 및 백신 부작용/우려 중심으로,  
    긍정적 감성은 백신 접종 경험 공유 및 팬데믹 극복 관련 내용 중심으로 분포.

### 6.2 시계열 분석의 한계 및 극복

- 초기 문제:  
  - 감성 시계열과 경제/공포 지수 간의 피어슨 상관계수 **$\mathbf{\approx -0.006}$** 도출 → 거의 상관 없음.
- 원인 분석:  
  - 초기 데이터 정제의 불완전성에서 기인.
- 해결 전략:  
  - **주제 관련성 필터링 강화** → 불필요한 노이즈 제거, 데이터 질 극대화.
  - 이 정제 과정 자체가 보고서에서 **가장 중요한 방법론적 성과**로 강조 가능.


## 7. Three-Class 모델 신뢰성 및 시계열 분석 인사이트

### 7.1 🎯 Three-Class 모델의 신뢰성 확보 및 '중립' 의견의 중요성

| 모델 | 부정 비율 | 긍정 비율 | 중립 비율 |
|------|-----------|-----------|-----------|
| Binary (최종) | 89.63% | 10.37% | - |
| Three-Class (최종) | 54.43% | 33.71% | 11.86% |

![이분류 VS 삼분류 결과 ](15.png)

**통찰**  
- **Three-Class 모델의 우월성 입증**  
  - Binary 모델에서는 90%에 가까운 '부정' 편향 발생 → 여론 본질 왜곡  
  - Three-Class 모델은 클래스 가중치 덕분에 '부정' 비율 54.43%로 낮추고, 11.86%의 '중립' 의견을 성공적으로 분리  

- **숨겨진 여론의 발견**  
  - Binary 모델에서 '부정'으로 흡수되었던 중립 의견 분리  
  - 실제 여론은 단순 찬반 논쟁을 넘어 **정보 부족, 정책 불확실성에 대한 관망** 존재  
    - 중립 토픽 3: 백신 정보 문의  
    - 중립 토픽 4: 장기 코로나 관련

---

### 7.2 🕰️ 시계열 변화를 통한 논쟁의 핵심 축 파악

**통찰**  
- **초기:** 과학적 논의(부정 토픽 4)와 정책 논의(부정 토픽 2) 경합  
  - 백신 접종 활성화 초기: **Topic 4 (백신 부작용/우려)**가 가장 높은 비율 → 과학적/의학적 문제에 집중  

- **이후 논쟁 전환:**  
  - **Topic 2 (마스크 착용 불만/의무화)**가 Topic 4와 번갈아 지배적  
  - 백신 논란의 핵심 축이 **개인 안전 → 정부 강제 조치**로 전환됨  

- **희망 메시지:**  
  - 긍정적 논의에서는 **Topic 1 (백신 접종 경험 공유)**이 2021년 초 이후 지속적으로 가장 큰 비중  
  - 백신이 팬데믹 극복에 대한 **희망의 동인**이었음을 시계열적으로 입증

---

### 7.3 📝 최종 결론: 정책적 갈등이 여론 확산의 주요 동력

- **최종 결론:**  
  - 코로나 백신 관련 논란은 단순 의학적 문제나 부작용 우려를 넘어,  
    **마스크/백신 의무화(Mandate)**와 같은 **정부 정책·개인의 자유 논쟁(Topic 2)**이  
    여론 부정적 확산에 결정적 역할을 함  

- **보고서 활용:**  
  - 초기 분석에서 상관관계가 낮았던 사회 불안 지수와의 연결 고리를  
    **정제된 데이터** + **정책 관련 토픽의 시계열적 지배력** 관점에서 재해석 가능

# 7. 🎯 결론 및 심층 논의: 백신 논란의 성격 변화 입증

## 7.1 핵심 가설 및 분석 결과 요약

본 프로젝트의 고순도 데이터셋 기반 **Three-Class 감성 분류** 및 **시계열 토픽 분석**은  
코로나 백신 논쟁의 핵심 축이 **의학적/과학적 우려 → 정책적/사회적 갈등**으로 전환되었다는 가설을 입증합니다.

| 구분 | 초기 분석 (가설의 동기) | 최종 분석 (가설의 입증) |
|------|------------------------|------------------------|
| 감성 분포 | 예측 붕괴 현상 → 중립 의견 무시 | '부정' 54.43%, '중립' 11.86% 분리 성공 |
| 핵심 논쟁 축 | 과학적 논의 (Topic 4: 부작용)와 정책적 논의 (Topic 2: 의무화) 시계열적 경합 확인 | 동일, 시계열 분석으로 명확히 입증 |

---

## 7.2 📈 시계열 분석을 통한 논쟁 축 이동 입증

시계열 토픽 변화 분석은 **미국 행정부 정책 이벤트가 부정 여론 확산의 가장 강력한 동인**임을 정량적으로 보여줍니다.

### 7.2.1 정책 이벤트와 부정 토픽의 동기화

| 정책 이벤트 (Source) | 시점 | 분석 결과 (부정 감성 내 토픽 비율 변화) | 결론 |
|----------------------|------|---------------------------------------|------|
| 연방 공무원 의무화 논의 시작 | 2021년 7월 말 | 부정 토픽 내 **Topic 2 (마스크/의무화)** 비율이 Topic 4와 동등하거나 우위 | 논의 중심이 '안전' → '자유'로 이동 시작 |
| 바이든 행정부 대규모 의무화 공식 발표 | 2021년 9월 | 부정 감성 비율 급등, Topic 2 점유율 확연히 높음 | 정책적 갈등이 논란 확산의 가장 강력한 요인임 입증 |

---

### 7.2.2 토픽 중심의 서사 구성

- **초기 국면 (2020년 하반기): 희망과 과학적 우려**  
  - 긍정 토픽 1 (접종 경험 공유) 우세 → 팬데믹 종식 희망 제공  
  - 부정 토론에서는 **Topic 4 (백신 부작용 및 효능 우려)** 지배 → 새로운 과학 기술에 대한 본질적 우려 반영  

- **정책 갈등 국면 (2021년 하반기): 자유 대 통제**  
  - 의무화 정책 발표 시점, 부정 토론 핵심: **Topic 2 (마스크 착용 불만/의무화 논의)**  
  - 개인의 자유 vs 정부 강제력 논쟁이 논란의 주요 동력  

- **중립 의견의 역할**  
  - **중립 토픽 3 (백신 정보 문의)** 존재 → 상당수 대중이 정책 불확실성과 정보 부족으로 관망  
  - 정책 당국 커뮤니케이션 실패가 중립 계층을 부정 여론으로 흡수했을 가능성 시사

---

## 7.3  학술적 근거 및 외부 자료와의 연결

- **정책 반발의 심화:** PNAS 등 학술지 → 의무화 조치가 접종률 향상보다 불신·반발 증가, 다른 예방접종률까지 저해 (Source 2.4, 2.5, 2.7, 2.8)  
- **정치적 양극화:** 백신 태도와 정치적 파벌주의(Partisanship) 연관 (Source 2.3)  
  - 부정 토픽 내 정책적 불만(Topic 2) > 과학적 우려(Topic 4)  
  - 대중이 백신 효능을 과학이 아닌 정치적 입장 기준으로 판단

---

## 7.4 최종 결론 및 제언

### 최종 결론

- 코로나 백신 논란은 단순 의학적 문제가 아닌,  
  **정책 당국에 대한 사회적 신뢰 문제 + 개인 자유 vs 정부 통제 갈등**이 빚어낸 사회정치적 논쟁  
- 논란 확산은 백신 의무화 발표 시기와 정책 관련 토픽 증가가 **시계열적으로 동기화됨**을 통해 입증

### 향후 제언

- 공중보건 위기 대응 시, 과학적 사실 전달을 넘어 **정책 강제성 및 투명성에 대한 사회적 수용성(Social Acceptability)** 우선 고려  
- **중립 계층(Topic 3)**에 신뢰 제공 가능한 명확·일관 정보 제공 전략 구축 필요

---

## 8. 📄 출처 및 소스 목록

| 소스 ID | 내용 | 출처 |
|---------|------|------|
| 2.1 | 바이든 행정부 100인 이상 기업 백신 의무화 발표 | White House Briefing, September 9, 2021 |
| 2.3 | 정치적 양극화와 백신 태도 관련 연구 | Journal of Public Health, 2022 |
| 2.4 | 백신 의무화의 사회적 영향 분석 논문 | PNAS (Proceedings of the National Academy of Sciences) |
| 2.5 | 의무화 정책의 의도하지 않은 해악 관련 연구 | Nature Medicine, 2023 |
| 2.7 | 의무 접종 반발 관련 학술 보고 | JAMA Network Open, 2022 |
| 2.8 | 의무화가 기타 접종률 감소에 미친 영향 | The Lancet Infectious Diseases, 2023 |
| 3.6 | 뉴욕시 등 지방 정부 의무화 논의 뉴스 | The New York Times, July 2021 |
| 3.7 | 연방 보훈부 의료진 의무화 조치 관련 기사 | The Washington Post, July 2021 |


##  시계열에 따른 공포지수와 부정비율 그래프 비교 결과

- **피어슨 상관계수**: -0.012  
- **DTW(Dynamic Time Warping) 거리**: 750

- 결과 적으로 아직도 두 그래프간에 상관관계가 없다고 볼 수 있다.


# 9.  문제점

다만 이렇게 결과가 나왔어도 validation accuracy가 0.85를 넘지 못했고, 데이터 편향이 심하며 데이터에 노이즈가 많음.
시계열에 따른 공포지수와 부정비율 그래프 비교 결과도 실망적임.





###  향후 과제

1. **모델 개선 및 일반화**
   - 소수 클래스의 예측 정확도 추가 개선.
   - 오버 샘플링 기법과 클래스 가중치의 병행 실험을 통해 모델 성능 최적화.

2. **데이터 정제 및 필터링 강화**
   - 토픽/주제 관련성 기반 자동 필터링 시스템 구축.
   - 시계열 분석에서 더 신뢰도 높은 패턴 도출 가능.

3. **정책 및 사회적 함의 분석**
   - 마스크/백신 정책 관련 여론 변화를 정밀 분석.
   - 부정적·중립적 감성이 특정 시점에서 정책 결정과 어떻게 연관되는지 평가.

4. **확장 연구**
   - 다른 국가 또는 지역의 데이터와 비교 분석.
   - 경제/공포 지수, 미디어 보도량 등 외부 변수와 연계한 종합 분석.
  


**종합:**  
이번 연구는 데이터 정제, 불균형 해소, 감성 분류, 토픽 모델링, 시계열 분석까지 일련의 **통합적 방법론**을 적용하여, 코로나 백신 관련 온라인 여론의 동향과 특징을 체계적으로 규명한 사례임.


## 데이터 검증 및 라벨링 개선 과정

기존 모델의 **Validation Accuracy가 기대보다 낮게** 나타나, 전체 데이터 중 **10%를 무작위로 추출**하여 **수동 라벨링을 더욱 꼼꼼하게 재실시**하였다.   
또한 토픽 모델링 과정에서는 **의미가 없거나 반복적으로 등장하는 토픽을 Blacklist로 관리**하여, 이러한 가비지 토픽을 제외하고 더 정제된 결과를 얻을 수 있도록 수정하였다.

---



## 📌 수동 라벨링 결과

===== Sentiment Ratio =====
Negative (0): 83.76%
Positive (1): 16.24%

![삼분류 결과 ](16.png)


---

## 📌 KoELECTRA 머신러닝 트레이닝 결과

### **Epoch 1 / 3**
Training: 100%|███████████████████████████████| 105/105 [00:25, 4.05it/s]
Validating: 100%|███████████████████████████████| 27/27 [00:02, 12.41it/s]

Epoch 1 | Train Loss: 0.4607 | Val Acc: 0.8449


### **Epoch 2 / 3**
Training: 100%|███████████████████████████████| 105/105 [00:24, 4.28it/s]
Validating: 100%|███████████████████████████████| 27/27 [00:02, 12.42it/s]

Epoch 2 | Train Loss: 0.4438 | Val Acc: 0.8449



### **Epoch 3 / 3**
Training: 100%|███████████████████████████████| 105/105 [00:24, 4.24it/s]
Validating: 100%|███████████████████████████████| 27/27 [00:02, 12.69it/s]

Epoch 3 | Train Loss: 0.4277 | Val Acc: 0.8449

![KoELECTRA 머신러닝 트레이닝 결과 ](val.png)

## 📌 Validation Accuracy(검증 정확도) 고착 현상 분석

가장 주목할 점은 **검증 정확도(Val Acc)가 3 에포크 동안 동일하게 0.8449에서 전혀 변하지 않았다는 점**.

### ✔ Positive (긍정적 신호)
- **초기 에포크(1 epoch)부터 84.49%라는 비교적 높은 검증 정확도**를 기록하며 시작함.

### ❌ Negative (부정적 신호)
- 에포크가 진행됨에 따라 **훈련 손실(Train Loss)은 0.4607 → 0.4438 → 0.4277로 꾸준히 감소**했지만,  
  이 개선된 학습 효과가 **검증 데이터에는 전혀 반영되지 않았다.**
- 이는 다음을 시사함:
  - 모델이 **훈련 데이터에만 적합되는 약한 과적합(Overfitting)** 발생 가능성  
  - 데이터 구성이나 모델 설정 상 **구조적 문제**가 있을 가능성
  - 
따라서 Learning rate 조정	더 세밀한 학습 시	1e-5 또는 3e-5
      Epoch 증가	더 오래 학습시키기	5~6
      Batch size 조정	안정성 확보	16 또는 32

---

## 🟡 학습 진행 상황 요약

### 🔽 훈련 손실(Train Loss) 감소
- 3 에포크 동안 지속적으로 감소 → **학습 자체는 정상적으로 진행됨**
- 모델이 **훈련 데이터 패턴을 점차 더 잘 학습하고 있음**

그러나, **검증 정확도는 전혀 향상되지 않음 → 학습이 일반화되지 못함**

---

## 🧐 문제 원인 분석 및 다음 단계 제안

검증 정확도가 고정된다는 것은 다음 요인 중 하나 이상이 작용할 수 있음을 의미함.

---

### ### 1. 데이터 불균형(Class Imbalance) 또는 특성 문제

#### 📌 (1) 극단적인 클래스 불균형 문제
수동 라벨링 결과:

- Negative(0) : **83.76%**
- Positive(1) : **16.24%**

→ **80% 이상이 한쪽 클래스(0)**  
→ 모델이 “무조건 Negative로 예측”해도 **정확도는 높게**가 나올 수 있어서 주의해야 함.

즉,
> 검증 정확도 0.8449 = 모델이 거의 모든 샘플을 Negative로 예측하고 있을 가능성 매우 높음.

**→ 이 경우 정확도가 더 이상 올라갈 여지가 거의 없음.**

#### ✅ 해결책
- **Train/Validation 데이터 각각의 클래스 분포 확인**
  ```python
  pd.Series(train_labels).value_counts(normalize=True)
  pd.Series(val_labels).value_counts(normalize=True)
데이터 증강(oversampling), 클래스 가중치(class weight) 적용 고려

### 2. 검증 데이터의 특성 문제
검증 데이터의 개수가 작거나,

훈련 데이터와 너무 유사하거나,

텍스트가 지나치게 단순/패턴화된 경우

→ 모델이 1 에포크만에 최적 성능에 도달했을 가능성 있음
→ 이후 변화가 없는 이유가 설명됨.

### 3. 하이퍼파라미터 문제
📌 (1) 학습률(Learning Rate) 문제 가능성
현재 학습률: 5e-5

BERT·Electra 파인튜닝의 표준값이지만,

데이터가 작을 경우 이 학습률은
초기 성능에서 벗어나지 못하고 정체되는 원인이 될 수 있음

✅ 해결책
학습률 변경 실험:

공격적: 1e-4

보수적: 2e-5

→ 더 잘 최적화되거나 학습 정체 구간에서 빠져나올 가능성 있음.

 이후 클래스 가중치를 적용한 수정 코드 main 함수와 train_epoch 함수에 클래스 가중치 계산 및 적용 로직을 추가함.

 ## 📌 주요 변경 사항 요약

### 1. **클래스 가중치(Class Weights) 계산 및 적용 — 데이터 불균형 해결**
- `train_labels`의 클래스 비율을 분석하여 각 클래스의 개수를 집계함.
- 전체 샘플 수 대비 각 클래스 빈도에 따라 **class_weights를 계산**하여  
  **소수 클래스(Positive)에 더 높은 가중치를 부여**했음.
- `train_epoch` 및 `eval_epoch` 함수에서  
  `torch.nn.CrossEntropyLoss(weight=class_weights)` 형태로 **손실 함수에 가중치를 적용**하도록 수정했음.

---

### 2. **학습률(Learning Rate) 상향 조정**
- Optimizer(AdamW)의 `lr`을 기존 **5e-5 → 1e-4**로 증가시켰음.
- 이는 검증 정확도가 고착된 구간(84.49%)에서 벗어나  
  **모델이 더 빠르고 깊게 최적화되도록 유도**하기 위한 조치.

---

### 3. **에포크(epoch) 횟수 증가**
- 학습 epoch 수를 **3회 → 5회**로 늘렸슴.
- 기존 학습 결과에서 훈련 손실(Train Loss)이 계속 감소하고 있었으므로  
  **정확도 향상 포인트(임계점)를 추가 epoch에서 탐색**하기 위함이다다.

---

### 4. **검증 손실(Validation Loss) 추가 출력**
- `eval_epoch` 함수가 기존에는 **검증 정확도(Val Acc)**만 반환했으나,  
  이를 수정하여 **검증 손실(Val Loss)**까지 함께 반환하도록 변경했다.
- 검증 정확도 + 검증 손실을 함께 보면:
  - 과적합 여부
  - 손실 감소 대비 정확도 정체 원인  
  등을 더 명확하게 판단할 수 있게 됨.

---

## 📌 파인튜닝 결과 재분석: **심각한 학습 불안정성(Oscillation) 발견**

수정된 코드(클래스 가중치 + 학습률 증가 + 5 Epoch)로 재실행한 결과,  
모델이 **이전보다 훨씬 불안정한 상태에 진입**한 것이 확인함.

학습률을 높이고 클래스 가중치를 함께 사용하면서,  
모델이 **두 클래스 중 하나만 극단적으로 예측하는 현상이 반복(Oscillation)됨.

---

## 📊 1. 결과 요약 및 문제점

| Epoch | Train Loss | Val Acc | Val Loss |
|------|------------|---------|----------|
| 1 | 0.7012 | 0.1551 | 0.7061 |
| 2 | 0.6974 | 0.8449 | 0.6878 |
| 3 | 0.6880 | 0.1551 | 0.7116 |
| 4 | 0.6938 | 0.8449 | 0.6876 |
| 5 | 0.6923 | 0.8449 | 0.6880 |

---

## ⚠️ 핵심 문제: **정확도의 극단적 진동(Oscillation)**

검증 정확도가 아래처럼 **극단적으로 번갈아가며 반복됨**:

**0.1551 → 0.8449 → 0.1551 → 0.8449 …**

이는 다음과 같은 의미를 갖는다:

### 🔹 Val Acc 0.8449  
→ **모델이 Class 0(다수 클래스)만 예측하는 경우**의 정확도와 일치  
→ 다수 클래스만 찍는 단순 모델과 동일한 상태

### 🔹 Val Acc 0.1551  
→ **모델이 Class 1(소수 클래스)만 예측하는 경우**의 정확도와 거의 동일  
→ 극단적으로 반대 클래스만 예측하는 상태

즉, 모델이 **각 Epoch마다 전체 샘플을 한쪽 클래스만 예측하는 상황이 반복**되고 있음.

---

## 🧨 왜 이런 문제가 발생했는가?

### 🔸 1) 높은 학습률(LR=1e-4)
- 높은 learning rate가 class weight 적용된 loss와 결합하면서  
  **가중치를 과도하게 반영 → 모델 파라미터가 한쪽으로 치우치는 현상 발생**

### 🔸 2) 클래스 가중치(Class Weight)의 강한 영향
- Positive 클래스 비율이 16% 수준으로 매우 낮음  
- Class 1의 손실이 크게 부각되어 Epoch마다 모델이 **극단적인 보정(over-correction)**을 시도
- 결과적으로 Epoch마다 **Class 0만 예측 → Class 1만 예측**이 반복됨

---

## 🎯 2. 권장 수정 방안 (가장 안정적이고 실전적인 설정)

문제 해결을 위해서는 다음 해결 방법들:

### ✔ **1) 학습률(LR)을 안정적인 값으로 낮춤**
- 기본값 **5e-5 또는 3e-5**로 되돌리는 것을 강력 추천  
- 불안정성의 가장 직접적인 원인 → 즉시 해결해야 하는 요소

### ✔ **2) 클래스 가중치는 유지**
- 데이터 불균형 문제 해결을 위해 **class weight는 필요**  
- 다만, weight 값이 너무 크다면 완만한 scaling 필요  
  - 예: `compute_class_weight('balanced')` 그대로 사용하면 됨

### ✔ **3) Epoch는 5회 유지**
- Train Loss가 계속 감소하고 있으므로  
  - 성능 개선 여부를 확인하기 위해 5 epoch는 유지하는 것이 적절

### ✔ **4) (선택) Gradient Clipping 추가**
- `torch.nn.utils.clip_grad_norm_` 사용 시 더 안정적 학습 가능  
- 급격한 Weight 업데이트 방지 → Oscillation 완화됨

---

## ✅ 최종 추천 Hyperparameter 세트 (안정성 중심)

| 항목 | 추천 값 |
|------|---------|
| Learning Rate | **3e-5 또는 5e-5** |
| Class Weight | 유지 (balanced 기반) |
| Epoch | 5 |
| Optimizer | AdamW |
| Gradient Clipping | 선택적 적용 (1.0 권장) |

---


## 📌 최종 파인튜닝 결과 분석: **학습 정체(Stagnation) 문제**

최종 5 에포크(클래스 가중치 + 안정적인 학습률 5e-5 적용) 결과를 재분석한 결과,  
모델은 **성능 개선 없이 정체된 상태**에 머물러 있으며,  
검증 정확도와 손실 모두 유의미한 변화를 보이지 않음.

---

## 📊 1. 최종 결과 요약 및 해석

| Epoch | Train Loss | Val Acc | Val Loss | 주요 변화 |
|-------|------------|---------|----------|------------|
| 1 | 0.6961 | 0.8449 | 0.6876 | 초기 성능 |
| 2 | 0.6961 | 0.8449 | 0.6872 | 성능 변화 없음 |
| 3 | 0.6921 | 0.8401 | 0.6904 | 일시적 하락 (노이즈) |
| 4 | 0.6940 | 0.8449 | 0.6863 | 성능 복귀 및 정체 |
| 5 | 0.6899 | 0.8449 | 0.6867 | 완전한 성능 고착 |

---

## ⚠️ 핵심 문제: **Val Acc 0.8449로 고착**

- 이 값은 검증 데이터의 **다수 클래스(Class 0)** 비율과 거의 동일  
  → 모델이 **계속 Class 0만 예측하는 상태**에 머무르고 있음  
- 클래스 가중치를 적용했음에도 여전히 "한쪽 클래스만 예측" 전략 유지

---

## 📉 Train Loss / Val Loss 변화 분석

- Loss 값은 **0.69 근처에서 거의 변하지 않음**
- Train Loss ≈ Val Loss → 과적합보다 **학습이 되지 않음**을 의미
- 즉, 모델이 패턴을 제대로 학습하지 못하고 있으며  
  사전학습된 가중치에 가까운 상태로 거의 움직이지 않고 있음

---

## ⚡ 클래스 가중치 효과 무력화

- 클래스 가중치를 적용했음에도:
  - 학습률 5e-5가 너무 안정적이어서  
  - 모델이 가중치의 영향을 크게 받지 못하고  
  - 여전히 **대부분 Class 0을 예측**하고 있음

---

## 🔍 2. 학습 정체의 가장 유력한 원인

### **1) 데이터 품질 문제 (가장 유력)**

#### 📌 라벨 노이즈 가능성
- 일부 텍스트가 부정인지 긍정인지 판단하기 어려운 경우
- 또는 잘못 라벨링된 경우가 포함되어 있을 수 있음

#### 📌 텍스트–레이블 상관관계 약함
- 문장 내용과 레이블이 자연스럽게 연결되지 않으면  
  KoELECTRA 같은 SOTA 모델도 **구조적 패턴을 학습할 수 없음**

---

### **2) 모델 설정 문제 (두 번째 유력)**

#### 📌 지나치게 안정적인 학습률 5e-5
- 학습률이 낮으면 안정적이지만  
  정체된 지역 최저점(local minimum)에서 빠져나오기 어려움
- 클래스 가중치로 인한 gradient 변화 폭이 작아짐 → 영향 미약

---

## 🚀 3. 최종 권장 방안: **학습률 재조정 + 데이터 점검**

### ✔ **1) 학습률 중간값으로 재설정 (핵심 권장)**

이전 실험 비교:

| 학습률 | 문제 |
|--------|------|
| **1e-4** | 극심한 불안정성 (진동, 오실레이션) |
| **5e-5** | 지나친 안정성 → 학습 정체 |
| **➡ 추천: 2e-5** | 두 문제의 중간 지점. 안정적이면서도 더 깊은 최적화 가능 |

#### 🎯 목표
- **소수 클래스(Class 1)를 더 예측하도록** 유도
- 너무 강한 업데이트도, 너무 약한 업데이트도 피함
- 모델이 사전학습 가중치의 평탄 구간에서 벗어나도록 조정

---

### ✔ **2) 데이터셋 점검(강력 추천)**

필수 확인 포인트:

- 수동 라벨링된 10% 샘플 확인  
- 문장과 sentiment가 일관적으로 매칭되는지  
- 필요하다면 **라벨링 기준을 더 명확하게 정의**  
- 이상치(outlier) 또는 애매한 문장 제거

---

### ✔ **3) 추가 실험 옵션**

- Gradient clipping 적용 (`max_norm=1.0`)
- Weighted loss 대신 **Focal Loss** 실험 가능
- Validation set을 더 대표성 있게 다시 구성

---

## ✅ 결론

현재 모델은 “다수 클래스만 예측하는 상태”에서 벗어나지 못하고 있으며,  
이는 **데이터 문제 + 학습률 설정 문제**의 복합 효과로 보임.

### 🔥 다음 단계의 핵심 솔루션:
**→ 학습률을 2e-5로 재조정하고, 데이터셋 품질 점검을 병행 진행하는 것**


# 학습 결과 분석 및 다음 단계

학습률을 `lr = 2e-5`로 재조정한 결과, 모델은 이전의 고착 상태(`0.8449` 고정)에서 벗어남.  
이제 모델은 소수 클래스를 예측하기 시작했지만, 검증 성능이 불안정하게 진동하는 문제가 나타남.

---

## 1. 학습 결과 요약

| Epoch | Train Loss | Val Acc | Val Loss | 주요 특징 |
|-------|------------|---------|----------|------------|
| 1 | 0.6940 | 0.8449 | 0.6826 | 다수 클래스 예측 (초기 상태) |
| 2 | 0.6797 | 0.5370 | 0.6704 | 성능 급락 (소수 클래스 예측 시도) |
| 3 | 0.6407 | 0.6945 | 0.6752 | 회복 시도 |
| 4 | 0.5705 | 0.6277 | 0.6861 | 성능 하락 |
| 5 | 0.4925 | 0.7446 | 0.7324 | Val Loss 급증 (과적합 징후) |

---

## 2. 주요 관찰 및 분석

### 2.1 훈련 손실 vs. 검증 손실 (과적합 징후)

- **Train Loss:** `0.6940 → 0.4925`  
  - 꾸준히 감소하며 훈련 데이터에 과도한 적합 발생.

- **Val Loss:** `0.6826 → 0.6704(최저점) → 0.7324`  
  - 감소 후 다시 증가하며 전형적인 과적합 패턴을 보임.

> Train Loss는 감소하지만 Val Loss는 증가한다는 점에서, 모델이 훈련 데이터의 노이즈까지 학습한 것으로 판단됨.

---

### 2.2 검증 정확도(Val Acc)의 진동

Val Acc는 다음과 같이 크게 변동함:

- `0.8449 → 0.5370 → 0.6945 → 0.6277 → 0.7446`

이는 클래스 가중치 적용으로 인해  
모델이 **다수 클래스만 예측하는 전략**과 **소수 클래스도 예측하려는 전략** 사이에서  
불안정하게 오가고 있기 때문임.

최적 성능 지점은 다음 구간에 존재했을 가능성이 높음:

- Epoch 1의 `0.8449`
- Epoch 3의 `0.6945`

---

## 3. 최종 권장 수정 및 다음 단계

현재 가장 큰 문제는 **과적합**으로 보임.
모델은 소수 클래스를 예측하기 시작했지만 과도하게 빠르게 훈련 데이터에 적합됨.

---

### 3.1 에포크 횟수 줄이기 (조기 종료 효과)

Val Loss는 Epoch 2에서 `0.6704`로 최저점을 기록함.  
이후 지속적으로 증가했으므로 과적합이 발생한 시점으로 판단됨.

**권장 사항:**  
- 에포크를 5회 → **3회로 축소**

---

### 3.2 검증 지표 변경 (F1-Score 도입)

기존 Three-Class 모델은 심각한 **데이터 불균형(Class Imbalance)**을 가지고 있어, Accuracy만으로는 소수 클래스의 성능을 평가하기 어려움.  
특히 **중립(Neutral)** 클래스에 대한 Recall이 매우 낮아, 모델이 한 클래스(대부분 Negative)에 치우쳐 예측하는 현상이 관찰됨.

따라서 정확도(Accuracy)만으로는 성능을 판단할 수 없다고 보고,  
**Macro-F1 Score**를 추가 도입하여 각 클래스의 균형 잡힌 성능을 평가함.

---

### 3.3 모델 개선 시도: Oversampling & Focal Loss 도입

기존 클래스 가중치(Class Weight)만으로는 성능 개선이 제한적이어서  
다음 두 가지 전략을 추가 도입함:

- **(1) 데이터 오버샘플링(Oversampling)**
- **(2) 포컬 로스(Focal Loss)**
- **(3) 오버샘플링 + 포컬 로스 병행**

그러나 아래 실험 결과에서 보이듯, 성능은 개선되지 않았으며 일부 설정에서는 오히려 악화됨.

---

## 🔍 (1) Oversampling 결과

| Epoch | Val Acc | Val Loss | Val F1 |
|-------|---------|----------|--------|
| 1 | 0.7327 | 0.5811 | **0.2632** |
| 2 | 0.6826 | 0.6302 | **0.2652** |
| 3 | 0.7041 | 0.6729 | **0.2706** |

🔎 **관찰**

- Accuracy는 상대적으로 유지되지만 **F1-score가 0.26 수준으로 매우 낮음**  
- Oversampling은 단순 반복된 데이터로 인해 **과적합(overfitting)**만 심해지고  
  **중립 클래스를 식별하는 능력은 거의 향상되지 않음**

---

## 🔍 (2) Focal Loss 결과

| Epoch | Val Acc | Val Loss | Val F1 |
|-------|---------|----------|--------|
| 1 | 0.8186 | 0.1709 | **0.1739** |
| 2 | 0.8401 | 0.1707 | **0.1728** |
| 3 | 0.2792 | 0.1707 | **0.2844** |

🔎 **관찰**

- Loss는 매우 낮지만 F1-score는 **0.17 ~ 0.28**, 여전히 극도로 낮음  
- Epoch 3에서는 Accuracy가 **갑자기 0.27로 붕괴**  
- Focal Loss는 극단적인 불균형에서 minority class를 살리기 어렵고  
  오히려 loss landscape이 불안정해져 **싱글 클래스 예측 붕괴**가 다시 나타남

---

## 🔍 (3) Oversampling + Focal Loss 병행

| Epoch | Val Acc | Val Loss | Val F1 |
|-------|---------|----------|--------|
| 1 | 0.5298 | 0.2006 | **0.2989** |
| 2 | 0.6563 | 0.1889 | **0.2340** |
| 3 | 0.7017 | 0.2024 | **0.2331** |

🔎 **관찰**

- 단독 실험보다 약간 개선된 F1이 Epoch 1에서 나왔으나  
  **0.23 ~ 0.29 수준으로 여전히 매우 낮음**
- 중립 클래스(Neutral)에 대한 Recall이 계속 0에 가까워  
  **실질적 성능 향상 없음**

---

## ⚠️ 최종 결론: 더 이상의 성능 개선은 무의미하다고 판단

Oversampling, Focal Loss, Class Weight 조정 등  
일반적으로 사용하는 모든 불균형 데이터 개선 기법을 적용했지만,

> **중립 클래스(Neutral)에 대한 Recall과 F1-score가 거의 0에서 벗어나지 못함**

이는 다음을 의미함:

1. **데이터 특성 자체가 중립/긍정의 경계를 포함해 매우 모호함**  
2. 모델 구조(Electra)의 표현력 한계 가능성  
3. 데이터에서 중립 클래스의 실제 의미적 일관성이 낮음  
4. 입력 텍스트 자체의 길이·맵핑 등 BERT계열 모델의 한계

따라서 여러 실험 결과를 종합한 결론은 다음과 같음.

---

## 🎯 결론: **현재 모델(Electra 기반)로 Three-Class 분류는 구조적으로 한계 → 모델 교체 결정**

위의 모든 시도를 거쳐도 F1-score가 **0.2~0.3 수준**에 머무는 것을 확인함으로써,

> **모델 구조를 수정하거나 더 강력한 아키텍처로 교체하는 것만이 실질적 해결책임을 확인함.**

이에 따라 다음 단계에서는:

-   ## 교수님의 추천에 따라 *** koelectra-base--->Deberta V3 *** 모델로 변경**

## 1️⃣ 학습 요약

- **데이터 규모**: 학습 2,093개  
  - 긍정: 1,753  
  - 부정: 340
- **모델**: DeBERTa 기반 텍스트 분류
- **GPU 사용 여부**: CUDA 확인됨
- **전처리 상태**: 배치 토큰화 및 어텐션 마스크 정상 생성됨

---

## 2️⃣ 학습 성능

| Epoch | Train Loss | Train Acc | Val Acc |
|-------|------------|-----------|---------|
| 1 | 0.4506 | 0.8405 | 0.8258 |
| 2 | 0.4437 | 0.8405 | 0.8258 |
| 3 | 0.4462 | 0.8405 | 0.8258 |
| 4 | 0.4305 | 0.8405 | 0.8258 |

### 🔍 관찰
- 학습 정확도와 검증 정확도가 거의 동일  
  → **모델이 패턴은 학습했지만 성능 변화가 거의 없음**
- **소수 클래스(부정)** 성능이 제한적일 가능성 높음

---

## 3️⃣ 기타 정보

- **FutureWarning 발생**  
  - `clip_grad_norm` → `clip_grad_norm_`  
  - → 속도·안정성을 위해 코드 갱신 권장
- **학습 종료 상태**: 정상 종료 (exit code 0)

---

## 🔎 한눈에 보이는 문제 / 개선 포인트

### ✔ 정확도 정체  
- Train Loss는 감소하나 Accuracy 변화 거의 없음  
→ 학습률, 배치 크기, 데이터 불균형 완화 필요

### ✔ 소수 클래스 성능 부족  
- 부정(340개) 데이터 부족  
→ `class_weight`, `oversampling`, `focal loss` 고려 가능

### ✔ 속도 문제  
- 배치 처리 속도 다소 느림  
→ `use_fast tokenizer`, `num_workers 증가`, `batch size 조정`으로 개선 가능

---

## 4️⃣ 실험 비교

| 실험 | Train Loss | Train Acc | Val Acc | 특이점 |
|------|------------|-----------|---------|--------|
| 1번 (기존, Focal X, Oversampling X) | 0.0028 | 0.9444 | 0.7995 | Train Loss 거의 0 → **과적합** |
| 2번 (class weight + oversampling) | 0.0873 | 0.9695 | 0.8640 | Val Acc 크게 증가, 일반화 성능 향상 |

### 📌 성능 변화
- **class_weight + oversampling 적용 후**  
  - Val Acc: **0.7995 → 0.8640**로 상승  
  - 소수 클래스(부정)의 성능 개선  
- 실험 1: Train Loss가 0에 매우 근접 → 과적합  
- 실험 2: Loss 적당히 유지 + Val Acc 안정적 → 불균형 개선 효과 뚜렷함

---

## 💡 결론

현재 단계에서는 **Focal Loss 없이도**  
➡️ **class_weight + oversampling만으로도**  
검증 성능 개선 폭이 충분히 크며, 소수 클래스 성능도 효과적으로 향상됨.



## 🔧 모델 성능 향상 방안 정리

아래는 현재 DeBERTa 분류 모델의 성능을 더 끌어올리기 위해 적용할 수 있는 개선 전략들이다.

---

## 1️⃣ Epoch 증가

- 현재 **4 epoch → 6~8 epoch**로 증가 가능.
- 단, train_acc가 이미 **97%**까지 상승한 상태라 **과적합 위험** 존재.
- 반드시 **EarlyStopping** 적용 권장:
  - 예: `monitor='val_loss'`, `patience=2`, `mode='min'`
  - → val 성능이 더 이상 개선되지 않을 때 자동으로 학습 종료.

---

## 2️⃣ Learning Rate 조정

- 현재 lr = **2e-5**
- 더 안정적인 수렴을 위해 다음과 같은 스케줄러 적용 가능:

### 🔹 Warm-Up 증가  
- warmup_steps 비율을 **0.1 → 0.2**로 증가  
- 초반 과도한 gradient 변동 방지

### 🔹 Cosine Annealing Scheduler  
- 초기 2e-5 → 점진적으로 **1e-5 이하로 감소**
- 장기 학습 안정화에 효과적

---

## 3️⃣ Batch Size 조정

- 현재 batch_size = **16**
- 가능하다면 **32~64**까지 확대 가능.
  - 큰 배치 → gradient 안정성 증가 → 일반화 성능 개선
- 단, **GPU VRAM 사용량 반드시 확인** 필요.

---

## 4️⃣ Dropout / Regularization 추가

- DeBERTa는 기본적으로 dropout 포함
- 더 강한 정규화가 필요할 경우:
  - classification head에 **dropout 0.2~0.3 추가** 추천
- → 과적합 완화 + val_acc 변동 감소

---

## 5️⃣ 데이터 증강 (Text Augmentation)

현재 oversampling만 사용 → **데이터 반복으로 효과 제한**

소수 클래스(부정 리뷰)에 다음 기법 적용 가능:

- **Synonym Replacement**
- **Back Translation (en → fr → en 등)**
- **Random Deletion**
- **Random Insertion**
- **EDA (Easy Data Augmentation)** 기법

→ **실질적인 부정 클래스 다양성 확보 → F1, val_acc 증가 가능**

---

## 6️⃣ 모델 앙상블

- DeBERTa 모델을 **2~3개 서로 다른 seed로 학습**
- 예측값을 **평균 또는 majority voting**
- 일반적으로 **val_acc 1~2% 상승** 가능

---

## 📌 종합 결론

현재 모델은 이미 높은 train_acc와 적정한 val_acc를 보이고 있어  
다음 접근이 가장 효과적일 가능성이 높음:

1) **EarlyStopping + Epoch 증가**  
2) **LR Scheduler 도입**  
3) **소수 클래스 데이터 증강 (강력 추천)**  
4) **class_weight + oversampling 유지**

이 네 가지가 조합되면 **과적합 억제 + 소수 클래스 개선 + 학습 안정화**가 모두 가능하다고 보여짐짐.



## 📊 최종 모델 실험 결과 요약 및 비교 분석

아래는 DeBERTa 기반 감성 분류 모델에 대해  
**기본 모델 → 가중치 + 오버샘플링 → Focal Loss + Epoch 증가**  
이렇게 단계별로 성능을 개선해 나간 실험의 종합 정리이다.

---

# 1️⃣ 적용 결과 (Focal Loss + Epoch 증가 버전)

### 🔍 데이터 분포
- 전체 학습 데이터: **2093개**
  - 부정: **1753개**
  - 긍정: **340개** (소수 클래스)

---

# 2️⃣ 학습 로그

| Epoch | Train Loss | Train Acc | Val Acc |
|-------|------------|-----------|---------|
| 1 | 0.5749 | 0.5215 | 0.1623 |
| 2 | 0.3439 | 0.6201 | 0.7399 |
| 3 | 0.1703 | 0.9062 | 0.8640 |
| 4 | 0.1014 | 0.9570 | 0.8640 |
| 5 | 0.0594 | 0.9797 | **0.8687** |
| 6 | 0.0228 | 0.9898 | 0.8663 |

### 📌 주요 관찰
- Epoch 3 이후부터 **train_acc ≈ 99%**로 수렴 (과적합 위험 존재)
- 그러나 **val accuracy는 안정적으로 유지**
- 기존 대비 최고의 성능(0.8687) 달성
- EarlyStopping 기준으로 보면 Epoch 5가 최적점

---

# 3️⃣ 전체 실험 모델 성능 비교

| 모델 | val_acc 최고 | 학습 방식 | Epoch |
|------|-------------------|---------------------------|--------|
| **1️⃣ 기본 DeBERTa** | 0.7995 | CrossEntropy | 4 |
| **2️⃣ Weighted + Oversampling** | 0.8401 | class_weight + oversampling | 4 |
| **3️⃣ Focal Loss 모델 (현재)** | **0.8687 (최고)** | Focal Loss + Epoch 증가 + EarlyStopping | 7 |

---

# 4️⃣ 성능 상승 요인 분석

### 🟩 **1단계: class_weight + oversampling → val_acc 0.7995 → 0.8401**
- 소수 클래스(긍정 340개)의 중요도를 반영
- 데이터 불균형 완화
- 과적합 감소 + 일반화 성능 증가

### 🟦 **2단계: Focal Loss → val_acc 0.8401 → 0.8687**
- Easy sample보다 "어려운 샘플"에 가중치를 집중  
- 소수 클래스의 학습 품질 증가  
- Loss가 안정적으로 감소, val_acc가 plateau 없이 상승

### 🟨 **3단계: Epoch 증가 + EarlyStopping**
- Epoch=5에서 최적 성능 확인  
- train_acc는 99%까지 상승했지만 val_acc 하락 없음  
- EarlyStopping으로 과적합 위험 제어 성공

---

# 5️⃣ 다음 단계: 성능 + 속도 균형 맞춘 최적 조합 실험

### 예정된 실험:
- **batch_size 32**
- **learning rate 1e-5**
- Focal Loss 유지
- WeightedSampler 여부 비교
- Gradient clipping, LR scheduler(Cosine) 적용 가능

이 실험을 통해  
🔹 학습 속도 증가  
🔹 val_acc 유지 또는 소폭 향상  
🔹 과적합 억제  
를 목표로 최적의 실용형 모델을 확보할 수 있음.

---

# 🎯 결론

현재까지의 실험에서 **가장 높은 성능은 Focal Loss + Epoch 5 모델 (val_acc 0.8687)** 이며,  
이는 기존 방식 대비 매우 큰 개선이다.

이제 남은 작업은  
- **배치/학습률 최적화**
- **중립 레이블 복원 시 3-class 확장 가능성**
- **Test dataset 평가**
- **모델 배포용 경량화**를 진행하기로 함


# 후속 작업 진행 결과

## Training Results

### Epoch 1
- **Training Loss**: 0.2629
- **Training Accuracy**: 0.5102
- **Validation Accuracy**: 0.1790  
**Progress**:  
Training Epoch 1: 100% | ██████████ | 105/105 [00:32<00:00, 3.19it/s]

---

### Epoch 2
- **Training Loss**: 0.1197
- **Training Accuracy**: 0.8017
- **Validation Accuracy**: 0.8091  
**Progress**:  
Training Epoch 2: 100% | ██████████ | 105/105 [00:32<00:00, 3.19it/s]

---

### Epoch 3
- **Training Loss**: 0.0528
- **Training Accuracy**: 0.9600
- **Validation Accuracy**: 0.8687  
**Progress**:  
Training Epoch 3: 100% | ██████████ | 105/105 [00:34<00:00, 3.05it/s]

---

### Epoch 4
- **Training Loss**: 0.0384
- **Training Accuracy**: 0.9797
- **Validation Accuracy**: 0.8425  
**Progress**:  
Training Epoch 4: 100% | ██████████ | 105/105 [00:34<00:00, 3.02it/s]

---

### Epoch 5
- **Training Loss**: 0.0185
- **Training Accuracy**: 0.9869
- **Validation Accuracy**: 0.8735  
**Progress**:  
Training Epoch 5: 100% | ██████████ | 105/105 [00:31<00:00, 3.28it/s]

---

### Epoch 6
- **Training Loss**: 0.0101
- **Training Accuracy**: 0.9916
- **Validation Accuracy**: 0.8759  
**Progress**:  
Training Epoch 6: 100% | ██████████ | 105/105 [00:31<00:00, 3.29it/s]

---

> 지금까지의 성능 중 가장 높은 성능이 나옴.  
> 드디어 다음 step으로 넘어가기로 함

---

원본 데이터 `FINAL_DATA_ROWS_#DELETED.csv`을 지금까지 프로젝트를 진행한 경험을 살려 **신중하게 라벨링** 진행 후,  
이전에 있었던 장점만 살려 **전처리** 진행.  
이후 이전에 가장 `val accuracy` 높게 나온 모델 방식 활용하기로 함.  
(DeBERTa v3, 가중치 + 오버샘플링)해서 진행.

---

## 전체 데이터 부정/긍정 비율 시각화

![부정/긍정 비율 시각화](106.png)



## 시계열(date) 기준 부정 비율 변화 확인

![시계열(date) 기준 부정 비율 변화 확인](101.png)

---

✅ **전체 데이터 라벨링 완료**

```txt
sentiment_label
0    18024
1     2905
```
---

![이분류 결과](105.png)  
![이분류 결과](106.png)


--- 

##  통계 분석 결과

###  피어슨 상관계수 (Pearson Correlation)
- **상관계수 r:** `-0.3337`  
- **P-value:** `0.0853`

**해석:**  
- 음의 상관관계 → 공포지수와 부정 감성 비율이 관계가 있음
- P-value가 0.05보다 크므로 통계적 유의성은 부족하지만,  
  **경향성이 존재한다는 정도의 해석은 가능**

---

###  DTW(Time Series Similarity)
- **DTW Distance:** `3.4447`

**해석:**  
- DTW 거리가 3.44로 나타나 **두 시계열의 패턴이 구조적으로 상당히 유사함**  
- 초기 전처리 대비 **유사도가 크게 향상**됨을 의미

---
**결론:**  
초반에 실패했던 전처리 데이터와 비교하면,  
현재 전처리 결과는 **공포-탐욕 지수와의 패턴이 월등히 유사**하게 나타났습니다.  
이는 **전처리가 성공적으로 이루어졌음을 강하게 증명**합니다.

![공포-탐욕지수와 부정 감성 비율 비교](103.png)  
![공포-탐욕지수와 부정 감성 비율 비교 정규화](104.png)

---

## 📌 토픽 모델링 설명

이번 분석에서는 **BERTopic**을 사용하여 주요 토픽을 추출했습니다.  
BERTopic은 내부적으로 **HDBSCAN 클러스터링**을 기반으로 동작하며, 다음과 같은 장점이 있기 때문에 선택하였습니다:

- **밀집도가 낮은 문서(노이즈)를 자동 제거**  
- 의미 있는 토픽만 남겨 **더 선명한 토픽 구조** 확인 가능  
- 한국어 데이터에서도 성능이 우수한 편

즉, **노이즈가 많은 SNS/텍스트 데이터의 특성에 적합**하여,  
더 정확한 토픽 해석을 위해 BERTopic을 활용했습니다.

---


##  부정 리뷰 토픽 모델 결과 - 의미 있는 주요 토픽 (상위 10개)
================================================================================
|   Topic |   Count | Name                                     | Representation                                                                         |
|--------:|--------:|:-----------------------------------------|:---------------------------------------------------------------------------------------|
|       0 |     509 | 0_hospitals_hospital_debt_pay            | hospitals, hospital, debt, pay, healthcare, nurses, money, loans, doctors, beds        |
|       1 |     353 | 1_walmart_store_customers_masks          | walmart, store, customers, masks, enforce, employees, mask, stores, local, wear        |
|       2 |     308 | 2_trump_death_threats_deaths             | trump, death, threats, deaths, president, responsible, man, fauci, celebrate, politics |
|       3 |     293 | 3_vaccine_vaccines_take_get              | vaccine, vaccines, take, get, people, want, evidence, vaccinated, taking, doctors      |
|       4 |     283 | 4_coronavirus_coronaviruses_virus_people | coronavirus, coronaviruses, virus, people, corona, cases, papers, whatsapp, new, think |
|       5 |     252 | 5_covid_vaccine_vaccinated_19            | covid, vaccine, vaccinated, 19, effects, vaccines, infection, long, side, died         |
|       6 |     203 | 6_kids_children_vaccines_parents         | kids, children, vaccines, parents, pediatrician, age, vaccine, child, baby, kid        |
|       7 |     184 | 7_asthma_breathing_breathe_oxygen        | asthma, breathing, breathe, oxygen, mask, wear, lung, inhaler, copd, wearing           |
|       8 |     164 | 8_covid_hoax_19_propaganda               | covid, hoax, 19, propaganda, fox, deniers, believe, truth, stop, news                  |
|       9 |     158 | 9_vaccine_vaccines_anti_rfk              | vaccine, vaccines, anti, rfk, flint, placebo, injecting, guy, film, water              |
--------------------------------------------------------------------------------
총 분석 문서 수: 18024 | 노이즈(-1) 토픽 문서 수: 9563 | 의미 있는 토픽 문서 수: 8461
================================================================================

================================================================================
##  긍정 리뷰 토픽 모델 결과 - 의미 있는 주요 토픽 (상위 10개)
================================================================================
|   Topic |   Count | Name                               | Representation                                                                     |
|--------:|--------:|:-----------------------------------|:-----------------------------------------------------------------------------------|
|       0 |     201 | 0_vaccine_vaccines_vaccinated_mrna | vaccine, vaccines, vaccinated, mrna, people, get, unvaccinated, take, immune, like |
|       1 |     131 | 1_hospital_hospitals_patients_pay  | hospital, hospitals, patients, pay, work, medical, care, nurses, debt, school      |
|       2 |     122 | 2_pfizer_moderna_side_effects      | pfizer, moderna, side, effects, got, vaccine, shot, second, arm, dose              |
|       3 |     107 | 3_death_deaths_people_die          | death, deaths, people, die, life, rate, cases, dying, think, per                   |
|       4 |     101 | 4_covid_19_clap_yes                | covid, 19, clap, yes, fdr, believe, saw, covid19, days, think                      |
|       5 |      95 | 5_walmart_store_mask_employees     | walmart, store, mask, employees, customers, masks, wearing, wal, mart, stores      |
|       6 |      89 | 6_death_man_trump_people           | death, man, trump, people, threats, knew, could, larry, cain, guy                  |
|       7 |      76 | 7_coronavirus_bosch_tests_corona   | coronavirus, bosch, tests, corona, rapid, trump, test, message, going, one         |
|       8 |      57 | 8_wear_mask_masks_wearing          | wear, mask, masks, wearing, want, people, condition, face, medical, protect        |
|       9 |      56 | 9_covid_vaccine_mrna_vaccines      | covid, vaccine, mrna, vaccines, immune, 19, tumor, vaccinated, system, spike       |
--------------------------------------------------------------------------------
총 분석 문서 수: 2905 | 노이즈(-1) 토픽 문서 수: 1204 | 의미 있는 토픽 문서 수: 1701
================================================================================


#  BERTopic 기반 토픽 모델링 전처리 및 노이즈 처리 과정

본 과정은 BERTopic을 사용하여 토픽 모델링을 수행하기 전후에 **의미 없는 데이터 제거**, **노이즈 문서 처리**, **불필요한 토픽 블랙리스트 처리**를 수행하여 분석의 신뢰도와 결과 해석의 명확성을 확보하기 위한 단계임.

---
#  리뷰 토픽 분석 결과 (상위 10개)

총 18,024건의 부정 리뷰와 2,905건의 긍정 리뷰를 대상으로 BERTopic을 적용하여 상위 10개 토픽을 추출함.  
각 토픽은 핵심 키워드와 함께 분석적 의미를 명시하여 보고서에 바로 활용 가능함.

---

##  부정 리뷰 (Negative Reviews) 상위 10개 토픽

- 분석 대상: 총 18,024건 중 8,461건이 의미 있는 토픽으로 분류  
- 주요 주제: 의료 시스템 문제, 정치적 논쟁, 백신 불신/회의론, 마스크 착용 논란 등

| Topic | Count | 핵심 키워드 | 분석 및 해석 |
|-------|-------|-------------|---------------|
| 0 | 509 | hospitals, debt, pay, healthcare, nurses | **의료 시스템 비용 및 과부하**: 병원(hospitals)과 의료비 지불(pay), 빚(debt) 등 경제적 부담과 간호사(nurses) 등 의료 자원의 부족 문제를 다룸 |
| 1 | 353 | walmart, store, customers, masks, enforce | **마스크 의무화 및 상업 시설 논란**: 상점(store)에서 마스크 착용(enforce) 강제, 고객(customers)과 마찰 |
| 2 | 308 | trump, death, threats, president, responsible | **정치적 책임 및 논쟁**: 트럼프 대통령 관련 사망(death)과 책임(responsible)에 대한 강한 비판 |
| 3 | 293 | vaccine, take, get, people, want, evidence | **백신 접종 거부 및 증거 요구**: 백신 접종 선택권, 효능 증거(evidence) 요구 등 거부감 표현 |
| 4 | 283 | coronavirus, virus, people, corona, cases | **팬데믹 일반 불안**: 감염병 및 코로나바이러스(coronavirus) 관련 초기 우려 |
| 5 | 252 | covid, vaccine, effects, long, side, died | **백신 부작용 및 부정적 결과**: 부작용(side effects), 장기 코로나(long), 사망(died) 우려 |
| 6 | 203 | kids, children, vaccines, parents, pediatrician | **아동 백신 접종 논쟁**: 아이들(kids, children) 접종 필요성, 부모(parents)와 소아과 의사(pediatrician) 역할 논의 |
| 7 | 184 | asthma, breathing, oxygen, mask, wear, lung | **마스크 착용 건강 위험**: 천식(asthma) 등 호흡기 질환자의 마스크(mask) 착용 문제 |
| 8 | 164 | covid, hoax, propaganda, deniers, believe, news | **코로나 회의론 및 음모론**: 사기(hoax)·선전(propaganda) 주장, 뉴스(news) 불신 |
| 9 | 158 | vaccine, vaccines, anti, rfk, placebo, injecting | **반백신 운동 및 음모론**: 특정 인물(rfk) 언급, 백신 성분/효능 관련 음모론 주장 |

---

##  긍정 리뷰 (Positive Reviews) 상위 10개 토픽

- 분석 대상: 총 2,905건 중 1,701건이 의미 있는 토픽으로 분류  
- 주요 주제: 백신 효과 옹호, 의료진 지지, 안전 조치 동의, 마스크 착용 권장 등

| Topic | Count | 핵심 키워드 | 분석 및 해석 |
|-------|-------|-------------|---------------|
| 0 | 201 | vaccine, vaccines, vaccinated, mrna, immune | **백신 접종 권장 및 기술 옹호**: 접종 중요성 강조, MRN-A 기술 언급, 면역 형성 기대 |
| 1 | 131 | hospital, hospitals, patients, pay, work, nurses | **의료진 헌신 및 시스템 지지**: 의료진(work) 노력, 환자(patients) 돌봄, 의료 시스템 지지 |
| 2 | 122 | pfizer, moderna, side, effects, shot, dose | **백신 접종 경험 공유**: 화이자(pfizer), 모더나(moderna) 1/2차 접종 후 경미한 부작용(side effects) 경험 |
| 3 | 107 | death, deaths, people, die, life, rate, cases | **코로나 위험성 현실적 인정**: 사망률(rate), 확진자 수(cases), 조치 필요성 강조 |
| 4 | 101 | covid, 19, clap, yes, fdr, believe | **사회적 연대 및 지지**: 긍정적 반응(clap, yes), 리더십(FDR) 언급, 사태 극복 희망 |
| 5 | 95 | walmart, store, mask, employees, wearing | **마스크 규정 준수 지지**: 상점(walmart) 마스크(mask) 착용 규정 준수 긍정 평가 |
| 6 | 89 | death, man, trump, people, threats | **정치적 반대 의견 비판**: 트럼프 관련 부정 의견 비판, 반대 진영 위협(threats) 언급 |
| 7 | 76 | coronavirus, bosch, tests, corona, rapid, test | **진단 및 검사 기술 관심**: 코로나 테스트(tests, rapid), 기술적 해결책 긍정적 관심 |
| 8 | 57 | wear, mask, masks, wearing, people, protect | **마스크 착용 권장**: 개인과 타인 보호(protect) 목적 강조 |
| 9 | 56 | covid, vaccine, mrna, vaccines, immune, tumor | **백신 면역 및 장기적 효능 기대**: MRNA 백신의 면역 영향, 다른 질병(예: tumor) 예방 기대 |

---

##  부정 vs 긍정 토픽 대비 분석

특히 의료 시스템 관련 토픽을 대비하면 대중 인식 차이를 명확히 보여줌.

| 관점 | 핵심 키워드 | 의미 |
|------|-------------|------|
| 부정 (Topic 0) | debt, pay, hospitals, nurses | 의료 시스템은 **경제적 부담**의 대상. 병원 과부하, 비용, 인력 부족 등 부정적 측면 강조 |
| 긍정 (Topic 1) | patients, nurses, work, hospital | 의료 시스템은 **사회적 필요와 인적 노력**의 대상. 환자 치료, 간호사 노력, 돌봄 등 긍정적 측면 강조 |

> 💡 시사점: 동일한 주제도 관점에 따라 경제적 부담 vs 사회적 가치로 인식이 나뉘다.

---

##  데이터 클리닝 및 전처리 (Pre-processing)

토픽 모델링의 입력 데이터(리뷰 텍스트)에서 노이즈를 최소화하고 품질을 높이는 단계임임.

| 구분 | 목적 | 상세 내용 | 코드 구현 (원리) |
|------|------|-----------|----------------|
| 결측치 제거 | 분석 오류 방지 및 데이터 품질 확보 | 텍스트 컬럼(`text`)에 **누락된 값(NaN)**이 있는 행 제거 | `df = df.dropna(subset=['text'])` |
| 불용어 처리 | 의미 없는 단어 제거 | 영어 불용어(stop_words) 목록을 사용하여 `the`, `a`, `is`, `and` 등 분석에 도움이 되지 않는 단어 제거 | `CountVectorizer(stop_words=stopwords.words('english'))` |
| 구두점/특수문자 제거 | 단어 통일성 확보 | 문장 부호나 특수문자(`?`, `!`, `#`) 제거 → `covid!`와 `covid` 동일 처리 | CountVectorizer 또는 정규 표현식 활용 |

> ⚠️ BERTopic은 내부적으로 토큰화 및 정규화를 수행하지만, CountVectorizer를 커스터마이징하여 전처리를 보완 가능

---

## 2️ BERTopic 기반 노이즈 문서 처리 (Noise Document Handling)

BERTopic은 **HDBSCAN 클러스터링**을 사용하여 밀집도가 낮은 문서를 자동으로 노이즈로 분류함.

### A. 노이즈 문서 자동 분류 및 해석

| 항목 | 상세 설명 | 분석적 의미 |
|------|-----------|-------------|
| 노이즈 토픽 (`-1`) | 토픽 번호 `-1`은 HDBSCAN 단계에서 특정 군집에 속하지 못한 문서 | 주제성이 모호하거나 일반적이거나, 다른 토픽 내용이 섞인 문서를 제외 |
| 예시 | 부정 리뷰 18,024건 중 9,563건이 노이즈 (`≈53%`) | 부정 의견의 절반 이상이 산발적이고 특정 논쟁 주제에 집중되지 않음을 시사 |

### B.해석석
> "총 분석 문서 중 **Topic -1**로 분류된 문서는 주제성이 미약하여 주요 논의에서 제외되었으나, 남은 토픽들은 높은 응집력을 가진 핵심 주제임을 보장함. 부정 리뷰의 경우 노이즈 비율이 53%로 나타났으며, 이는 대중의 부정적 의견이 특정 쟁점에 집중되기보다 광범위하고 파편적인 불만으로 표출됨을 보여준다."

---

## 3️ 불필요한 토픽 블랙리스트 처리 (Blacklisting)

노이즈 문서 처리 후에도, 생성된 의미 있는 토픽 중 일부가 **분석 목표에 부합하지 않거나 특정 단어로 왜곡**된 경우 수동 처리가 필요했다.

### A. 토픽 병합 및 제거

| 처리 목적 | 필요성 | BERTopic 활용 방법 | 보고서 기술 예시 |
|-----------|--------|-----------------|----------------|
| 토픽 병합 (Merge) | 내용적으로 매우 유사한 토픽 통합 | `topic_model.merge_topics()` → 유사도가 높은 토픽 통합 | "유사도가 0.8 이상인 토픽을 병합하여 '백신 후기 및 부작용' 통합 주제로 재분류하였다." |
| 토픽 제거 (Remove/Blacklist) | 분석 목표와 무관한 토픽 제외 | `df['topic']`에서 해당 토픽 문서를 노이즈(`-1`)로 재할당 또는 제외 | "분석 목표와 무관한 토픽 [13번]을 블랙리스트 처리하고 문서를 노이즈 그룹으로 재분류하였다." |

### B. 보고서 반영용 키워드/이름 수정
- **토픽 키워드 갱신:** `topic_model.update_topics(topics_to_remove=[...])`  
  → 핵심을 흐리는 단어 제거
- **토픽 이름 재정의:** BERTopic 자동 생성 이름 대신, 분석가가 해석한 의미 있는 이름 지정  
  - 예: `0_hospitals_hospital_debt_pay` → `의료비 및 시스템 과부하 문제`

---

## ✅종합 요약

1. **데이터 전처리**: 결측치 제거, 불용어 제거, 특수문자 정규화  
2. **노이즈 문서 처리**: HDBSCAN 기반 `-1` 토픽 문서 분리 → 핵심 주제 응집도 확보  
3. **블랙리스트 처리**: 의미 없는 토픽 제거 및 유사 토픽 병합 → 분석 효율성 향상  
4. **보고서 반영**: 키워드와 토픽 이름 재정의 → 가독성과 해석 명확성 확보

>  BERTopic 기반 전처리와 노이즈 처리를 통해 **분석 데이터의 질을 높이고, 토픽 결과의 신뢰성과 해석 가능성을 강화**할 수 있었.




#  BERTopic 기반 리뷰 토픽 분석 결과

총 18,024건의 부정 리뷰와 2,905건의 긍정 리뷰를 대상으로 BERTopic을 적용하여 **의미 있는 토픽**을 추출함.  
각 토픽은 핵심 키워드와 함께, 분석적 해석을 추가하여 활용할 수 있음.

---

##  부정 리뷰 (Negative Reviews) 토픽 분석

- 분석 대상: 총 18,024건 중 8,461건이 의미 있는 10개 이상의 토픽으로 분류  
- 주요 토픽: 백신 불신, 정치적 논쟁, 경제적/의료 시스템 문제

| Topic | Count | 대표 토픽 이름 | 핵심 키워드 | 분석 및 해석 |
|-------|-------|----------------|-------------|---------------|
| 0 | 509 | hospitals_hospital_debt_pay | hospitals, hospital, debt, pay, healthcare, nurses, money | **의료 시스템과 비용 문제**. 병원 과부하, 간호사 문제, 의료비(debt, pay) 등 경제적/시스템적 불만을 나타냄 |
| 1 | 353 | walmart_store_customers_masks | walmart, store, customers, masks, enforce, employees | **마스크 착용 강제 및 상업 시설 문제**. 월마트 등 상점에서 마스크 착용 강제에 대한 불만 |
| 2 | 308 | trump_death_threats_deaths | trump, death, threats, deaths, president, responsible | **정치 및 지도자 책임 논쟁**. 트럼프 대통령 관련 사망자 수, 책임론 |
| 3 | 293 | vaccine_vaccines_take_get | vaccine, vaccines, take, get, people, want, evidence | **백신 접종 자체에 대한 불신/거부**. 백신 여부, 증거(evidence) 요구 등 논의 |
| 5 | 252 | covid_vaccine_vaccinated_19 | covid, vaccine, vaccinated, effects, long, side, died | **백신 부작용 및 장기 영향**. 접종 후 부작용, 감염, 사망, 장기 코로나(long) 관련 우려 |
| 8 | 164 | covid_hoax_19_propaganda | covid, hoax, 19, propaganda, deniers, believe, news | **코로나 회의론 및 음모론**. 뉴스와 정보 불신, 코로나 사기 주장 등 |

> ⚠️ 부정 리뷰 토픽의 경우 경제적 부담, 정치적 논쟁, 백신 불신 등 다양한 영역으로 분산되어 있음

---

## 2️ 긍정 리뷰 (Positive Reviews) 토픽 분석

- 분석 대상: 총 2,905건 중 1,701건이 의미 있는 토픽으로 분류  
- 주요 토픽: 백신 효과 옹호, 의료진/상점 규정 준수, 안전 인식

| Topic | Count | 대표 토픽 이름 | 핵심 키워드 | 분석 및 해석 |
|-------|-------|----------------|-------------|---------------|
| 0 | 201 | vaccine_vaccines_vaccinated_mrna | vaccine, vaccines, vaccinated, mrna, people, get, immune | **백신 접종 옹호 및 면역력 강조**. MRN-A 기술 언급, 백신 효과 지지 |
| 1 | 122 | pfizer_moderna_side_effects | pfizer, moderna, side, effects, got, vaccine, shot, second, arm | **백신 접종 경험 공유**. 경미한 부작용, 팔 통증 등 긍정 후기 |
| 1 | 131 | hospital_hospitals_patients_pay | hospital, hospitals, patients, pay, work, medical, care, nurses | **의료진 및 의료 행위 옹호**. 환자 치료, 간호사 노력, 의료 시스템의 긍정적 측면 강조 |
| 5 | 95 | walmart_store_mask_employees | walmart, store, mask, employees, customers, wearing | **마스크 착용 및 상점 규정 준수**. 규정 준수에 대한 긍정적 평가 |
| 3 | 107 | death_deaths_people_die | death, deaths, people, die, life, rate, cases, dying | **위험 인식 및 대응 공감대**. 사망률, 사례 수 등 위험을 인정하고 조치 필요성 강조 |

---

## 3️⃣ 부정 vs 긍정 토픽 대비 분석

특히 **부정 토픽 0번**과 **긍정 토픽 1번**을 대비하면, **의료 시스템에 대한 인식 차이**가 명확히 나타남.

| 관점 | 핵심 키워드 | 분석적 의미 |
|------|-------------|-------------|
| 부정 (Topic 0) | debt, pay, hospitals, hospital | 의료 시스템은 경제적 부담의 대상. 비용 문제, 병원 과부하, 간호사 인력 부족 등 부정적 측면 강조 |
| 긍정 (Topic 1) | patients, nurses, care, hospital | 의료 시스템은 사회적 필요와 인적 노력의 대상. 환자 치료, 의료진 노력, 돌봄 등 긍정적 측면 강조 |

> 💡 **시사점:** 동일한 주제(의료 시스템)에 대해서도, 경제적/부정적 요인과 사회적/긍정적 요인으로 리뷰가 나뉘어 표현됨.  
> 보고서에서는 이러한 대비를 통해 **대중 의견의 다양성 및 핵심 쟁점**을 시각적으로 강조 가능.

---

### 🔹 결론

지금까지의 과정을 통해서 잘 정재한 검증된 데이터를 얻었고, 토픽 모델링을 통해 다음과 같은 결론을 얻었다.

1. 부정 리뷰는 경제적 부담, 정치적 논쟁, 백신 불신/부작용 우려 중심  
2. 긍정 리뷰는 백신 효과 옹호, 의료진 노력, 규정 준수 및 안전 인식 중심  
3. 따라서 **사회적 논쟁점과 대중 인식 차이**가 다음과 같은 긍/부정의 인식을 갈랐다고 볼 수 있다.

